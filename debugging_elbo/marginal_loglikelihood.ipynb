{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.log_normal import LogNormal\n",
    "\n",
    "from multi_virt_v2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phumon/Documents/Research/nlu-test-sets/params_mvirt_sync/lr-0.0001-steps-$4000-alpha-lognormal-identity-dim*_theta-normal-identity_nosubsample_2.00_0.40_particles8/params.p\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir='/Users/phumon/Documents/Research/nlu-test-sets/params_mvirt_sync'\n",
    "file_name=f'lr-0.0001-steps-$4000-alpha-lognormal-identity-dim*_theta-normal-identity_nosubsample_2.00_0.40_particles8/params.p'\n",
    "exp_dir=os.path.join(base_dir, file_name)\n",
    "\n",
    "\n",
    "print(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(exp_dir, dimension):\n",
    "    posterior_stats = {}\n",
    "    \n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(exp_dir)\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    for k, v in pyro_param_dict.items():\n",
    "        if k == \"g mu\":\n",
    "            n_items = v.size(0)\n",
    "        elif k == \"t mu\":\n",
    "            n_models = v.size(0)\n",
    "        posterior_stats[k] = v.mean().item()\n",
    "    \n",
    "    betas = Normal(posterior_stats['b mu']*torch.ones(n_items, dimension), torch.exp(torch.tensor(posterior_stats['b logstd'])))\n",
    "    log_gamma = Normal(posterior_stats['g mu']*torch.ones(n_items), torch.exp(torch.tensor(posterior_stats['g logstd'])))\n",
    "    alphas = LogNormal(posterior_stats['a mu'] * torch.ones(n_items, dimension), torch.exp(torch.tensor(posterior_stats['a logstd'])))\n",
    "    thetas = Normal(posterior_stats['t mu'] * torch.ones(n_models, dimension), torch.exp(torch.tensor(posterior_stats['t logstd'])))\n",
    "    probs = {\n",
    "                \"beta\": betas,\n",
    "                \"log_gamma\": log_gamma,\n",
    "                \"alpha\": alphas,\n",
    "                \"theta\": thetas\n",
    "    }\n",
    "    \n",
    "    return posterior_stats, probs, n_items, n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prior(item_param_std, alpha_std, dimension, n_items, n_models):\n",
    "    # Generate params\n",
    "    betas = Normal(torch.zeros(n_items, dimension), torch.tensor(item_param_std))\n",
    "    log_gamma = Normal(torch.zeros(n_items), torch.tensor(item_param_std))\n",
    "\n",
    "    alphas = LogNormal(0 * torch.ones(n_items, dimension), torch.tensor(alpha_std))\n",
    "\n",
    "    # Generate thetas\n",
    "    thetas = Normal(0 * torch.ones(n_models, dimension), torch.tensor(item_param_std))\n",
    "    probs = {\n",
    "                \"beta\": betas,\n",
    "                \"log_gamma\": log_gamma,\n",
    "                \"alpha\": alphas,\n",
    "                \"theta\": thetas\n",
    "    }\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marginal_loglik(prior_probs, posterior_probs, dimension, n_particles=10):\n",
    "    log_weights = []\n",
    "    for i in range(n_particles):\n",
    "        #log p(x) = logsumexp(log p(x|z_k) + log p(z_k) - log q(z_k), dim=DIM) - log(K)\n",
    "        log_weight = 0\n",
    "        prior_values = {}\n",
    "        for k, dist_param in prior_probs.items():\n",
    "            prior_tmp = prior_probs[k].sample()\n",
    "            prior_values[k] = prior_tmp\n",
    "            posterior_tmp = posterior_probs[k].sample()\n",
    "            log_weight += (prior_probs[k].log_prob(prior_tmp) - posterior_probs[k].log_prob(posterior_tmp)).sum()\n",
    "        \n",
    "        gamma = sigmoid(prior_values['log_gamma'])\n",
    "        alphas = prior_values['alpha']\n",
    "        thetas = prior_values['theta']\n",
    "        betas = prior_values['beta']\n",
    "        if dimension > 1:\n",
    "            prob = gamma[None, :] + (1.0 - gamma[None, :]) * sigmoid(torch.sum(alphas[None, :, :] * (thetas[:, None] - betas[None, :]).squeeze(), dim=-1))\n",
    "        else:\n",
    "            betas=betas.squeeze()\n",
    "            gamma=gamma.squeeze()\n",
    "            alphas=alphas.squeeze()\n",
    "            thetas=thetas.squeeze()\n",
    "            prob = gamma[None, :] + (1.0 - gamma[None, :]) * sigmoid(alphas[None, :] * (thetas[:, None] - betas[None, :]))\n",
    "        log_weight += torch.log(prob).sum()\n",
    "        log_weights.append(log_weight)\n",
    "    marginal = torch.logsumexp(log_weight, 0) - torch.log(torch.tensor(n_particles))\n",
    "    return marginal\n",
    "    #return lik, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_logprob_list=[]\n",
    "correct_list=[]\n",
    "dim_list=[]\n",
    "item_param_std=2; alpha_std=0.4\n",
    "\n",
    "for filepath in glob.iglob(exp_dir):\n",
    "    dimension = int(filepath.split('/')[-2].split('_')[0].rsplit('-',1)[1][3:])\n",
    "    dim_list.append(dimension)\n",
    "    \n",
    "    posterior_stats, posterior_probs, n_items, n_models = get_posterior(filepath, dimension)\n",
    "    prior_probs = get_prior(item_param_std, alpha_std, dimension, n_items, n_models)\n",
    "    marginal = get_marginal_loglik(prior_probs, posterior_probs, dimension)\n",
    "    \n",
    "    marginal_logprob_list.append(marginal.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, -17705.234375),\n",
       " (2, -16971.255859375),\n",
       " (3, -18588.919921875),\n",
       " (4, -23208.138671875),\n",
       " (5, -27083.51953125),\n",
       " (6, -27869.66796875),\n",
       " (7, -23846.10546875),\n",
       " (8, -25149.951171875)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data = list(zip(dim_list, marginal_logprob_list))\n",
    "plot_data.sort(key=lambda x: x[0])\n",
    "dim, marginals = list(zip(*plot_data))\n",
    "\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, -17705.234375),\n",
       " (2, -16971.255859375),\n",
       " (3, -18588.919921875),\n",
       " (4, -23208.138671875),\n",
       " (5, -27083.51953125),\n",
       " (6, -27869.66796875),\n",
       " (7, -23846.10546875),\n",
       " (8, -25149.951171875)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data = list(zip(dim_list, marginal_logprob_list))\n",
    "plot_data.sort(key=lambda x: x[0])\n",
    "dim, marginals = list(zip(*plot_data))\n",
    "\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28182e57282c4451acd1bd53f6955f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(dim[:-4], marginals[:-4])\n",
    "plt.xlabel('Dim')\n",
    "plt.ylabel('log p(x)') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(dim, acc)\n",
    "plt.xlabel('Dim')\n",
    "plt.ylabel('reconstruction acc') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent_features",
   "language": "python",
   "name": "latent_features"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
