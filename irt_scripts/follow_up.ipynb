{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle5 as pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+torch.exp(-x))\n",
    "\n",
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean', target=None):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    if target:\n",
    "        idx = model_names.index(target)\n",
    "        best_value = theta[col].iloc[idx]\n",
    "        print('Local Grad for Target Model')\n",
    "        print(f'Target model: {target}\\n{best_value}')\n",
    "    else:\n",
    "        best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "        print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col].values), torch.tensor(beta[col].values)\n",
    "    \n",
    "    logits = (a*(best_value-b))\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = sigmoids*(1.-sigmoids)*a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g)*scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model_guide(alpha_dist, theta_dist, alpha_transform, theta_transform):\n",
    "    model = lambda obs: irt_model(obs, alpha_dist, theta_dist, alpha_transform = alpha_transform, theta_transform = theta_transform)\n",
    "    guide = lambda obs: vi_posterior(obs, alpha_dist, theta_dist)\n",
    "    \n",
    "    return model, guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data_accuracies(data, verbose = False, get_cols = False):\n",
    "    '''\n",
    "    Method to reformat `data` and calculate item and responder accuracies.\n",
    "    \n",
    "    Args:\n",
    "        data:                DataFrame of item responses.\n",
    "        verbose:             Boolean value of whether to print statements.\n",
    "        get_cols:            Boolean value of whether to return original column\n",
    "                             values of `data`.\n",
    "        \n",
    "    Returns:\n",
    "        new_data:            Reformatted `data`, dropping first column.\n",
    "        accuracies:          Accuracy for each responder across examples.\n",
    "        example_accuracies:  Accuracy for each example across responders.\n",
    "        data.columns.values: Returns only if `get_cols` is True. Original column\n",
    "                             values of `data`.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    new_data = new_data[:,1:]\n",
    "    \n",
    "    model_names = dict(data['userid'])\n",
    "    accuracies = new_data.mean(-1)\n",
    "    example_accuracies = new_data.mean(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'.join([f'{name}: {acc}' for name, acc in zip(model_names.values(),accuracies)]))\n",
    "    \n",
    "    if get_cols:\n",
    "        return new_data, accuracies, example_accuracies, data.columns.values\n",
    "    else:\n",
    "        return new_data, accuracies, example_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_stats_CI(params, p=0.95, dist='normal'):\n",
    "    '''\n",
    "    Method to calculate lower and upper quantiles defined by `p`, mean, and variance of `param`\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of distribution parameters for each item keyed according to the \n",
    "                parametric distribution defined by `dist`.\n",
    "        p:      Percent of distribution covered by the lower and upper interval values for each\n",
    "                parameter.\n",
    "        dist:   Name of parametric distribution\n",
    "    \n",
    "    Returns:\n",
    "        return: {\n",
    "            'lower': Lower interval values of each parameter,\n",
    "            'upper': Upper interval values of each parameter,\n",
    "            'mean' : Mean of each parameter,\n",
    "            'var'  : Variance of each parameter\n",
    "        }\n",
    "    '''\n",
    "    stats = {}\n",
    "    if dist == 'normal':\n",
    "        L,U = scipy.stats.norm.interval(p,loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "        M,V = scipy.stats.norm.stats(loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "    elif dist == 'log-normal':\n",
    "        L,U = scipy.stats.lognorm.interval(p, s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "        M,V = scipy.stats.lognorm.stats(s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "    elif dist == 'beta':\n",
    "        L,U = scipy.stats.beta.interval(p,a=params['alpha'], b=params['beta'])\n",
    "        M,V = scipy.stats.beta.stats(a=params['alpha'], b=params['beta'])\n",
    "    else:\n",
    "        raise TypeError(f'Distribution type {dist} not supported.')\n",
    "    \n",
    "    return {\n",
    "        'lower':[L],\n",
    "        'upper':[U],\n",
    "        'mean':[M],\n",
    "        'var':[V],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_plot_stats(exp_dir, alpha_dist, theta_dist, transforms, p = 0.95):\n",
    "    '''\n",
    "    Method to return plotting statistics for 3 parameter IRT model parameters.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir:          Path to 3 parameter IRT parameters and responses.\n",
    "        alpha_dist:       Name of the item discrimination [a] distribution.\n",
    "        theta_dist:       Name of the responder ability [t] distribution.\n",
    "        transforms:       Dictionary of transformations to apply to each parameter type\n",
    "                          where keys are parameter names and values are functions.\n",
    "        p:                Percent of distribution covered by the lower and upper interval \n",
    "                          values for each parameter.\n",
    "    \n",
    "    Returns:\n",
    "        param_plot_stats: Dictionary of parameter plot statistics where keys are parameter\n",
    "                          names and values are plot statistics dictionaries as defined by\n",
    "                          get_stats_CI().\n",
    "    '''\n",
    "    param_dists = {\n",
    "        'a':alpha_dist,\n",
    "        'b':'normal',\n",
    "        'g':'normal',\n",
    "        't':theta_dist,\n",
    "    }\n",
    "\n",
    "    dist_params = {\n",
    "        'normal':['mu', 'logstd'],\n",
    "        'log-normal':['mu', 'logstd'],\n",
    "        'beta':['alpha', 'beta'],\n",
    "    }\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(os.path.join(exp_dir, 'params.p'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    # get stats for plotting\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for param, param_dist in param_dists.items():\n",
    "        temp_params = dist_params[param_dist]\n",
    "\n",
    "        for idx, (p1_orig, p2_orig) in enumerate(zip(pyro_param_dict[f'{param} {temp_params[0]}'], pyro_param_dict[f'{param} {temp_params[1]}'])):\n",
    "            p1, p2 = p1_orig.detach(), p2_orig.detach()\n",
    "            \n",
    "            temp_stats_df = pd.DataFrame.from_dict(\n",
    "                get_stats_CI(\n",
    "                    params = {\n",
    "                        temp_params[0]:p1,\n",
    "                        temp_params[1]:p2,\n",
    "                    },\n",
    "                    p=p,\n",
    "                    dist = param_dist,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            temp_stats_df = temp_stats_df.applymap(transforms[param])\n",
    "        \n",
    "            if idx == 0:\n",
    "                param_plot_stats[param] = temp_stats_df\n",
    "            else:\n",
    "                param_plot_stats[param] = param_plot_stats[param].append(temp_stats_df, ignore_index = True)\n",
    "    \n",
    "    return param_plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sign_mult(df1, df2):\n",
    "    newdf = copy.deepcopy(df2)\n",
    "    \n",
    "    for idx, row in df1.iterrows():\n",
    "        if numpy.sign(row['mean']) < 0:\n",
    "            newdf.loc[idx,'mean'] = -1*newdf.loc[idx,'mean']\n",
    "            newdf.loc[idx,'lower'] = -1*newdf.loc[idx,'upper']\n",
    "            newdf.loc[idx,'upper'] = -1*newdf.loc[idx,'lower']\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_diff_by_set(diffs, item_ids):\n",
    "    diff_by_set = {}\n",
    "    id_split = '_'\n",
    "\n",
    "    max_diff = -1e6\n",
    "    min_diff = 1e6\n",
    "    \n",
    "    for idx, diff in enumerate(diffs):\n",
    "        set_name = item_ids[idx].split(id_split)[0]\n",
    "\n",
    "        if set_name in diff_by_set.keys():\n",
    "            diff_by_set[set_name].append(diff)\n",
    "        else:\n",
    "            diff_by_set[set_name] = [diff]\n",
    "            \n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            \n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "    \n",
    "    return diff_by_set, min_diff, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_irt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,adversarial-nli,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad-v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large_best\n",
      "==========================================================================================\n",
      "Overall acc: 0.7403\n",
      "abductive_nli acc: 0.8564\n",
      "adversarial_nli acc: 0.4938\n",
      "arc_challenge acc: 0.3319\n",
      "arc_easy acc: 0.6296\n",
      "arct acc: 0.8604\n",
      "boolq acc: 0.8367\n",
      "cb acc: 0.8571\n",
      "commonsenseqa acc: 0.6759\n",
      "copa acc: 0.8400\n",
      "cosmosqa acc: 0.7984\n",
      "hellaswag acc: 0.8417\n",
      "mcscript acc: 0.9183\n",
      "mctaco acc: 0.5360\n",
      "mnli acc: 0.8991\n",
      "mrqa_natural_questions acc: 0.6941\n",
      "mutual_plus acc: 0.7314\n",
      "mutual acc: 0.8668\n",
      "newsqa acc: 0.5542\n",
      "piqa acc: 0.7617\n",
      "qamr acc: 0.7303\n",
      "quail acc: 0.6691\n",
      "quoref acc: 0.8023\n",
      "rte acc: 0.8345\n",
      "snli acc: 0.9203\n",
      "socialiqa acc: 0.7738\n",
      "squad_v2 acc: 0.4326\n",
      "wic acc: 0.7085\n",
      "winogrande acc: 0.7697\n",
      "wsc acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()\n",
    "data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles', exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <th>abductive_nli_5</th>\n",
       "      <th>abductive_nli_6</th>\n",
       "      <th>abductive_nli_7</th>\n",
       "      <th>abductive_nli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>wsc_42</th>\n",
       "      <th>wsc_43</th>\n",
       "      <th>wsc_44</th>\n",
       "      <th>wsc_45</th>\n",
       "      <th>wsc_46</th>\n",
       "      <th>wsc_47</th>\n",
       "      <th>wsc_48</th>\n",
       "      <th>wsc_49</th>\n",
       "      <th>wsc_50</th>\n",
       "      <th>wsc_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 82757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  abductive_nli_0  abductive_nli_1  \\\n",
       "0   roberta-base-10M-1_best                1                0   \n",
       "1      roberta-base-10M-1_1                0                0   \n",
       "2     roberta-base-10M-1_25                1                1   \n",
       "3     roberta-base-10M-1_50                1                0   \n",
       "4     roberta-base-10M-1_10                1                0   \n",
       "..                      ...              ...              ...   \n",
       "85   xlm-roberta-large_best                1                1   \n",
       "86      xlm-roberta-large_1                1                1   \n",
       "87     xlm-roberta-large_25                1                1   \n",
       "88     xlm-roberta-large_50                1                1   \n",
       "89     xlm-roberta-large_10                0                1   \n",
       "\n",
       "    abductive_nli_2  abductive_nli_3  abductive_nli_4  abductive_nli_5  \\\n",
       "0                 1                1                1                1   \n",
       "1                 0                1                1                0   \n",
       "2                 1                1                1                1   \n",
       "3                 1                1                1                1   \n",
       "4                 1                1                1                1   \n",
       "..              ...              ...              ...              ...   \n",
       "85                0                1                1                1   \n",
       "86                0                1                1                0   \n",
       "87                0                1                1                1   \n",
       "88                1                1                1                1   \n",
       "89                0                1                1                0   \n",
       "\n",
       "    abductive_nli_6  abductive_nli_7  abductive_nli_8  ...  wsc_42  wsc_43  \\\n",
       "0                 1                0                1  ...       1       0   \n",
       "1                 1                0                1  ...       1       0   \n",
       "2                 1                1                1  ...       0       0   \n",
       "3                 1                0                1  ...       1       0   \n",
       "4                 1                0                1  ...       1       0   \n",
       "..              ...              ...              ...  ...     ...     ...   \n",
       "85                1                1                1  ...       1       1   \n",
       "86                1                0                1  ...       0       0   \n",
       "87                0                1                1  ...       1       1   \n",
       "88                1                1                1  ...       1       1   \n",
       "89                0                1                1  ...       0       0   \n",
       "\n",
       "    wsc_44  wsc_45  wsc_46  wsc_47  wsc_48  wsc_49  wsc_50  wsc_51  \n",
       "0        1       1       0       1       0       1       0       1  \n",
       "1        1       0       0       1       0       0       0       1  \n",
       "2        0       1       0       1       1       1       1       1  \n",
       "3        0       1       0       1       1       1       0       1  \n",
       "4        0       1       0       1       1       1       0       1  \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "85       0       1       0       1       1       1       0       0  \n",
       "86       1       0       1       0       0       0       1       1  \n",
       "87       0       1       0       1       1       1       0       0  \n",
       "88       0       1       0       1       1       1       0       0  \n",
       "89       1       0       1       0       0       0       1       1  \n",
       "\n",
       "[90 rows x 82757 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 38590\n",
      "g 0\n",
      "t 47\n"
     ]
    }
   ],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats.items():\n",
    "    param_stat['log_mean'] = numpy.log(param_stat['mean'])\n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "param_b = pd.concat([param_plot_stats['b'], task_name_format], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: albert-xxlarge-v2\n",
      "1.6489769220352173\n",
      "No gamma: 0.14222308635772687\n",
      "With gamma: 0.11293618947661707\n",
      "           mean\n",
      "0      0.170596\n",
      "1      0.230350\n",
      "2      0.063763\n",
      "3      0.014811\n",
      "4      0.090399\n",
      "...         ...\n",
      "82751  0.058886\n",
      "82752  0.140021\n",
      "82753  0.090254\n",
      "82754  0.130726\n",
      "82755  0.097754\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats['g'],\n",
    ")\n",
    "\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot = pd.concat([leh_scores_plot, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_75 = leh_scores_plot.groupby(by='task_name').quantile(q=0.75).reset_index()\n",
    "\n",
    "with open(os.path.join('plot_stats_pickles', f'LEH_75qtile.p'), 'wb') as f:\n",
    "    pickle.dump(leh_75, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## % all incorrect/correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcent_correct = pd.DataFrame(\n",
    "    combined_responses.iloc[:,1:].sum(axis=0)/combined_responses.shape[0], columns=['pcent_correct']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcent_correct['all_correct'] = pcent_correct['pcent_correct'].eq(1)\n",
    "pcent_correct['all_wrong'] = pcent_correct['pcent_correct'].eq(0)\n",
    "pcent_correct['all_either'] = pcent_correct['all_correct'] + pcent_correct['all_wrong']\n",
    "pcent_correct['dataset'] = list(pd.Series(pcent_correct.index.values).apply(lambda x: '_'.join(x.split('_')[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcent_correct</th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <td>0.744444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <td>0.644444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_47</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_48</th>\n",
       "      <td>0.544444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_49</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_50</th>\n",
       "      <td>0.311111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_51</th>\n",
       "      <td>0.688889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82756 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pcent_correct  all_correct  all_wrong  all_either  \\\n",
       "abductive_nli_0       0.466667        False      False       False   \n",
       "abductive_nli_1       0.388889        False      False       False   \n",
       "abductive_nli_2       0.744444        False      False       False   \n",
       "abductive_nli_3       0.844444        False      False       False   \n",
       "abductive_nli_4       0.644444        False      False       False   \n",
       "...                        ...          ...        ...         ...   \n",
       "wsc_47                0.777778        False      False       False   \n",
       "wsc_48                0.544444        False      False       False   \n",
       "wsc_49                0.633333        False      False       False   \n",
       "wsc_50                0.311111        False      False       False   \n",
       "wsc_51                0.688889        False      False       False   \n",
       "\n",
       "                       dataset  \n",
       "abductive_nli_0  abductive_nli  \n",
       "abductive_nli_1  abductive_nli  \n",
       "abductive_nli_2  abductive_nli  \n",
       "abductive_nli_3  abductive_nli  \n",
       "abductive_nli_4  abductive_nli  \n",
       "...                        ...  \n",
       "wsc_47                     wsc  \n",
       "wsc_48                     wsc  \n",
       "wsc_49                     wsc  \n",
       "wsc_50                     wsc  \n",
       "wsc_51                     wsc  \n",
       "\n",
       "[82756 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude lower       0.857838\n",
      "upper       2.089375\n",
      "mean        1.368802\n",
      "var         0.108964\n",
      "log_mean    0.285911\n",
      "dtype: float64\n",
      "\n",
      "only lower       1.013472\n",
      "upper       2.422414\n",
      "mean        1.601511\n",
      "var         0.136384\n",
      "log_mean    0.457826\n",
      "dtype: float64\n",
      "\n",
      "only correct lower       0.610682\n",
      "upper       1.927486\n",
      "mean        1.128396\n",
      "var         0.121926\n",
      "log_mean    0.113834\n",
      "dtype: float64\n",
      "\n",
      "only wrong lower       1.077908\n",
      "upper       2.501590\n",
      "mean        1.677196\n",
      "var         0.138696\n",
      "log_mean    0.512855\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('exclude', param_plot_stats['a'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['a'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['a'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['a'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude lower       0.175066\n",
      "upper       0.422752\n",
      "mean        0.280274\n",
      "var         0.550505\n",
      "log_mean   -1.574811\n",
      "dtype: float64\n",
      "\n",
      "only lower       0.121289\n",
      "upper       0.213446\n",
      "mean        0.160410\n",
      "var         0.563151\n",
      "log_mean   -2.880551\n",
      "dtype: float64\n",
      "\n",
      "only correct lower       0.765192\n",
      "upper       0.968812\n",
      "mean        0.910426\n",
      "var         0.583914\n",
      "log_mean   -0.093919\n",
      "dtype: float64\n",
      "\n",
      "only wrong lower       0.018283\n",
      "upper       0.092608\n",
      "mean        0.040428\n",
      "var         0.559830\n",
      "log_mean   -3.326336\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('exclude', param_plot_stats['g'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['g'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['g'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['g'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([pcent_correct.reset_index(), task_name_format], axis=1)\n",
    "\n",
    "dataset2format = {'all':'all'}\n",
    "format2dataset = {'all':'all'}\n",
    "\n",
    "for dset in temp['dataset'].unique():\n",
    "    fmat = temp.loc[temp['dataset'] == dset, 'format'].unique()[0]\n",
    "    dataset2format[dset] = fmat\n",
    "    format2dataset[fmat] = dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial_nli\n"
     ]
    }
   ],
   "source": [
    "item_excludes = {}\n",
    "\n",
    "for dataset in pcent_correct['dataset'].unique():\n",
    "    temp = pcent_correct.loc[pcent_correct['dataset'] == dataset, :]\n",
    "    \n",
    "    try:\n",
    "        assert np.not_equal(temp.index.values, np.array(sorted(temp.index.values, key=lambda x: int(x.split('_')[-1])))).sum() == 0, dataset\n",
    "    except:\n",
    "        print(dataset)\n",
    "        pass\n",
    "    \n",
    "    item_excludes[dataset] = temp['all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['all_correct', 'all_wrong', 'all_either', 'dataset']\n",
    "grouped_pcent_correct = pcent_correct[keeps].groupby(by='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all_pcent = {}\n",
    "combined_all_count = {}\n",
    "\n",
    "for col in ['all_correct', 'all_wrong', 'all_either']:\n",
    "    combined_all_count[col] = pcent_correct[col].sum()\n",
    "    combined_all_pcent[col] = combined_all_count[col]/combined_responses.shape[1]\n",
    "    \n",
    "combined_all_count['total_count'] = combined_responses.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_pcent_either = grouped_pcent_correct.sum()/grouped_pcent_correct.count()\n",
    "summary_pcent = grouped_pcent_either.append(pd.DataFrame.from_dict({'all':combined_all_pcent}, orient='index'))\n",
    "\n",
    "grouped_count_either = grouped_pcent_correct.sum()\n",
    "grouped_count_either['total_count'] = grouped_pcent_correct.count()['all_either']\n",
    "summary_count = grouped_count_either.append(pd.DataFrame.from_dict({'all':combined_all_count}, orient='index'))\n",
    "\n",
    "\n",
    "summary_pcent['format'] = list(pd.Series(summary_pcent.index.values).apply(lambda x: dataset2format[x]))\n",
    "summary_count['format'] = list(pd.Series(summary_count.index.values).apply(lambda x: dataset2format[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adversarial_nli</th>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_easy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boolq</th>\n",
       "      <td>0.095413</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mctaco</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrqa_natural_questions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073076</td>\n",
       "      <td>0.073076</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsqa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161426</td>\n",
       "      <td>0.161426</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qamr</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snli</th>\n",
       "      <td>0.031759</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.033388</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squad_v2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>0.041181</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        all_correct  all_wrong  all_either          format\n",
       "adversarial_nli            0.000313   0.011875    0.012188  classification\n",
       "arc_easy                   0.000000   0.000421    0.000421          MC-par\n",
       "boolq                      0.095413   0.002446    0.097859          MC-par\n",
       "cosmosqa                   0.000000   0.002009    0.002009          MC-par\n",
       "hellaswag                  0.000000   0.000398    0.000398          MC-par\n",
       "mctaco                     0.000000   0.108108    0.108108         MC-sent\n",
       "mnli                       0.000102   0.000407    0.000509  classification\n",
       "mrqa_natural_questions     0.000000   0.073076    0.073076  span selection\n",
       "newsqa                     0.000000   0.161426    0.161426  span selection\n",
       "qamr                       0.000000   0.080714    0.080714  span selection\n",
       "quoref                     0.000000   0.026468    0.026468  span selection\n",
       "snli                       0.031759   0.001629    0.033388  classification\n",
       "squad_v2                   0.000000   0.002743    0.002743         MC-sent\n",
       "all                        0.005679   0.035502    0.041181             all"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_pcent.loc[summary_pcent['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>total_count</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adversarial_nli</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>3200</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_easy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2376</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boolq</th>\n",
       "      <td>156</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1635</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1493</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5021</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mctaco</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>1332</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9824</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrqa_natural_questions</th>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>6418</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsqa</th>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>4293</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qamr</th>\n",
       "      <td>0</td>\n",
       "      <td>1515</td>\n",
       "      <td>1515</td>\n",
       "      <td>18770</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1209</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snli</th>\n",
       "      <td>312</td>\n",
       "      <td>16</td>\n",
       "      <td>328</td>\n",
       "      <td>9824</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squad_v2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>6198</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>470</td>\n",
       "      <td>2938</td>\n",
       "      <td>3408</td>\n",
       "      <td>82757</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        all_correct  all_wrong  all_either  total_count  \\\n",
       "adversarial_nli                   1         38          39         3200   \n",
       "arc_easy                          0          1           1         2376   \n",
       "boolq                           156          4         160         1635   \n",
       "cosmosqa                          0          3           3         1493   \n",
       "hellaswag                         0          2           2         5021   \n",
       "mctaco                            0        144         144         1332   \n",
       "mnli                              1          4           5         9824   \n",
       "mrqa_natural_questions            0        469         469         6418   \n",
       "newsqa                            0        693         693         4293   \n",
       "qamr                              0       1515        1515        18770   \n",
       "quoref                            0         32          32         1209   \n",
       "snli                            312         16         328         9824   \n",
       "squad_v2                          0         17          17         6198   \n",
       "all                             470       2938        3408        82757   \n",
       "\n",
       "                                format  \n",
       "adversarial_nli         classification  \n",
       "arc_easy                        MC-par  \n",
       "boolq                           MC-par  \n",
       "cosmosqa                        MC-par  \n",
       "hellaswag                       MC-par  \n",
       "mctaco                         MC-sent  \n",
       "mnli                    classification  \n",
       "mrqa_natural_questions  span selection  \n",
       "newsqa                  span selection  \n",
       "qamr                    span selection  \n",
       "quoref                  span selection  \n",
       "snli                    classification  \n",
       "squad_v2                       MC-sent  \n",
       "all                                all  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_count.loc[summary_count['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_by_format = summary_count.groupby(by='format')\n",
    "summary_by_format = summary_by_format.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MC-par</th>\n",
       "      <td>156</td>\n",
       "      <td>10</td>\n",
       "      <td>166</td>\n",
       "      <td>17193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-sent</th>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>10853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>470</td>\n",
       "      <td>2938</td>\n",
       "      <td>3408</td>\n",
       "      <td>82757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>314</td>\n",
       "      <td>58</td>\n",
       "      <td>372</td>\n",
       "      <td>23015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span selection</th>\n",
       "      <td>0</td>\n",
       "      <td>2709</td>\n",
       "      <td>2709</td>\n",
       "      <td>30690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                all_correct  all_wrong  all_either  total_count\n",
       "format                                                         \n",
       "MC-par                  156         10         166        17193\n",
       "MC-sent                   0        161         161        10853\n",
       "all                     470       2938        3408        82757\n",
       "classification          314         58         372        23015\n",
       "span selection            0       2709        2709        30690"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_format.loc[summary_by_format['all_either'] > 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Break Down of All Either\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "format\n",
       "MC-par            0.048709\n",
       "MC-sent           0.047242\n",
       "all               1.000000\n",
       "classification    0.109155\n",
       "span selection    0.794894\n",
       "Name: all_either, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Break Down of All Either')\n",
    "summary_by_format['all_either']/summary_by_format.loc['all', 'all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of All Either by Task Format\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "format\n",
       "MC-par            0.009655\n",
       "MC-sent           0.014835\n",
       "all               0.041181\n",
       "classification    0.016163\n",
       "span selection    0.088270\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Breakdown of All Either by Task Format')\n",
    "summary_by_format['all_either']/summary_by_format['total_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','data')\n",
    "files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim Model Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_model_dir = os.path.join('..','data_trimmed_model')\n",
    "os.makedirs(trimmed_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_models = ['albert-xxlarge-v2', 'xlm-roberta-large', 'roberta-large', 'roberta-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    temp_models = temp['userid'].apply(lambda x:''.join(x.split('_')[:-1]))\n",
    "    \n",
    "    exclude_indexes = temp_models.eq(exclude_models[0])\n",
    "    for i in range(1,len(exclude_models)):\n",
    "        exclude_indexes = exclude_indexes + temp_models.eq(exclude_models[i])\n",
    "    \n",
    "    trimmed = temp.loc[~exclude_indexes, :]\n",
    "    \n",
    "    check = set(temp.loc[~exclude_indexes, :]['userid'].apply(lambda x:''.join(x.split('_')[:-1])).unique())\n",
    "    for model in exclude_models:\n",
    "        assert not model in check, f'{file}, {model}'\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_model_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim Item Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_item_dir = os.path.join('..','data_trimmed_item')\n",
    "os.makedirs(trimmed_item_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending = '_irt_all_coded.csv'\n",
    "\n",
    "for file in files:\n",
    "    dataset_name = '_'.join(file[:-len(ending)].split('-'))\n",
    "    if dataset_name == 'mrqa_nq':\n",
    "        dataset_name = 'mrqa_natural_questions'\n",
    "    \n",
    "    if not dataset_name in item_excludes.keys():\n",
    "        print(dataset_name)  \n",
    "    \n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    trimmed = temp.loc[:,~np.array([False] + list(item_excludes[dataset_name]))]\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_item_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LEH at BERT-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### From Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.8104567527770996\n",
      "No gamma: 0.15963196480051325\n",
      "With gamma: 0.12148421911600042\n",
      "           mean\n",
      "0      0.176043\n",
      "1      0.208972\n",
      "2      0.060574\n",
      "3      0.036004\n",
      "4      0.092786\n",
      "...         ...\n",
      "82751  0.094904\n",
      "82752  0.182747\n",
      "82753  0.141831\n",
      "82754  0.043311\n",
      "82755  0.055791\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    list(combined_responses['userid']),\n",
    "    gamma = param_plot_stats['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert = pd.DataFrame(pd.Series(leh_scores_bert), columns = ['mean'])\n",
    "print(leh_scores_plot_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### From Trimmed BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache_trimmed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir_trimmed = os.path.join(repo, 'params_trimmed_model', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir_trimmed, 'responses.p'), 'rb') as f:\n",
    "    combined_responses_trimmed = pickle.load(f).reset_index()\n",
    "data_trimmed, accuracies_trimmed, example_accuracies_trimmed = get_data_accuracies(combined_responses_trimmed)\n",
    "column_names_trimmed = combined_responses_trimmed.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache_trimmed:\n",
    "    param_plot_stats_trimmed = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats_trimmed[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats_trimmed = get_plot_stats(\n",
    "        exp_dir_trimmed,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = p\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles_trimmed_model', exist_ok=True)\n",
    "    for key, value in param_plot_stats_trimmed.items():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.9805275201797485\n",
      "No gamma: 0.1567958442231057\n",
      "With gamma: 0.12096604941079794\n",
      "           mean\n",
      "0      0.158494\n",
      "1      0.150325\n",
      "2      0.039995\n",
      "3      0.052717\n",
      "4      0.152572\n",
      "...         ...\n",
      "82751  0.084873\n",
      "82752  0.150056\n",
      "82753  0.117921\n",
      "82754  0.098012\n",
      "82755  0.059681\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert_trimmed = icc_best_deriv(\n",
    "    param_plot_stats_trimmed['a'],\n",
    "    param_plot_stats_trimmed['b'],\n",
    "    param_plot_stats_trimmed['t'],\n",
    "    list(combined_responses_trimmed['userid']),\n",
    "    gamma = param_plot_stats_trimmed['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert_trimmed = pd.DataFrame(pd.Series(leh_scores_bert_trimmed), columns = ['mean'])\n",
    "print(leh_scores_plot_bert_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "leh_bert_combined = pd.concat([leh_scores_plot_bert, leh_scores_plot_bert_trimmed], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.0005181697052024826\n",
      "std 0.059380400067841184\n",
      "median 0.0020297530195709183\n",
      "IQR 0.049340527744277426\n",
      "upper_whisker 0.09977841616189373\n",
      "lower_whisker -0.09758369481521596\n",
      "pcent above lower 0.04359804727149693\n",
      "pcent below lower 0.03825704480641887\n"
     ]
    }
   ],
   "source": [
    "diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])\n",
    "\n",
    "print('mean', diff.mean())\n",
    "print('std', diff.std())\n",
    "print('median', diff.median())\n",
    "\n",
    "IQR = diff.quantile(0.75) - diff.quantile(0.25)\n",
    "upper_whisker = diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (diff > upper_whisker).sum()/diff.shape[0])\n",
    "print('pcent below lower', (diff < lower_whisker).sum()/diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197540f39f09481796ef9f406e513b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14f5038a785454a9d8924ecf96727f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.07837129239456639\n",
      "std 0.5712089759066041\n",
      "median 0.025084227491001372\n",
      "IQR 0.5199853736242595\n",
      "upper_whisker 1.0685743083792318\n",
      "lower_whisker -1.0113671861178057\n",
      "pcent above lower 0.049615737831698\n",
      "pcent below lower 0.0\n"
     ]
    }
   ],
   "source": [
    "rel_diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])/leh_scores_plot_bert_trimmed['mean']\n",
    "\n",
    "print('mean', rel_diff.mean())\n",
    "print('std', rel_diff.std())\n",
    "print('median', rel_diff.median())\n",
    "\n",
    "IQR = rel_diff.quantile(0.75) - rel_diff.quantile(0.25)\n",
    "upper_whisker = rel_diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = rel_diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (rel_diff > upper_whisker).sum()/rel_diff.shape[0])\n",
    "print('pcent below lower', (rel_diff < lower_whisker).sum()/rel_diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3aeb534ff14b4d8f78c975f5339a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c16cefc19c479d90edc5a068cd9634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "font_label = 12\n",
    "font_legend = 10\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 12\n",
    "font_title = 14\n",
    "marker_scale = 1.5\n",
    "\n",
    "plot.rc('axes', labelsize=font_label)\n",
    "plot.rc('axes', titlesize=font_title)\n",
    "plot.rc('legend', fontsize=font_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_box(df, order, param_type, task_metadata, xsize=12, ysize=3, width=0.6, rotation=90, ylim=None, ystep=None):\n",
    "    \n",
    "    param2label = {\n",
    "        'discriminative':r'$\\log$ Discrimination ($\\log$ $\\alpha$)',\n",
    "        'difficulty': r'Difficulty ($\\beta$)',\n",
    "        \"disc-diff\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_pos\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_minmax\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"irt-score\": \"LEH Score\",\n",
    "    }\n",
    "    \n",
    "    param2yname = {\n",
    "        'discriminative': \"log_mean\",\n",
    "        'difficulty': \"mean\",\n",
    "        \"disc-diff\": 0,\n",
    "        \"disc-diff_pos\": 0,\n",
    "        \"disc-diff_minmax\": 0,\n",
    "        \"irt-score\": \"mean\",\n",
    "    }\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    f, ax = plot.subplots(figsize=(xsize, ysize))\n",
    "    \n",
    "    my_pal = {\"MC-par\": \"r\",\n",
    "              \"MC-sent\": \"b\",\n",
    "              \"classification\":\"g\",\n",
    "              \"span selection\": \"grey\"}    \n",
    "    \n",
    "    ax = sns.boxplot(x=\"task_name\", y=param2yname[param_type], data=df, order=order, width=width)\n",
    "    \n",
    "    for i, task in enumerate(order):\n",
    "        # Select which box you want to change    \n",
    "        mybox = ax.artists[i]\n",
    "        \n",
    "        # Change the appearance of that box\n",
    "        skill = task_metadata.loc[task]['format']\n",
    "        mybox.set_facecolor(my_pal[skill])\n",
    "    \n",
    "    # Add transparency to colors\n",
    "    for patch in ax.artists:\n",
    "         r, g, b, a = patch.get_facecolor()\n",
    "         patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "    sns.despine()\n",
    "    plot.xticks(range(len(order)), order, rotation=rotation, fontsize=font_xtick)\n",
    "    \n",
    "    if not ylim is None and not ystep is None:\n",
    "        plot.ylim(ylim)\n",
    "        plot.yticks(numpy.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    \n",
    "    plot.xlabel(None)\n",
    "    plot.ylabel(param2label[param_type], fontsize=font_label)\n",
    "    \n",
    "    return f\n",
    "#     plot.savefig('../plots/' + param_type + \"_box.png\",\n",
    "#                 format='png', dpi=300,\n",
    "#                 bbox_inches = 'tight',\n",
    "#                 pad_inches = .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.739129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.739129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      mean\n",
       "mean  1.000000  0.739129\n",
       "mean  0.739129  1.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_bert_combined.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot_bert = pd.concat([leh_scores_plot_bert, task_name_format], axis=1)\n",
    "leh_scores_plot_bert_trimmed = pd.concat([leh_scores_plot_bert_trimmed, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>task_name</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176043</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208972</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060574</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036004</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092786</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82751</th>\n",
       "      <td>0.094904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82752</th>\n",
       "      <td>0.182747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82753</th>\n",
       "      <td>0.141831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82754</th>\n",
       "      <td>0.043311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82755</th>\n",
       "      <td>0.055791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82756 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  task_name   format\n",
       "0      0.176043  AbductNLI  MC-sent\n",
       "1      0.208972  AbductNLI  MC-sent\n",
       "2      0.060574  AbductNLI  MC-sent\n",
       "3      0.036004  AbductNLI  MC-sent\n",
       "4      0.092786  AbductNLI  MC-sent\n",
       "...         ...        ...      ...\n",
       "82751  0.094904        NaN      NaN\n",
       "82752  0.182747        NaN      NaN\n",
       "82753  0.141831        NaN      NaN\n",
       "82754  0.043311        NaN      NaN\n",
       "82755  0.055791        NaN      NaN\n",
       "\n",
       "[82756 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_scores_plot_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7141af0ec040e7838514ba909749d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plot_box(\n",
    "    leh_scores_plot_bert,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "f.suptitle('All Models')\n",
    "f.savefig(os.path.join('..', 'plots_LEH_BERT', 'all_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6116e3526ec476b94af97871d441eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftrimmed = plot_box(\n",
    "    leh_scores_plot_bert_trimmed,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "ftrimmed.suptitle('MiniBERTas + BERT')\n",
    "ftrimmed.savefig(os.path.join('..', 'plots_LEH_BERT', 'trimmed_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "leh_tasks = pd.concat([\n",
    "    leh_scores_plot_bert.rename(columns={'mean':'Full'}),\n",
    "    pd.DataFrame(leh_scores_plot_bert_trimmed['mean']).rename(columns={'mean':'BERT'})\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.004662516241732889\n",
      "rel diff 0.027159661919406792\n"
     ]
    }
   ],
   "source": [
    "leh_tasks_qtile = leh_tasks.groupby(by='task_name').quantile(q=0.75)\n",
    "leh_tasks_qtile['diff'] = leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT']\n",
    "leh_tasks_qtile['rel_diff'] = (leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT'])/leh_tasks_qtile['BERT']\n",
    "\n",
    "print('diff', leh_tasks_qtile['diff'].median())\n",
    "print('rel diff', leh_tasks_qtile['rel_diff'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median diff (magnitude) 0.010413355061485552\n",
      "median rel diff (magnitude) 0.06581982948185636\n"
     ]
    }
   ],
   "source": [
    "print('median diff (magnitude)', leh_tasks_qtile['diff'].abs().median())\n",
    "print('median rel diff (magnitude)', leh_tasks_qtile['rel_diff'].abs().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>Up to BERT</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Relative Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.231662</td>\n",
       "      <td>-0.223760</td>\n",
       "      <td>-0.965891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.221559</td>\n",
       "      <td>-0.213656</td>\n",
       "      <td>-0.964329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.223147</td>\n",
       "      <td>-0.214825</td>\n",
       "      <td>-0.962706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.165677</td>\n",
       "      <td>0.183855</td>\n",
       "      <td>-0.018178</td>\n",
       "      <td>-0.098869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.098872</td>\n",
       "      <td>0.105602</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>-0.063725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.080718</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>-0.062757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.156625</td>\n",
       "      <td>0.162685</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-0.037246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.144227</td>\n",
       "      <td>0.146788</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>-0.017451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.140743</td>\n",
       "      <td>0.141083</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.177377</td>\n",
       "      <td>0.177229</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.157061</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.017516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.139638</td>\n",
       "      <td>0.137026</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.199047</td>\n",
       "      <td>0.195312</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.019122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.157568</td>\n",
       "      <td>0.153708</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>0.192580</td>\n",
       "      <td>0.187115</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.029207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.205817</td>\n",
       "      <td>0.196631</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.046721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.136394</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.051023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.123591</td>\n",
       "      <td>0.117422</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.052537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.183029</td>\n",
       "      <td>0.171389</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.067915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.191943</td>\n",
       "      <td>0.178365</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.076127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>0.249394</td>\n",
       "      <td>0.230511</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>0.081917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.171956</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.087441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.185164</td>\n",
       "      <td>0.168119</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.101384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.223206</td>\n",
       "      <td>0.201757</td>\n",
       "      <td>0.021449</td>\n",
       "      <td>0.106310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.191947</td>\n",
       "      <td>0.168858</td>\n",
       "      <td>0.023090</td>\n",
       "      <td>0.136742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.149266</td>\n",
       "      <td>0.129645</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.151343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>0.275583</td>\n",
       "      <td>0.235964</td>\n",
       "      <td>0.039619</td>\n",
       "      <td>0.167902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.215212</td>\n",
       "      <td>0.171353</td>\n",
       "      <td>0.043859</td>\n",
       "      <td>0.255957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full  Up to BERT  Difference  Relative Difference\n",
       "task_name                                                        \n",
       "WiC         0.007902    0.231662   -0.223760            -0.965891\n",
       "Winogrande  0.007903    0.221559   -0.213656            -0.964329\n",
       "WSC         0.008322    0.223147   -0.214825            -0.962706\n",
       "ARC-C       0.165677    0.183855   -0.018178            -0.098869\n",
       "CB          0.098872    0.105602   -0.006729            -0.063725\n",
       "SNLI        0.080718    0.086122   -0.005405            -0.062757\n",
       "ANLI        0.156625    0.162685   -0.006059            -0.037246\n",
       "PiQA        0.144227    0.146788   -0.002562            -0.017451\n",
       "COPA        0.140743    0.141083   -0.000340            -0.002408\n",
       "MC-TACO     0.177377    0.177229    0.000148             0.000838\n",
       "ARCT        0.159812    0.157061    0.002751             0.017516\n",
       "MNLI        0.139638    0.137026    0.002612             0.019059\n",
       "ARC-E       0.199047    0.195312    0.003735             0.019122\n",
       "RTE         0.157568    0.153708    0.003860             0.025112\n",
       "MRQA-NQ     0.192580    0.187115    0.005465             0.029207\n",
       "QAMR        0.205817    0.196631    0.009187             0.046721\n",
       "MCScript    0.136394    0.129773    0.006621             0.051023\n",
       "BoolQ       0.123591    0.117422    0.006169             0.052537\n",
       "QuAIL       0.183029    0.171389    0.011640             0.067915\n",
       "MuTual+     0.191943    0.178365    0.013578             0.076127\n",
       "NewsQA      0.249394    0.230511    0.018883             0.081917\n",
       "CosmosQA    0.186992    0.171956    0.015036             0.087441\n",
       "SocialIQA   0.185164    0.168119    0.017045             0.101384\n",
       "CSQA        0.223206    0.201757    0.021449             0.106310\n",
       "MuTual      0.191947    0.168858    0.023090             0.136742\n",
       "AbductNLI   0.149266    0.129645    0.019621             0.151343\n",
       "Quoref      0.275583    0.235964    0.039619             0.167902\n",
       "HellaSwag   0.215212    0.171353    0.043859             0.255957"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.rename(columns={'BERT':'Up to BERT', 'diff':'Difference', 'rel_diff':'Relative Difference'}).sort_values(by='Relative Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>BERT</th>\n",
       "      <th>diff</th>\n",
       "      <th>rel_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.156625</td>\n",
       "      <td>0.162685</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>-0.037246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.165677</td>\n",
       "      <td>0.183855</td>\n",
       "      <td>-0.018178</td>\n",
       "      <td>-0.098869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.098872</td>\n",
       "      <td>0.105602</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>-0.063725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.140743</td>\n",
       "      <td>0.141083</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.144227</td>\n",
       "      <td>0.146788</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>-0.017451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.080718</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>-0.062757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.223147</td>\n",
       "      <td>-0.214825</td>\n",
       "      <td>-0.962706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.231662</td>\n",
       "      <td>-0.223760</td>\n",
       "      <td>-0.965891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.221559</td>\n",
       "      <td>-0.213656</td>\n",
       "      <td>-0.964329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full      BERT      diff  rel_diff\n",
       "task_name                                         \n",
       "ANLI        0.156625  0.162685 -0.006059 -0.037246\n",
       "ARC-C       0.165677  0.183855 -0.018178 -0.098869\n",
       "CB          0.098872  0.105602 -0.006729 -0.063725\n",
       "COPA        0.140743  0.141083 -0.000340 -0.002408\n",
       "PiQA        0.144227  0.146788 -0.002562 -0.017451\n",
       "SNLI        0.080718  0.086122 -0.005405 -0.062757\n",
       "WSC         0.008322  0.223147 -0.214825 -0.962706\n",
       "WiC         0.007902  0.231662 -0.223760 -0.965891\n",
       "Winogrande  0.007903  0.221559 -0.213656 -0.964329"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.loc[leh_tasks_qtile['diff'] < 0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
