{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle5 as pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+torch.exp(-x))\n",
    "\n",
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean', target=None):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    if target:\n",
    "        idx = model_names.index(target)\n",
    "        best_value = theta[col].iloc[idx]\n",
    "        print('Local Grad for Target Model')\n",
    "        print(f'Target model: {target}\\n{best_value}')\n",
    "    else:\n",
    "        best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "        print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col].values), torch.tensor(beta[col].values)\n",
    "    \n",
    "    logits = (a*(best_value-b))\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = sigmoids*(1.-sigmoids)*a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g)*scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model_guide(alpha_dist, theta_dist, alpha_transform, theta_transform):\n",
    "    model = lambda obs: irt_model(obs, alpha_dist, theta_dist, alpha_transform = alpha_transform, theta_transform = theta_transform)\n",
    "    guide = lambda obs: vi_posterior(obs, alpha_dist, theta_dist)\n",
    "    \n",
    "    return model, guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data_accuracies(data, verbose = False, get_cols = False):\n",
    "    '''\n",
    "    Method to reformat `data` and calculate item and responder accuracies.\n",
    "    \n",
    "    Args:\n",
    "        data:                DataFrame of item responses.\n",
    "        verbose:             Boolean value of whether to print statements.\n",
    "        get_cols:            Boolean value of whether to return original column\n",
    "                             values of `data`.\n",
    "        \n",
    "    Returns:\n",
    "        new_data:            Reformatted `data`, dropping first column.\n",
    "        accuracies:          Accuracy for each responder across examples.\n",
    "        example_accuracies:  Accuracy for each example across responders.\n",
    "        data.columns.values: Returns only if `get_cols` is True. Original column\n",
    "                             values of `data`.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    new_data = new_data[:,1:]\n",
    "    \n",
    "    model_names = dict(data['userid'])\n",
    "    accuracies = new_data.mean(-1)\n",
    "    example_accuracies = new_data.mean(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'.join([f'{name}: {acc}' for name, acc in zip(model_names.values(),accuracies)]))\n",
    "    \n",
    "    if get_cols:\n",
    "        return new_data, accuracies, example_accuracies, data.columns.values\n",
    "    else:\n",
    "        return new_data, accuracies, example_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_stats_CI(params, p=0.95, dist='normal'):\n",
    "    '''\n",
    "    Method to calculate lower and upper quantiles defined by `p`, mean, and variance of `param`\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of distribution parameters for each item keyed according to the \n",
    "                parametric distribution defined by `dist`.\n",
    "        p:      Percent of distribution covered by the lower and upper interval values for each\n",
    "                parameter.\n",
    "        dist:   Name of parametric distribution\n",
    "    \n",
    "    Returns:\n",
    "        return: {\n",
    "            'lower': Lower interval values of each parameter,\n",
    "            'upper': Upper interval values of each parameter,\n",
    "            'mean' : Mean of each parameter,\n",
    "            'var'  : Variance of each parameter\n",
    "        }\n",
    "    '''\n",
    "    stats = {}\n",
    "    if dist == 'normal':\n",
    "        L,U = scipy.stats.norm.interval(p,loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "        M,V = scipy.stats.norm.stats(loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "    elif dist == 'log-normal':\n",
    "        L,U = scipy.stats.lognorm.interval(p, s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "        M,V = scipy.stats.lognorm.stats(s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "    elif dist == 'beta':\n",
    "        L,U = scipy.stats.beta.interval(p,a=params['alpha'], b=params['beta'])\n",
    "        M,V = scipy.stats.beta.stats(a=params['alpha'], b=params['beta'])\n",
    "    else:\n",
    "        raise TypeError(f'Distribution type {dist} not supported.')\n",
    "    \n",
    "    return {\n",
    "        'lower':[L],\n",
    "        'upper':[U],\n",
    "        'mean':[M],\n",
    "        'var':[V],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_plot_stats(exp_dir, alpha_dist, theta_dist, transforms, p = 0.95):\n",
    "    '''\n",
    "    Method to return plotting statistics for 3 parameter IRT model parameters.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir:          Path to 3 parameter IRT parameters and responses.\n",
    "        alpha_dist:       Name of the item discrimination [a] distribution.\n",
    "        theta_dist:       Name of the responder ability [t] distribution.\n",
    "        transforms:       Dictionary of transformations to apply to each parameter type\n",
    "                          where keys are parameter names and values are functions.\n",
    "        p:                Percent of distribution covered by the lower and upper interval \n",
    "                          values for each parameter.\n",
    "    \n",
    "    Returns:\n",
    "        param_plot_stats: Dictionary of parameter plot statistics where keys are parameter\n",
    "                          names and values are plot statistics dictionaries as defined by\n",
    "                          get_stats_CI().\n",
    "    '''\n",
    "    param_dists = {\n",
    "        'a':alpha_dist,\n",
    "        'b':'normal',\n",
    "        'g':'normal',\n",
    "        't':theta_dist,\n",
    "    }\n",
    "\n",
    "    dist_params = {\n",
    "        'normal':['mu', 'logstd'],\n",
    "        'log-normal':['mu', 'logstd'],\n",
    "        'beta':['alpha', 'beta'],\n",
    "    }\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(os.path.join(exp_dir, 'params.p'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    # get stats for plotting\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for param, param_dist in param_dists.items():\n",
    "        temp_params = dist_params[param_dist]\n",
    "\n",
    "        for idx, (p1_orig, p2_orig) in enumerate(zip(pyro_param_dict[f'{param} {temp_params[0]}'], pyro_param_dict[f'{param} {temp_params[1]}'])):\n",
    "            p1, p2 = p1_orig.detach(), p2_orig.detach()\n",
    "            \n",
    "            temp_stats_df = pd.DataFrame.from_dict(\n",
    "                get_stats_CI(\n",
    "                    params = {\n",
    "                        temp_params[0]:p1,\n",
    "                        temp_params[1]:p2,\n",
    "                    },\n",
    "                    p=p,\n",
    "                    dist = param_dist,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            temp_stats_df = temp_stats_df.applymap(transforms[param])\n",
    "        \n",
    "            if idx == 0:\n",
    "                param_plot_stats[param] = temp_stats_df\n",
    "            else:\n",
    "                param_plot_stats[param] = param_plot_stats[param].append(temp_stats_df, ignore_index = True)\n",
    "    \n",
    "    return param_plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sign_mult(df1, df2):\n",
    "    newdf = copy.deepcopy(df2)\n",
    "    \n",
    "    for idx, row in df1.iterrows():\n",
    "        if numpy.sign(row['mean']) < 0:\n",
    "            newdf.loc[idx,'mean'] = -1*newdf.loc[idx,'mean']\n",
    "            newdf.loc[idx,'lower'] = -1*newdf.loc[idx,'upper']\n",
    "            newdf.loc[idx,'upper'] = -1*newdf.loc[idx,'lower']\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_diff_by_set(diffs, item_ids):\n",
    "    diff_by_set = {}\n",
    "    id_split = '_'\n",
    "\n",
    "    max_diff = -1e6\n",
    "    min_diff = 1e6\n",
    "    \n",
    "    for idx, diff in enumerate(diffs):\n",
    "        set_name = item_ids[idx].split(id_split)[0]\n",
    "\n",
    "        if set_name in diff_by_set.keys():\n",
    "            diff_by_set[set_name].append(diff)\n",
    "        else:\n",
    "            diff_by_set[set_name] = [diff]\n",
    "            \n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            \n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "    \n",
    "    return diff_by_set, min_diff, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_irt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,adversarial-nli,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad-v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large_best\n",
      "==========================================================================================\n",
      "Overall acc: 0.7421\n",
      "abductive_nli acc: 0.8564\n",
      "adversarial_nli acc: 0.4938\n",
      "arc_challenge acc: 0.3319\n",
      "arc_easy acc: 0.6296\n",
      "arct acc: 0.8604\n",
      "boolq acc: 0.8367\n",
      "cb acc: 0.8571\n",
      "commonsenseqa acc: 0.6759\n",
      "copa acc: 0.8400\n",
      "cosmosqa acc: 0.7984\n",
      "hellaswag acc: 0.8417\n",
      "mcscript acc: 0.9183\n",
      "mctaco acc: 0.5360\n",
      "mnli acc: 0.8991\n",
      "mrqa_natural_questions acc: 0.6941\n",
      "mutual_plus acc: 0.7314\n",
      "mutual acc: 0.8668\n",
      "newsqa acc: 0.5542\n",
      "piqa acc: 0.7617\n",
      "qamr acc: 0.7303\n",
      "quail acc: 0.6691\n",
      "quoref acc: 0.8023\n",
      "rte acc: 0.8345\n",
      "snli acc: 0.9203\n",
      "socialiqa acc: 0.7738\n",
      "squad_v2 acc: 0.4301\n",
      "wic acc: 0.7085\n",
      "winogrande acc: 0.7697\n",
      "wsc acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()\n",
    "data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles', exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <th>abductive_nli_5</th>\n",
       "      <th>abductive_nli_6</th>\n",
       "      <th>abductive_nli_7</th>\n",
       "      <th>abductive_nli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>wsc_42</th>\n",
       "      <th>wsc_43</th>\n",
       "      <th>wsc_44</th>\n",
       "      <th>wsc_45</th>\n",
       "      <th>wsc_46</th>\n",
       "      <th>wsc_47</th>\n",
       "      <th>wsc_48</th>\n",
       "      <th>wsc_49</th>\n",
       "      <th>wsc_50</th>\n",
       "      <th>wsc_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 82234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  abductive_nli_0  abductive_nli_1  \\\n",
       "0   roberta-base-10M-1_best                1                0   \n",
       "1      roberta-base-10M-1_1                0                0   \n",
       "2     roberta-base-10M-1_25                1                1   \n",
       "3     roberta-base-10M-1_50                1                0   \n",
       "4     roberta-base-10M-1_10                1                0   \n",
       "..                      ...              ...              ...   \n",
       "85   xlm-roberta-large_best                1                1   \n",
       "86      xlm-roberta-large_1                1                1   \n",
       "87     xlm-roberta-large_25                1                1   \n",
       "88     xlm-roberta-large_50                1                1   \n",
       "89     xlm-roberta-large_10                0                1   \n",
       "\n",
       "    abductive_nli_2  abductive_nli_3  abductive_nli_4  abductive_nli_5  \\\n",
       "0                 1                1                1                1   \n",
       "1                 0                1                1                0   \n",
       "2                 1                1                1                1   \n",
       "3                 1                1                1                1   \n",
       "4                 1                1                1                1   \n",
       "..              ...              ...              ...              ...   \n",
       "85                0                1                1                1   \n",
       "86                0                1                1                0   \n",
       "87                0                1                1                1   \n",
       "88                1                1                1                1   \n",
       "89                0                1                1                0   \n",
       "\n",
       "    abductive_nli_6  abductive_nli_7  abductive_nli_8  ...  wsc_42  wsc_43  \\\n",
       "0                 1                0                1  ...       1       0   \n",
       "1                 1                0                1  ...       1       0   \n",
       "2                 1                1                1  ...       0       0   \n",
       "3                 1                0                1  ...       1       0   \n",
       "4                 1                0                1  ...       1       0   \n",
       "..              ...              ...              ...  ...     ...     ...   \n",
       "85                1                1                1  ...       1       1   \n",
       "86                1                0                1  ...       0       0   \n",
       "87                0                1                1  ...       1       1   \n",
       "88                1                1                1  ...       1       1   \n",
       "89                0                1                1  ...       0       0   \n",
       "\n",
       "    wsc_44  wsc_45  wsc_46  wsc_47  wsc_48  wsc_49  wsc_50  wsc_51  \n",
       "0        1       1       0       1       0       1       0       1  \n",
       "1        1       0       0       1       0       0       0       1  \n",
       "2        0       1       0       1       1       1       1       1  \n",
       "3        0       1       0       1       1       1       0       1  \n",
       "4        0       1       0       1       1       1       0       1  \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "85       0       1       0       1       1       1       0       0  \n",
       "86       1       0       1       0       0       0       1       1  \n",
       "87       0       1       0       1       1       1       0       0  \n",
       "88       0       1       0       1       1       1       0       0  \n",
       "89       1       0       1       0       0       0       1       1  \n",
       "\n",
       "[90 rows x 82234 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 36860\n",
      "g 0\n",
      "t 49\n"
     ]
    }
   ],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats.items():\n",
    "    param_stat['log_mean'] = numpy.log(param_stat['mean'])\n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "param_b = pd.concat([param_plot_stats['b'], task_name_format], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: albert-xxlarge-v2\n",
      "1.582378625869751\n",
      "No gamma: 0.14226206233809993\n",
      "With gamma: 0.11365353401378116\n",
      "           mean\n",
      "0      0.193985\n",
      "1      0.178925\n",
      "2      0.057262\n",
      "3      0.014374\n",
      "4      0.105861\n",
      "...         ...\n",
      "82228  0.059020\n",
      "82229  0.123432\n",
      "82230  0.083337\n",
      "82231  0.107942\n",
      "82232  0.082005\n",
      "\n",
      "[82233 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats['g'],\n",
    ")\n",
    "\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot = pd.concat([leh_scores_plot, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>task_name</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193985</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178925</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057262</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014374</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105861</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82228</th>\n",
       "      <td>0.059020</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82229</th>\n",
       "      <td>0.123432</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82230</th>\n",
       "      <td>0.083337</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82231</th>\n",
       "      <td>0.107942</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82232</th>\n",
       "      <td>0.082005</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82233 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  task_name   format\n",
       "0      0.193985  AbductNLI  MC-sent\n",
       "1      0.178925  AbductNLI  MC-sent\n",
       "2      0.057262  AbductNLI  MC-sent\n",
       "3      0.014374  AbductNLI  MC-sent\n",
       "4      0.105861  AbductNLI  MC-sent\n",
       "...         ...        ...      ...\n",
       "82228  0.059020        WSC  MC-sent\n",
       "82229  0.123432        WSC  MC-sent\n",
       "82230  0.083337        WSC  MC-sent\n",
       "82231  0.107942        WSC  MC-sent\n",
       "82232  0.082005        WSC  MC-sent\n",
       "\n",
       "[82233 rows x 3 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_75 = leh_scores_plot.groupby(by='task_name').quantile(q=0.75).reset_index()\n",
    "\n",
    "with open(os.path.join('plot_stats_pickles', f'LEH_75qtile.p'), 'wb') as f:\n",
    "    pickle.dump(leh_75, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Follow-ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## % all incorrect/correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcent_correct = pd.DataFrame(\n",
    "    combined_responses.iloc[:,1:].sum(axis=0)/combined_responses.shape[0], columns=['pcent_correct']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcent_correct['all_correct'] = pcent_correct['pcent_correct'].eq(1)\n",
    "pcent_correct['all_wrong'] = pcent_correct['pcent_correct'].eq(0)\n",
    "pcent_correct['all_either'] = pcent_correct['all_correct'] + pcent_correct['all_wrong']\n",
    "pcent_correct['dataset'] = list(pd.Series(pcent_correct.index.values).apply(lambda x: '_'.join(x.split('_')[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('exclude', param_plot_stats['a'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['a'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['a'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['a'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('exclude', param_plot_stats['g'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['g'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['g'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['g'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = pd.concat([pcent_correct.reset_index(), task_name_format], axis=1)\n",
    "\n",
    "dataset2format = {'all':'all'}\n",
    "format2dataset = {'all':'all'}\n",
    "\n",
    "for dset in temp['dataset'].unique():\n",
    "    fmat = temp.loc[temp['dataset'] == dset, 'format'].unique()[0]\n",
    "    dataset2format[dset] = fmat\n",
    "    format2dataset[fmat] = dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item_excludes = {}\n",
    "\n",
    "for dataset in pcent_correct['dataset'].unique():\n",
    "    temp = pcent_correct.loc[pcent_correct['dataset'] == dataset, :]\n",
    "    \n",
    "    try:\n",
    "        assert np.not_equal(temp.index.values, np.array(sorted(temp.index.values, key=lambda x: int(x.split('_')[-1])))).sum() == 0, dataset\n",
    "    except:\n",
    "        print(dataset)\n",
    "        pass\n",
    "    \n",
    "    item_excludes[dataset] = temp['all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keeps = ['all_correct', 'all_wrong', 'all_either', 'dataset']\n",
    "grouped_pcent_correct = pcent_correct[keeps].groupby(by='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined_all_pcent = {}\n",
    "combined_all_count = {}\n",
    "\n",
    "for col in ['all_correct', 'all_wrong', 'all_either']:\n",
    "    combined_all_count[col] = pcent_correct[col].sum()\n",
    "    combined_all_pcent[col] = combined_all_count[col]/combined_responses.shape[1]\n",
    "    \n",
    "combined_all_count['total_count'] = combined_responses.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_pcent_either = grouped_pcent_correct.sum()/grouped_pcent_correct.count()\n",
    "summary_pcent = grouped_pcent_either.append(pd.DataFrame.from_dict({'all':combined_all_pcent}, orient='index'))\n",
    "\n",
    "grouped_count_either = grouped_pcent_correct.sum()\n",
    "grouped_count_either['total_count'] = grouped_pcent_correct.count()['all_either']\n",
    "summary_count = grouped_count_either.append(pd.DataFrame.from_dict({'all':combined_all_count}, orient='index'))\n",
    "\n",
    "\n",
    "summary_pcent['format'] = list(pd.Series(summary_pcent.index.values).apply(lambda x: dataset2format[x]))\n",
    "summary_count['format'] = list(pd.Series(summary_count.index.values).apply(lambda x: dataset2format[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_pcent.loc[summary_pcent['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_count.loc[summary_count['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_by_format = summary_count.groupby(by='format')\n",
    "summary_by_format = summary_by_format.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_by_format.loc[summary_by_format['all_either'] > 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Break Down of All Either')\n",
    "summary_by_format['all_either']/summary_by_format.loc['all', 'all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Breakdown of All Either by Task Format')\n",
    "summary_by_format['all_either']/summary_by_format['total_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Trim Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','data')\n",
    "files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Trim Model Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trimmed_model_dir = os.path.join('..','data_trimmed_model')\n",
    "os.makedirs(trimmed_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exclude_models = ['albert-xxlarge-v2', 'xlm-roberta-large', 'roberta-large', 'roberta-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    temp_models = temp['userid'].apply(lambda x:''.join(x.split('_')[:-1]))\n",
    "    \n",
    "    exclude_indexes = temp_models.eq(exclude_models[0])\n",
    "    for i in range(1,len(exclude_models)):\n",
    "        exclude_indexes = exclude_indexes + temp_models.eq(exclude_models[i])\n",
    "    \n",
    "    trimmed = temp.loc[~exclude_indexes, :]\n",
    "    \n",
    "    check = set(temp.loc[~exclude_indexes, :]['userid'].apply(lambda x:''.join(x.split('_')[:-1])).unique())\n",
    "    for model in exclude_models:\n",
    "        assert not model in check, f'{file}, {model}'\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_model_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Trim Item Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trimmed_item_dir = os.path.join('..','data_trimmed_item')\n",
    "os.makedirs(trimmed_item_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ending = '_irt_all_coded.csv'\n",
    "\n",
    "for file in files:\n",
    "    dataset_name = '_'.join(file[:-len(ending)].split('-'))\n",
    "    if dataset_name == 'mrqa_nq':\n",
    "        dataset_name = 'mrqa_natural_questions'\n",
    "    \n",
    "    if not dataset_name in item_excludes.keys():\n",
    "        print(dataset_name)  \n",
    "    \n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    trimmed = temp.loc[:,~np.array([False] + list(item_excludes[dataset_name]))]\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_item_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEH at BERT-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.7179280519485474\n",
      "No gamma: 0.15662000563206477\n",
      "With gamma: 0.12033600391590196\n",
      "           mean\n",
      "0      0.173203\n",
      "1      0.169138\n",
      "2      0.056116\n",
      "3      0.046104\n",
      "4      0.129236\n",
      "...         ...\n",
      "82228  0.087480\n",
      "82229  0.152120\n",
      "82230  0.120044\n",
      "82231  0.037668\n",
      "82232  0.050374\n",
      "\n",
      "[82233 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    list(combined_responses['userid']),\n",
    "    gamma = param_plot_stats['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert = pd.DataFrame(pd.Series(leh_scores_bert), columns = ['mean'])\n",
    "print(leh_scores_plot_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Trimmed BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache_trimmed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir_trimmed = os.path.join(repo, 'params_trimmed_model', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir_trimmed, 'responses.p'), 'rb') as f:\n",
    "    combined_responses_trimmed = pickle.load(f).reset_index()\n",
    "data_trimmed, accuracies_trimmed, example_accuracies_trimmed = get_data_accuracies(combined_responses_trimmed)\n",
    "column_names_trimmed = combined_responses_trimmed.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache_trimmed:\n",
    "    param_plot_stats_trimmed = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats_trimmed[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats_trimmed = get_plot_stats(\n",
    "        exp_dir_trimmed,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = p\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles_trimmed_model', exist_ok=True)\n",
    "    for key, value in param_plot_stats_trimmed.items():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.9205797910690308\n",
      "No gamma: 0.15686171258458687\n",
      "With gamma: 0.12112190022703949\n",
      "           mean\n",
      "0      0.155609\n",
      "1      0.131961\n",
      "2      0.056406\n",
      "3      0.058805\n",
      "4      0.128713\n",
      "...         ...\n",
      "82228  0.097181\n",
      "82229  0.166697\n",
      "82230  0.142921\n",
      "82231  0.122178\n",
      "82232  0.069321\n",
      "\n",
      "[82233 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert_trimmed = icc_best_deriv(\n",
    "    param_plot_stats_trimmed['a'],\n",
    "    param_plot_stats_trimmed['b'],\n",
    "    param_plot_stats_trimmed['t'],\n",
    "    list(combined_responses_trimmed['userid']),\n",
    "    gamma = param_plot_stats_trimmed['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert_trimmed = pd.DataFrame(pd.Series(leh_scores_bert_trimmed), columns = ['mean'])\n",
    "print(leh_scores_plot_bert_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_bert_combined = pd.concat([leh_scores_plot_bert, leh_scores_plot_bert_trimmed], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean -0.0007858963111375089\n",
      "std 0.04295326081138878\n",
      "median -0.0017299276058100402\n",
      "IQR 0.04448709300453024\n",
      "upper_whisker 0.08537090195616145\n",
      "lower_whisker -0.09257747006195952\n",
      "pcent above lower 0.040166356572179054\n",
      "pcent below lower 0.011394452348813736\n"
     ]
    }
   ],
   "source": [
    "diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])\n",
    "\n",
    "print('mean', diff.mean())\n",
    "print('std', diff.std())\n",
    "print('median', diff.median())\n",
    "\n",
    "IQR = diff.quantile(0.75) - diff.quantile(0.25)\n",
    "upper_whisker = diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (diff > upper_whisker).sum()/diff.shape[0])\n",
    "print('pcent below lower', (diff < lower_whisker).sum()/diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.04818176671356783\n",
      "std 0.48766134206164674\n",
      "median -0.020584120997042255\n",
      "IQR 0.45042455248578395\n",
      "upper_whisker 0.8926601474803466\n",
      "lower_whisker -0.9090380624627892\n",
      "pcent above lower 0.05154864835285104\n",
      "pcent below lower 3.6481704425230744e-05\n"
     ]
    }
   ],
   "source": [
    "rel_diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])/leh_scores_plot_bert_trimmed['mean']\n",
    "\n",
    "print('mean', rel_diff.mean())\n",
    "print('std', rel_diff.std())\n",
    "print('median', rel_diff.median())\n",
    "\n",
    "IQR = rel_diff.quantile(0.75) - rel_diff.quantile(0.25)\n",
    "upper_whisker = rel_diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = rel_diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (rel_diff > upper_whisker).sum()/rel_diff.shape[0])\n",
    "print('pcent below lower', (rel_diff < lower_whisker).sum()/rel_diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_label = 12\n",
    "font_legend = 10\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 12\n",
    "font_title = 14\n",
    "marker_scale = 1.5\n",
    "\n",
    "plot.rc('axes', labelsize=font_label)\n",
    "plot.rc('axes', titlesize=font_title)\n",
    "plot.rc('legend', fontsize=font_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, order, param_type, task_metadata, xsize=12, ysize=3, width=0.6, rotation=90, ylim=None, ystep=None):\n",
    "    \n",
    "    param2label = {\n",
    "        'discriminative':r'$\\log$ Discrimination ($\\log$ $\\alpha$)',\n",
    "        'difficulty': r'Difficulty ($\\beta$)',\n",
    "        \"disc-diff\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_pos\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_minmax\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"irt-score\": \"LEH Score\",\n",
    "    }\n",
    "    \n",
    "    param2yname = {\n",
    "        'discriminative': \"log_mean\",\n",
    "        'difficulty': \"mean\",\n",
    "        \"disc-diff\": 0,\n",
    "        \"disc-diff_pos\": 0,\n",
    "        \"disc-diff_minmax\": 0,\n",
    "        \"irt-score\": \"mean\",\n",
    "    }\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    f, ax = plot.subplots(figsize=(xsize, ysize))\n",
    "    \n",
    "    my_pal = {\"MC-par\": \"r\",\n",
    "              \"MC-sent\": \"b\",\n",
    "              \"classification\":\"g\",\n",
    "              \"span selection\": \"grey\"}    \n",
    "    \n",
    "    ax = sns.boxplot(x=\"task_name\", y=param2yname[param_type], data=df, order=order, width=width)\n",
    "    \n",
    "    for i, task in enumerate(order):\n",
    "        # Select which box you want to change    \n",
    "        mybox = ax.artists[i]\n",
    "        \n",
    "        # Change the appearance of that box\n",
    "        skill = task_metadata.loc[task]['format']\n",
    "        mybox.set_facecolor(my_pal[skill])\n",
    "    \n",
    "    # Add transparency to colors\n",
    "    for patch in ax.artists:\n",
    "         r, g, b, a = patch.get_facecolor()\n",
    "         patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "    sns.despine()\n",
    "    plot.xticks(range(len(order)), order, rotation=rotation, fontsize=font_xtick)\n",
    "    \n",
    "    if not ylim is None and not ystep is None:\n",
    "        plot.ylim(ylim)\n",
    "        plot.yticks(numpy.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    \n",
    "    plot.xlabel(None)\n",
    "    plot.ylabel(param2label[param_type], fontsize=font_label)\n",
    "    \n",
    "    return f\n",
    "#     plot.savefig('../plots/' + param_type + \"_box.png\",\n",
    "#                 format='png', dpi=300,\n",
    "#                 bbox_inches = 'tight',\n",
    "#                 pad_inches = .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.851996</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      mean\n",
       "mean  1.000000  0.851996\n",
       "mean  0.851996  1.000000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_bert_combined.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot_bert = pd.concat([leh_scores_plot_bert, task_name_format], axis=1)\n",
    "leh_scores_plot_bert_trimmed = pd.concat([leh_scores_plot_bert_trimmed, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>task_name</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173203</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.169138</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056116</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046104</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129236</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82228</th>\n",
       "      <td>0.087480</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82229</th>\n",
       "      <td>0.152120</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82230</th>\n",
       "      <td>0.120044</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82231</th>\n",
       "      <td>0.037668</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82232</th>\n",
       "      <td>0.050374</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82233 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  task_name   format\n",
       "0      0.173203  AbductNLI  MC-sent\n",
       "1      0.169138  AbductNLI  MC-sent\n",
       "2      0.056116  AbductNLI  MC-sent\n",
       "3      0.046104  AbductNLI  MC-sent\n",
       "4      0.129236  AbductNLI  MC-sent\n",
       "...         ...        ...      ...\n",
       "82228  0.087480        WSC  MC-sent\n",
       "82229  0.152120        WSC  MC-sent\n",
       "82230  0.120044        WSC  MC-sent\n",
       "82231  0.037668        WSC  MC-sent\n",
       "82232  0.050374        WSC  MC-sent\n",
       "\n",
       "[82233 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_scores_plot_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plot_box(\n",
    "    leh_scores_plot_bert,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "f.suptitle('All Models')\n",
    "f.savefig(os.path.join('..', 'plots_LEH_BERT', 'all_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftrimmed = plot_box(\n",
    "    leh_scores_plot_bert_trimmed,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "ftrimmed.suptitle('MiniBERTas + BERT')\n",
    "ftrimmed.savefig(os.path.join('..', 'plots_LEH_BERT', 'trimmed_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_tasks = pd.concat([\n",
    "    leh_scores_plot_bert.rename(columns={'mean':'Full'}),\n",
    "    pd.DataFrame(leh_scores_plot_bert_trimmed['mean']).rename(columns={'mean':'BERT'})\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.0004319164170291101\n",
      "rel diff 0.003139606438779691\n"
     ]
    }
   ],
   "source": [
    "leh_tasks_qtile = leh_tasks.groupby(by='task_name').quantile(q=0.75)\n",
    "leh_tasks_qtile['diff'] = leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT']\n",
    "leh_tasks_qtile['rel_diff'] = (leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT'])/leh_tasks_qtile['BERT']\n",
    "\n",
    "print('diff', leh_tasks_qtile['diff'].median())\n",
    "print('rel diff', leh_tasks_qtile['rel_diff'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median diff (magnitude) 0.007062470129307899\n",
      "median rel diff (magnitude) 0.045879653921333696\n"
     ]
    }
   ],
   "source": [
    "print('median diff (magnitude)', leh_tasks_qtile['diff'].abs().median())\n",
    "print('median rel diff (magnitude)', leh_tasks_qtile['rel_diff'].abs().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>Up to BERT</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Relative Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.156865</td>\n",
       "      <td>0.182751</td>\n",
       "      <td>-0.025886</td>\n",
       "      <td>-0.141647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.120486</td>\n",
       "      <td>0.137196</td>\n",
       "      <td>-0.016711</td>\n",
       "      <td>-0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.081733</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>-0.078601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.095546</td>\n",
       "      <td>0.102609</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>-0.068829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.130247</td>\n",
       "      <td>0.137610</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>-0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.145755</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.043591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.155506</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>-0.029599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>-0.003064</td>\n",
       "      <td>-0.019429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.136101</td>\n",
       "      <td>0.137891</td>\n",
       "      <td>-0.001790</td>\n",
       "      <td>-0.012979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.170578</td>\n",
       "      <td>0.171609</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>-0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.193183</td>\n",
       "      <td>0.193815</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>-0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.147528</td>\n",
       "      <td>0.147940</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.002791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.155578</td>\n",
       "      <td>0.155994</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.203746</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.137570</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.003140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>0.190189</td>\n",
       "      <td>0.188656</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>0.174415</td>\n",
       "      <td>0.172593</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.010556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.234560</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.040117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.118433</td>\n",
       "      <td>0.113740</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.041255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.180569</td>\n",
       "      <td>0.172648</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.045880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.136289</td>\n",
       "      <td>0.128843</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>0.057791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.186451</td>\n",
       "      <td>0.172403</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.081482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.216280</td>\n",
       "      <td>0.198769</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>0.088099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.189703</td>\n",
       "      <td>0.172277</td>\n",
       "      <td>0.017426</td>\n",
       "      <td>0.101151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.182806</td>\n",
       "      <td>0.165148</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>0.106923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>0.269232</td>\n",
       "      <td>0.240880</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.117701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.181741</td>\n",
       "      <td>0.162351</td>\n",
       "      <td>0.019390</td>\n",
       "      <td>0.119434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.148372</td>\n",
       "      <td>0.126602</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.171954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.209003</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>0.041272</td>\n",
       "      <td>0.246063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full  Up to BERT  Difference  Relative Difference\n",
       "task_name                                                        \n",
       "ARC-C       0.156865    0.182751   -0.025886            -0.141647\n",
       "WiC         0.120486    0.137196   -0.016711            -0.121800\n",
       "SNLI        0.081733    0.088705   -0.006972            -0.078601\n",
       "CB          0.095546    0.102609   -0.007062            -0.068829\n",
       "WSC         0.130247    0.137610   -0.007364            -0.053510\n",
       "PiQA        0.139402    0.145755   -0.006354            -0.043591\n",
       "ANLI        0.155506    0.160249   -0.004743            -0.029599\n",
       "Winogrande  0.154651    0.157715   -0.003064            -0.019429\n",
       "COPA        0.136101    0.137891   -0.001790            -0.012979\n",
       "MC-TACO     0.170578    0.171609   -0.001031            -0.006007\n",
       "ARC-E       0.193183    0.193815   -0.000632            -0.003261\n",
       "RTE         0.147528    0.147940   -0.000413            -0.002791\n",
       "ARCT        0.155578    0.155994   -0.000416            -0.002667\n",
       "QAMR        0.203746    0.203850   -0.000104            -0.000510\n",
       "MNLI        0.138002    0.137570    0.000432             0.003140\n",
       "MRQA-NQ     0.190189    0.188656    0.001533             0.008125\n",
       "SQuAD2.0    0.174415    0.172593    0.001822             0.010556\n",
       "NewsQA      0.243969    0.234560    0.009410             0.040117\n",
       "BoolQ       0.118433    0.113740    0.004692             0.041255\n",
       "CosmosQA    0.180569    0.172648    0.007921             0.045880\n",
       "MCScript    0.136289    0.128843    0.007446             0.057791\n",
       "MuTual+     0.186451    0.172403    0.014048             0.081482\n",
       "CSQA        0.216280    0.198769    0.017511             0.088099\n",
       "MuTual      0.189703    0.172277    0.017426             0.101151\n",
       "QuAIL       0.182806    0.165148    0.017658             0.106923\n",
       "Quoref      0.269232    0.240880    0.028352             0.117701\n",
       "SocialIQA   0.181741    0.162351    0.019390             0.119434\n",
       "AbductNLI   0.148372    0.126602    0.021770             0.171954\n",
       "HellaSwag   0.209003    0.167731    0.041272             0.246063"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.rename(columns={'BERT':'Up to BERT', 'diff':'Difference', 'rel_diff':'Relative Difference'}).sort_values(by='Relative Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>BERT</th>\n",
       "      <th>diff</th>\n",
       "      <th>rel_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.155506</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>-0.029599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.156865</td>\n",
       "      <td>0.182751</td>\n",
       "      <td>-0.025886</td>\n",
       "      <td>-0.141647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.193183</td>\n",
       "      <td>0.193815</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>-0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.155578</td>\n",
       "      <td>0.155994</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.095546</td>\n",
       "      <td>0.102609</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>-0.068829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.136101</td>\n",
       "      <td>0.137891</td>\n",
       "      <td>-0.001790</td>\n",
       "      <td>-0.012979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.170578</td>\n",
       "      <td>0.171609</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>-0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.139402</td>\n",
       "      <td>0.145755</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.043591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.203746</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.147528</td>\n",
       "      <td>0.147940</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.002791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.081733</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>-0.078601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.130247</td>\n",
       "      <td>0.137610</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>-0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.120486</td>\n",
       "      <td>0.137196</td>\n",
       "      <td>-0.016711</td>\n",
       "      <td>-0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>-0.003064</td>\n",
       "      <td>-0.019429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full      BERT      diff  rel_diff\n",
       "task_name                                         \n",
       "ANLI        0.155506  0.160249 -0.004743 -0.029599\n",
       "ARC-C       0.156865  0.182751 -0.025886 -0.141647\n",
       "ARC-E       0.193183  0.193815 -0.000632 -0.003261\n",
       "ARCT        0.155578  0.155994 -0.000416 -0.002667\n",
       "CB          0.095546  0.102609 -0.007062 -0.068829\n",
       "COPA        0.136101  0.137891 -0.001790 -0.012979\n",
       "MC-TACO     0.170578  0.171609 -0.001031 -0.006007\n",
       "PiQA        0.139402  0.145755 -0.006354 -0.043591\n",
       "QAMR        0.203746  0.203850 -0.000104 -0.000510\n",
       "RTE         0.147528  0.147940 -0.000413 -0.002791\n",
       "SNLI        0.081733  0.088705 -0.006972 -0.078601\n",
       "WSC         0.130247  0.137610 -0.007364 -0.053510\n",
       "WiC         0.120486  0.137196 -0.016711 -0.121800\n",
       "Winogrande  0.154651  0.157715 -0.003064 -0.019429"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.loc[leh_tasks_qtile['diff'] < 0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
