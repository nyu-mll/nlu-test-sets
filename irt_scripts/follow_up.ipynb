{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle5 as pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+torch.exp(-x))\n",
    "\n",
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean', target=None):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    if target:\n",
    "        idx = model_names.index(target)\n",
    "        best_value = theta[col].iloc[idx]\n",
    "        print('Local Grad for Target Model')\n",
    "        print(f'Target model: {target}\\n{best_value}')\n",
    "    else:\n",
    "        best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "        print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col].values), torch.tensor(beta[col].values)\n",
    "    \n",
    "    logits = (a*(best_value-b))\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = sigmoids*(1.-sigmoids)*a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g)*scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model_guide(alpha_dist, theta_dist, alpha_transform, theta_transform):\n",
    "    model = lambda obs: irt_model(obs, alpha_dist, theta_dist, alpha_transform = alpha_transform, theta_transform = theta_transform)\n",
    "    guide = lambda obs: vi_posterior(obs, alpha_dist, theta_dist)\n",
    "    \n",
    "    return model, guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data_accuracies(data, verbose = False, get_cols = False):\n",
    "    '''\n",
    "    Method to reformat `data` and calculate item and responder accuracies.\n",
    "    \n",
    "    Args:\n",
    "        data:                DataFrame of item responses.\n",
    "        verbose:             Boolean value of whether to print statements.\n",
    "        get_cols:            Boolean value of whether to return original column\n",
    "                             values of `data`.\n",
    "        \n",
    "    Returns:\n",
    "        new_data:            Reformatted `data`, dropping first column.\n",
    "        accuracies:          Accuracy for each responder across examples.\n",
    "        example_accuracies:  Accuracy for each example across responders.\n",
    "        data.columns.values: Returns only if `get_cols` is True. Original column\n",
    "                             values of `data`.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    new_data = new_data[:,1:]\n",
    "    \n",
    "    model_names = dict(data['userid'])\n",
    "    accuracies = new_data.mean(-1)\n",
    "    example_accuracies = new_data.mean(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'.join([f'{name}: {acc}' for name, acc in zip(model_names.values(),accuracies)]))\n",
    "    \n",
    "    if get_cols:\n",
    "        return new_data, accuracies, example_accuracies, data.columns.values\n",
    "    else:\n",
    "        return new_data, accuracies, example_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_stats_CI(params, p=0.95, dist='normal'):\n",
    "    '''\n",
    "    Method to calculate lower and upper quantiles defined by `p`, mean, and variance of `param`\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of distribution parameters for each item keyed according to the \n",
    "                parametric distribution defined by `dist`.\n",
    "        p:      Percent of distribution covered by the lower and upper interval values for each\n",
    "                parameter.\n",
    "        dist:   Name of parametric distribution\n",
    "    \n",
    "    Returns:\n",
    "        return: {\n",
    "            'lower': Lower interval values of each parameter,\n",
    "            'upper': Upper interval values of each parameter,\n",
    "            'mean' : Mean of each parameter,\n",
    "            'var'  : Variance of each parameter\n",
    "        }\n",
    "    '''\n",
    "    stats = {}\n",
    "    if dist == 'normal':\n",
    "        L,U = scipy.stats.norm.interval(p,loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "        M,V = scipy.stats.norm.stats(loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "    elif dist == 'log-normal':\n",
    "        L,U = scipy.stats.lognorm.interval(p, s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "        M,V = scipy.stats.lognorm.stats(s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "    elif dist == 'beta':\n",
    "        L,U = scipy.stats.beta.interval(p,a=params['alpha'], b=params['beta'])\n",
    "        M,V = scipy.stats.beta.stats(a=params['alpha'], b=params['beta'])\n",
    "    else:\n",
    "        raise TypeError(f'Distribution type {dist} not supported.')\n",
    "    \n",
    "    return {\n",
    "        'lower':[L],\n",
    "        'upper':[U],\n",
    "        'mean':[M],\n",
    "        'var':[V],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_plot_stats(exp_dir, alpha_dist, theta_dist, transforms, p = 0.95):\n",
    "    '''\n",
    "    Method to return plotting statistics for 3 parameter IRT model parameters.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir:          Path to 3 parameter IRT parameters and responses.\n",
    "        alpha_dist:       Name of the item discrimination [a] distribution.\n",
    "        theta_dist:       Name of the responder ability [t] distribution.\n",
    "        transforms:       Dictionary of transformations to apply to each parameter type\n",
    "                          where keys are parameter names and values are functions.\n",
    "        p:                Percent of distribution covered by the lower and upper interval \n",
    "                          values for each parameter.\n",
    "    \n",
    "    Returns:\n",
    "        param_plot_stats: Dictionary of parameter plot statistics where keys are parameter\n",
    "                          names and values are plot statistics dictionaries as defined by\n",
    "                          get_stats_CI().\n",
    "    '''\n",
    "    param_dists = {\n",
    "        'a':alpha_dist,\n",
    "        'b':'normal',\n",
    "        'g':'normal',\n",
    "        't':theta_dist,\n",
    "    }\n",
    "\n",
    "    dist_params = {\n",
    "        'normal':['mu', 'logstd'],\n",
    "        'log-normal':['mu', 'logstd'],\n",
    "        'beta':['alpha', 'beta'],\n",
    "    }\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(os.path.join(exp_dir, 'params.p'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    # get stats for plotting\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for param, param_dist in param_dists.items():\n",
    "        temp_params = dist_params[param_dist]\n",
    "\n",
    "        for idx, (p1_orig, p2_orig) in enumerate(zip(pyro_param_dict[f'{param} {temp_params[0]}'], pyro_param_dict[f'{param} {temp_params[1]}'])):\n",
    "            p1, p2 = p1_orig.detach(), p2_orig.detach()\n",
    "            \n",
    "            temp_stats_df = pd.DataFrame.from_dict(\n",
    "                get_stats_CI(\n",
    "                    params = {\n",
    "                        temp_params[0]:p1,\n",
    "                        temp_params[1]:p2,\n",
    "                    },\n",
    "                    p=p,\n",
    "                    dist = param_dist,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            temp_stats_df = temp_stats_df.applymap(transforms[param])\n",
    "        \n",
    "            if idx == 0:\n",
    "                param_plot_stats[param] = temp_stats_df\n",
    "            else:\n",
    "                param_plot_stats[param] = param_plot_stats[param].append(temp_stats_df, ignore_index = True)\n",
    "    \n",
    "    return param_plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sign_mult(df1, df2):\n",
    "    newdf = copy.deepcopy(df2)\n",
    "    \n",
    "    for idx, row in df1.iterrows():\n",
    "        if numpy.sign(row['mean']) < 0:\n",
    "            newdf.loc[idx,'mean'] = -1*newdf.loc[idx,'mean']\n",
    "            newdf.loc[idx,'lower'] = -1*newdf.loc[idx,'upper']\n",
    "            newdf.loc[idx,'upper'] = -1*newdf.loc[idx,'lower']\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_diff_by_set(diffs, item_ids):\n",
    "    diff_by_set = {}\n",
    "    id_split = '_'\n",
    "\n",
    "    max_diff = -1e6\n",
    "    min_diff = 1e6\n",
    "    \n",
    "    for idx, diff in enumerate(diffs):\n",
    "        set_name = item_ids[idx].split(id_split)[0]\n",
    "\n",
    "        if set_name in diff_by_set.keys():\n",
    "            diff_by_set[set_name].append(diff)\n",
    "        else:\n",
    "            diff_by_set[set_name] = [diff]\n",
    "            \n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            \n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "    \n",
    "    return diff_by_set, min_diff, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_irt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,adversarial-nli,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad_v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large_best\n",
      "==========================================================================================\n",
      "Overall acc: 0.7403\n",
      "abductive_nli acc: 0.8564\n",
      "adversarial_nli acc: 0.4938\n",
      "arc_challenge acc: 0.3319\n",
      "arc_easy acc: 0.6296\n",
      "arct acc: 0.8604\n",
      "boolq acc: 0.8367\n",
      "cb acc: 0.8571\n",
      "commonsenseqa acc: 0.6759\n",
      "copa acc: 0.8400\n",
      "cosmosqa acc: 0.7984\n",
      "hellaswag acc: 0.8417\n",
      "mcscript acc: 0.9183\n",
      "mctaco acc: 0.5360\n",
      "mnli acc: 0.8991\n",
      "mrqa_natural_questions acc: 0.6941\n",
      "mutual_plus acc: 0.7314\n",
      "mutual acc: 0.8668\n",
      "newsqa acc: 0.5542\n",
      "piqa acc: 0.7617\n",
      "qamr acc: 0.7303\n",
      "quail acc: 0.6691\n",
      "quoref acc: 0.8023\n",
      "rte acc: 0.8345\n",
      "snli acc: 0.9203\n",
      "socialiqa acc: 0.7738\n",
      "squad_v2 acc: 0.4326\n",
      "wic acc: 0.7085\n",
      "winogrande acc: 0.7697\n",
      "wsc acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()\n",
    "data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles', exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <th>abductive_nli_5</th>\n",
       "      <th>abductive_nli_6</th>\n",
       "      <th>abductive_nli_7</th>\n",
       "      <th>abductive_nli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>wsc_42</th>\n",
       "      <th>wsc_43</th>\n",
       "      <th>wsc_44</th>\n",
       "      <th>wsc_45</th>\n",
       "      <th>wsc_46</th>\n",
       "      <th>wsc_47</th>\n",
       "      <th>wsc_48</th>\n",
       "      <th>wsc_49</th>\n",
       "      <th>wsc_50</th>\n",
       "      <th>wsc_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 82757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  abductive_nli_0  abductive_nli_1  \\\n",
       "0   roberta-base-10M-1_best                1                0   \n",
       "1      roberta-base-10M-1_1                0                0   \n",
       "2     roberta-base-10M-1_25                1                1   \n",
       "3     roberta-base-10M-1_50                1                0   \n",
       "4     roberta-base-10M-1_10                1                0   \n",
       "..                      ...              ...              ...   \n",
       "85   xlm-roberta-large_best                1                1   \n",
       "86      xlm-roberta-large_1                1                1   \n",
       "87     xlm-roberta-large_25                1                1   \n",
       "88     xlm-roberta-large_50                1                1   \n",
       "89     xlm-roberta-large_10                0                1   \n",
       "\n",
       "    abductive_nli_2  abductive_nli_3  abductive_nli_4  abductive_nli_5  \\\n",
       "0                 1                1                1                1   \n",
       "1                 0                1                1                0   \n",
       "2                 1                1                1                1   \n",
       "3                 1                1                1                1   \n",
       "4                 1                1                1                1   \n",
       "..              ...              ...              ...              ...   \n",
       "85                0                1                1                1   \n",
       "86                0                1                1                0   \n",
       "87                0                1                1                1   \n",
       "88                1                1                1                1   \n",
       "89                0                1                1                0   \n",
       "\n",
       "    abductive_nli_6  abductive_nli_7  abductive_nli_8  ...  wsc_42  wsc_43  \\\n",
       "0                 1                0                1  ...       1       0   \n",
       "1                 1                0                1  ...       1       0   \n",
       "2                 1                1                1  ...       0       0   \n",
       "3                 1                0                1  ...       1       0   \n",
       "4                 1                0                1  ...       1       0   \n",
       "..              ...              ...              ...  ...     ...     ...   \n",
       "85                1                1                1  ...       1       1   \n",
       "86                1                0                1  ...       0       0   \n",
       "87                0                1                1  ...       1       1   \n",
       "88                1                1                1  ...       1       1   \n",
       "89                0                1                1  ...       0       0   \n",
       "\n",
       "    wsc_44  wsc_45  wsc_46  wsc_47  wsc_48  wsc_49  wsc_50  wsc_51  \n",
       "0        1       1       0       1       0       1       0       1  \n",
       "1        1       0       0       1       0       0       0       1  \n",
       "2        0       1       0       1       1       1       1       1  \n",
       "3        0       1       0       1       1       1       0       1  \n",
       "4        0       1       0       1       1       1       0       1  \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "85       0       1       0       1       1       1       0       0  \n",
       "86       1       0       1       0       0       0       1       1  \n",
       "87       0       1       0       1       1       1       0       0  \n",
       "88       0       1       0       1       1       1       0       0  \n",
       "89       1       0       1       0       0       0       1       1  \n",
       "\n",
       "[90 rows x 82757 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 35716\n",
      "g 0\n",
      "t 47\n"
     ]
    }
   ],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats.items():\n",
    "    param_stat['log_mean'] = numpy.log(param_stat['mean'])\n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "param_b = pd.concat([param_plot_stats['b'], task_name_format], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: albert-xxlarge-v2\n",
      "1.6105766296386719\n",
      "No gamma: 0.14762448462619243\n",
      "With gamma: 0.1185372240065298\n",
      "           mean\n",
      "0      0.171294\n",
      "1      0.230789\n",
      "2      0.064061\n",
      "3      0.015200\n",
      "4      0.090730\n",
      "...         ...\n",
      "82751  0.059779\n",
      "82752  0.141603\n",
      "82753  0.091485\n",
      "82754  0.128162\n",
      "82755  0.097277\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats['g'],\n",
    ")\n",
    "\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot = pd.concat([leh_scores_plot, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_75 = leh_scores_plot.groupby(by='task_name').quantile(q=0.75).reset_index()\n",
    "\n",
    "with open(os.path.join('plot_stats_pickles', f'LEH_75qtile.p'), 'wb') as f:\n",
    "    pickle.dump(leh_75, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ns = ['NewsQA', 'MC-TACO', 'ARCT', 'WiC', 'SQuAD2.0', 'SocialIQA', 'CSQA', 'BoolQ', 'MNLI', 'AbductNLI', 'MuTual+', 'Quoref', 'RTE', 'MuTual', 'Winogrande', 'CosmosQA', 'PiQA', 'HellaSwag', 'CB', 'MCScript', 'COPA', 'WSC']\n",
    "roberta_scores = [57.8, 55.9, 86.7, 71.5, 91.5, 79.9, 74.6, 85.7, 89.7, 85, 77.9, 78.7, 87.6, 87.8, 77.3, 79.4, 77.6, 84.1, 90.5, 92.8, 86, 78.8]\n",
    "human_perf = [46.5, 75.8, 79.8, 80, 86.8, 88.1, 88.9, 89, 92, 92.9, 93, 93, 93.6, 93.8, 94, 94, 94.9, 95.6, 95.8, 98.2, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_human = pd.DataFrame([\n",
    "    [n, r, h] for n, r, h in zip(task_ns, roberta_scores, human_perf)\n",
    "], columns = ['task_name', 'roberta', 'human'])\n",
    "roberta_human['gap'] = roberta_human['human'] - roberta_human['roberta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANLI</td>\n",
       "      <td>0.202093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARC-C</td>\n",
       "      <td>0.224374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARC-E</td>\n",
       "      <td>0.221798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARCT</td>\n",
       "      <td>0.146663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>0.180351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BoolQ</td>\n",
       "      <td>0.126232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.102626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COPA</td>\n",
       "      <td>0.173248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CSQA</td>\n",
       "      <td>0.239099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CosmosQA</td>\n",
       "      <td>0.204523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>0.259556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MC-TACO</td>\n",
       "      <td>0.256297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCScript</td>\n",
       "      <td>0.135480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MNLI</td>\n",
       "      <td>0.120850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MRQA-NQ</td>\n",
       "      <td>0.188073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MuTual</td>\n",
       "      <td>0.207742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MuTual+</td>\n",
       "      <td>0.215006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NewsQA</td>\n",
       "      <td>0.245779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PiQA</td>\n",
       "      <td>0.163360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QAMR</td>\n",
       "      <td>0.178407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QuAIL</td>\n",
       "      <td>0.236739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Quoref</td>\n",
       "      <td>0.260933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RTE</td>\n",
       "      <td>0.180724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SNLI</td>\n",
       "      <td>0.050806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SQuAD2.0</td>\n",
       "      <td>0.170584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SocialIQA</td>\n",
       "      <td>0.200835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WSC</td>\n",
       "      <td>0.142330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WiC</td>\n",
       "      <td>0.146126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>0.166134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     task_name      mean\n",
       "0         ANLI  0.202093\n",
       "1        ARC-C  0.224374\n",
       "2        ARC-E  0.221798\n",
       "3         ARCT  0.146663\n",
       "4    AbductNLI  0.180351\n",
       "5        BoolQ  0.126232\n",
       "6           CB  0.102626\n",
       "7         COPA  0.173248\n",
       "8         CSQA  0.239099\n",
       "9     CosmosQA  0.204523\n",
       "10   HellaSwag  0.259556\n",
       "11     MC-TACO  0.256297\n",
       "12    MCScript  0.135480\n",
       "13        MNLI  0.120850\n",
       "14     MRQA-NQ  0.188073\n",
       "15      MuTual  0.207742\n",
       "16     MuTual+  0.215006\n",
       "17      NewsQA  0.245779\n",
       "18        PiQA  0.163360\n",
       "19        QAMR  0.178407\n",
       "20       QuAIL  0.236739\n",
       "21      Quoref  0.260933\n",
       "22         RTE  0.180724\n",
       "23        SNLI  0.050806\n",
       "24    SQuAD2.0  0.170584\n",
       "25   SocialIQA  0.200835\n",
       "26         WSC  0.142330\n",
       "27         WiC  0.146126\n",
       "28  Winogrande  0.166134"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_name</th>\n",
       "      <th>roberta</th>\n",
       "      <th>human</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NewsQA</td>\n",
       "      <td>57.8</td>\n",
       "      <td>46.5</td>\n",
       "      <td>-11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MC-TACO</td>\n",
       "      <td>55.9</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARCT</td>\n",
       "      <td>86.7</td>\n",
       "      <td>79.8</td>\n",
       "      <td>-6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WiC</td>\n",
       "      <td>71.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQuAD2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>86.8</td>\n",
       "      <td>-4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SocialIQA</td>\n",
       "      <td>79.9</td>\n",
       "      <td>88.1</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CSQA</td>\n",
       "      <td>74.6</td>\n",
       "      <td>88.9</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BoolQ</td>\n",
       "      <td>85.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MNLI</td>\n",
       "      <td>89.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MuTual+</td>\n",
       "      <td>77.9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Quoref</td>\n",
       "      <td>78.7</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RTE</td>\n",
       "      <td>87.6</td>\n",
       "      <td>93.6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MuTual</td>\n",
       "      <td>87.8</td>\n",
       "      <td>93.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Winogrande</td>\n",
       "      <td>77.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CosmosQA</td>\n",
       "      <td>79.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PiQA</td>\n",
       "      <td>77.6</td>\n",
       "      <td>94.9</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HellaSwag</td>\n",
       "      <td>84.1</td>\n",
       "      <td>95.6</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CB</td>\n",
       "      <td>90.5</td>\n",
       "      <td>95.8</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MCScript</td>\n",
       "      <td>92.8</td>\n",
       "      <td>98.2</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COPA</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WSC</td>\n",
       "      <td>78.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     task_name  roberta  human   gap\n",
       "0       NewsQA     57.8   46.5 -11.3\n",
       "1      MC-TACO     55.9   75.8  19.9\n",
       "2         ARCT     86.7   79.8  -6.9\n",
       "3          WiC     71.5   80.0   8.5\n",
       "4     SQuAD2.0     91.5   86.8  -4.7\n",
       "5    SocialIQA     79.9   88.1   8.2\n",
       "6         CSQA     74.6   88.9  14.3\n",
       "7        BoolQ     85.7   89.0   3.3\n",
       "8         MNLI     89.7   92.0   2.3\n",
       "9    AbductNLI     85.0   92.9   7.9\n",
       "10     MuTual+     77.9   93.0  15.1\n",
       "11      Quoref     78.7   93.0  14.3\n",
       "12         RTE     87.6   93.6   6.0\n",
       "13      MuTual     87.8   93.8   6.0\n",
       "14  Winogrande     77.3   94.0  16.7\n",
       "15    CosmosQA     79.4   94.0  14.6\n",
       "16        PiQA     77.6   94.9  17.3\n",
       "17   HellaSwag     84.1   95.6  11.5\n",
       "18          CB     90.5   95.8   5.3\n",
       "19    MCScript     92.8   98.2   5.4\n",
       "20        COPA     86.0  100.0  14.0\n",
       "21         WSC     78.8  100.0  21.2"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARC-E', 'ARC-C', 'QAMR', 'SNLI', 'ANLI', 'MRQA-NQ', 'QuAIL'}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "srh = set(roberta_human['task_name'])\n",
    "sleh = set(leh_75['task_name'])\n",
    "print(sleh.difference(srh))\n",
    "print(len(sleh.difference(srh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta</th>\n",
       "      <th>human</th>\n",
       "      <th>gap</th>\n",
       "      <th>LEH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roberta</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685949</td>\n",
       "      <td>-0.211692</td>\n",
       "      <td>-0.573634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>0.685949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565949</td>\n",
       "      <td>-0.326342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gap</th>\n",
       "      <td>-0.211692</td>\n",
       "      <td>0.565949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEH</th>\n",
       "      <td>-0.573634</td>\n",
       "      <td>-0.326342</td>\n",
       "      <td>0.211614</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          roberta     human       gap       LEH\n",
       "roberta  1.000000  0.685949 -0.211692 -0.573634\n",
       "human    0.685949  1.000000  0.565949 -0.326342\n",
       "gap     -0.211692  0.565949  1.000000  0.211614\n",
       "LEH     -0.573634 -0.326342  0.211614  1.000000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_combined = roberta_human.join(leh_75.set_index('task_name').loc[roberta_human['task_name'],:], on='task_name').rename(columns={'mean':'LEH'})\n",
    "metrics_combined.corr('pearson')                                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Follow-ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## % all incorrect/correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcent_correct = pd.DataFrame(\n",
    "    combined_responses.iloc[:,1:].sum(axis=0)/combined_responses.shape[0], columns=['pcent_correct']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcent_correct['all_correct'] = pcent_correct['pcent_correct'].eq(1)\n",
    "pcent_correct['all_wrong'] = pcent_correct['pcent_correct'].eq(0)\n",
    "pcent_correct['all_either'] = pcent_correct['all_correct'] + pcent_correct['all_wrong']\n",
    "pcent_correct['dataset'] = list(pd.Series(pcent_correct.index.values).apply(lambda x: '_'.join(x.split('_')[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcent_correct</th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <td>0.744444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <td>0.644444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abductive_nli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_47</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_48</th>\n",
       "      <td>0.544444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_49</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_50</th>\n",
       "      <td>0.311111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsc_51</th>\n",
       "      <td>0.688889</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wsc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82756 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pcent_correct  all_correct  all_wrong  all_either  \\\n",
       "abductive_nli_0       0.466667        False      False       False   \n",
       "abductive_nli_1       0.388889        False      False       False   \n",
       "abductive_nli_2       0.744444        False      False       False   \n",
       "abductive_nli_3       0.844444        False      False       False   \n",
       "abductive_nli_4       0.644444        False      False       False   \n",
       "...                        ...          ...        ...         ...   \n",
       "wsc_47                0.777778        False      False       False   \n",
       "wsc_48                0.544444        False      False       False   \n",
       "wsc_49                0.633333        False      False       False   \n",
       "wsc_50                0.311111        False      False       False   \n",
       "wsc_51                0.688889        False      False       False   \n",
       "\n",
       "                       dataset  \n",
       "abductive_nli_0  abductive_nli  \n",
       "abductive_nli_1  abductive_nli  \n",
       "abductive_nli_2  abductive_nli  \n",
       "abductive_nli_3  abductive_nli  \n",
       "abductive_nli_4  abductive_nli  \n",
       "...                        ...  \n",
       "wsc_47                     wsc  \n",
       "wsc_48                     wsc  \n",
       "wsc_49                     wsc  \n",
       "wsc_50                     wsc  \n",
       "wsc_51                     wsc  \n",
       "\n",
       "[82756 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude lower       0.871511\n",
      "upper       2.108712\n",
      "mean        1.385880\n",
      "var         0.109867\n",
      "log_mean    0.298848\n",
      "dtype: float64\n",
      "\n",
      "only lower       1.015828\n",
      "upper       2.423998\n",
      "mean        1.603821\n",
      "var         0.136212\n",
      "log_mean    0.459488\n",
      "dtype: float64\n",
      "\n",
      "only correct lower       0.609443\n",
      "upper       1.925238\n",
      "mean        1.126661\n",
      "var         0.121745\n",
      "log_mean    0.112298\n",
      "dtype: float64\n",
      "\n",
      "only wrong lower       1.080839\n",
      "upper       2.503786\n",
      "mean        1.680153\n",
      "var         0.138527\n",
      "log_mean    0.515029\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('exclude', param_plot_stats['a'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['a'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['a'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['a'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude lower       0.147596\n",
      "upper       0.392111\n",
      "mean        0.248828\n",
      "var         0.548299\n",
      "log_mean   -1.660597\n",
      "dtype: float64\n",
      "\n",
      "only lower       0.117880\n",
      "upper       0.209088\n",
      "mean        0.156187\n",
      "var         0.562981\n",
      "log_mean   -2.896617\n",
      "dtype: float64\n",
      "\n",
      "only correct lower       0.767574\n",
      "upper       0.969053\n",
      "mean        0.911289\n",
      "var         0.583508\n",
      "log_mean   -0.092970\n",
      "dtype: float64\n",
      "\n",
      "only wrong lower       0.013946\n",
      "upper       0.087514\n",
      "mean        0.035391\n",
      "var         0.559697\n",
      "log_mean   -3.345124\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('exclude', param_plot_stats['g'].loc[~np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only', param_plot_stats['g'].loc[np.array(pcent_correct['all_either']),:].mean())\n",
    "print('')\n",
    "print('only correct', param_plot_stats['g'].loc[np.array(pcent_correct['all_correct']),:].mean())\n",
    "print('')\n",
    "print('only wrong', param_plot_stats['g'].loc[np.array(pcent_correct['all_wrong']),:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = pd.concat([pcent_correct.reset_index(), task_name_format], axis=1)\n",
    "\n",
    "dataset2format = {'all':'all'}\n",
    "format2dataset = {'all':'all'}\n",
    "\n",
    "for dset in temp['dataset'].unique():\n",
    "    fmat = temp.loc[temp['dataset'] == dset, 'format'].unique()[0]\n",
    "    dataset2format[dset] = fmat\n",
    "    format2dataset[fmat] = dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial_nli\n"
     ]
    }
   ],
   "source": [
    "item_excludes = {}\n",
    "\n",
    "for dataset in pcent_correct['dataset'].unique():\n",
    "    temp = pcent_correct.loc[pcent_correct['dataset'] == dataset, :]\n",
    "    \n",
    "    try:\n",
    "        assert np.not_equal(temp.index.values, np.array(sorted(temp.index.values, key=lambda x: int(x.split('_')[-1])))).sum() == 0, dataset\n",
    "    except:\n",
    "        print(dataset)\n",
    "        pass\n",
    "    \n",
    "    item_excludes[dataset] = temp['all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keeps = ['all_correct', 'all_wrong', 'all_either', 'dataset']\n",
    "grouped_pcent_correct = pcent_correct[keeps].groupby(by='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "combined_all_pcent = {}\n",
    "combined_all_count = {}\n",
    "\n",
    "for col in ['all_correct', 'all_wrong', 'all_either']:\n",
    "    combined_all_count[col] = pcent_correct[col].sum()\n",
    "    combined_all_pcent[col] = combined_all_count[col]/combined_responses.shape[1]\n",
    "    \n",
    "combined_all_count['total_count'] = combined_responses.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_pcent_either = grouped_pcent_correct.sum()/grouped_pcent_correct.count()\n",
    "summary_pcent = grouped_pcent_either.append(pd.DataFrame.from_dict({'all':combined_all_pcent}, orient='index'))\n",
    "\n",
    "grouped_count_either = grouped_pcent_correct.sum()\n",
    "grouped_count_either['total_count'] = grouped_pcent_correct.count()['all_either']\n",
    "summary_count = grouped_count_either.append(pd.DataFrame.from_dict({'all':combined_all_count}, orient='index'))\n",
    "\n",
    "\n",
    "summary_pcent['format'] = list(pd.Series(summary_pcent.index.values).apply(lambda x: dataset2format[x]))\n",
    "summary_count['format'] = list(pd.Series(summary_count.index.values).apply(lambda x: dataset2format[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adversarial_nli</th>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_easy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boolq</th>\n",
       "      <td>0.095413</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mctaco</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrqa_natural_questions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073076</td>\n",
       "      <td>0.073076</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsqa</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161426</td>\n",
       "      <td>0.161426</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qamr</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>0.026468</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snli</th>\n",
       "      <td>0.031759</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.033388</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squad_v2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>0.041181</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        all_correct  all_wrong  all_either          format\n",
       "adversarial_nli            0.000313   0.011875    0.012188  classification\n",
       "arc_easy                   0.000000   0.000421    0.000421          MC-par\n",
       "boolq                      0.095413   0.002446    0.097859          MC-par\n",
       "cosmosqa                   0.000000   0.002009    0.002009          MC-par\n",
       "hellaswag                  0.000000   0.000398    0.000398          MC-par\n",
       "mctaco                     0.000000   0.108108    0.108108         MC-sent\n",
       "mnli                       0.000102   0.000407    0.000509  classification\n",
       "mrqa_natural_questions     0.000000   0.073076    0.073076  span selection\n",
       "newsqa                     0.000000   0.161426    0.161426  span selection\n",
       "qamr                       0.000000   0.080714    0.080714  span selection\n",
       "quoref                     0.000000   0.026468    0.026468  span selection\n",
       "snli                       0.031759   0.001629    0.033388  classification\n",
       "squad_v2                   0.000000   0.002743    0.002743  span selection\n",
       "all                        0.005679   0.035502    0.041181             all"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_pcent.loc[summary_pcent['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>total_count</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adversarial_nli</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>3200</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arc_easy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2376</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boolq</th>\n",
       "      <td>156</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>1635</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1493</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellaswag</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5021</td>\n",
       "      <td>MC-par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mctaco</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>1332</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9824</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrqa_natural_questions</th>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>6418</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newsqa</th>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>4293</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qamr</th>\n",
       "      <td>0</td>\n",
       "      <td>1515</td>\n",
       "      <td>1515</td>\n",
       "      <td>18770</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1209</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snli</th>\n",
       "      <td>312</td>\n",
       "      <td>16</td>\n",
       "      <td>328</td>\n",
       "      <td>9824</td>\n",
       "      <td>classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squad_v2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>6198</td>\n",
       "      <td>span selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>470</td>\n",
       "      <td>2938</td>\n",
       "      <td>3408</td>\n",
       "      <td>82757</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        all_correct  all_wrong  all_either  total_count  \\\n",
       "adversarial_nli                   1         38          39         3200   \n",
       "arc_easy                          0          1           1         2376   \n",
       "boolq                           156          4         160         1635   \n",
       "cosmosqa                          0          3           3         1493   \n",
       "hellaswag                         0          2           2         5021   \n",
       "mctaco                            0        144         144         1332   \n",
       "mnli                              1          4           5         9824   \n",
       "mrqa_natural_questions            0        469         469         6418   \n",
       "newsqa                            0        693         693         4293   \n",
       "qamr                              0       1515        1515        18770   \n",
       "quoref                            0         32          32         1209   \n",
       "snli                            312         16         328         9824   \n",
       "squad_v2                          0         17          17         6198   \n",
       "all                             470       2938        3408        82757   \n",
       "\n",
       "                                format  \n",
       "adversarial_nli         classification  \n",
       "arc_easy                        MC-par  \n",
       "boolq                           MC-par  \n",
       "cosmosqa                        MC-par  \n",
       "hellaswag                       MC-par  \n",
       "mctaco                         MC-sent  \n",
       "mnli                    classification  \n",
       "mrqa_natural_questions  span selection  \n",
       "newsqa                  span selection  \n",
       "qamr                    span selection  \n",
       "quoref                  span selection  \n",
       "snli                    classification  \n",
       "squad_v2                span selection  \n",
       "all                                all  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_count.loc[summary_count['all_either'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_by_format = summary_count.groupby(by='format')\n",
    "summary_by_format = summary_by_format.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_correct</th>\n",
       "      <th>all_wrong</th>\n",
       "      <th>all_either</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MC-par</th>\n",
       "      <td>156</td>\n",
       "      <td>10</td>\n",
       "      <td>166</td>\n",
       "      <td>17193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-sent</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>470</td>\n",
       "      <td>2938</td>\n",
       "      <td>3408</td>\n",
       "      <td>82757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>314</td>\n",
       "      <td>58</td>\n",
       "      <td>372</td>\n",
       "      <td>23015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>span selection</th>\n",
       "      <td>0</td>\n",
       "      <td>2726</td>\n",
       "      <td>2726</td>\n",
       "      <td>36888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                all_correct  all_wrong  all_either  total_count\n",
       "format                                                         \n",
       "MC-par                  156         10         166        17193\n",
       "MC-sent                   0        144         144         5660\n",
       "all                     470       2938        3408        82757\n",
       "classification          314         58         372        23015\n",
       "span selection            0       2726        2726        36888"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_format.loc[summary_by_format['all_either'] > 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Break Down of All Either\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "format\n",
       "MC-par            0.048709\n",
       "MC-sent           0.042254\n",
       "all               1.000000\n",
       "classification    0.109155\n",
       "span selection    0.799883\n",
       "Name: all_either, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Break Down of All Either')\n",
    "summary_by_format['all_either']/summary_by_format.loc['all', 'all_either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown of All Either by Task Format\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "format\n",
       "MC-par            0.009655\n",
       "MC-sent           0.025442\n",
       "all               0.041181\n",
       "classification    0.016163\n",
       "span selection    0.073899\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Breakdown of All Either by Task Format')\n",
    "summary_by_format['all_either']/summary_by_format['total_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Trim Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..','data')\n",
    "files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Trim Model Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trimmed_model_dir = os.path.join('..','data_trimmed_model')\n",
    "os.makedirs(trimmed_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exclude_models = ['albert-xxlarge-v2', 'xlm-roberta-large', 'roberta-large', 'roberta-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    temp_models = temp['userid'].apply(lambda x:''.join(x.split('_')[:-1]))\n",
    "    \n",
    "    exclude_indexes = temp_models.eq(exclude_models[0])\n",
    "    for i in range(1,len(exclude_models)):\n",
    "        exclude_indexes = exclude_indexes + temp_models.eq(exclude_models[i])\n",
    "    \n",
    "    trimmed = temp.loc[~exclude_indexes, :]\n",
    "    \n",
    "    check = set(temp.loc[~exclude_indexes, :]['userid'].apply(lambda x:''.join(x.split('_')[:-1])).unique())\n",
    "    for model in exclude_models:\n",
    "        assert not model in check, f'{file}, {model}'\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_model_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Trim Item Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trimmed_item_dir = os.path.join('..','data_trimmed_item')\n",
    "os.makedirs(trimmed_item_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ending = '_irt_all_coded.csv'\n",
    "\n",
    "for file in files:\n",
    "    dataset_name = '_'.join(file[:-len(ending)].split('-'))\n",
    "    if dataset_name == 'mrqa_nq':\n",
    "        dataset_name = 'mrqa_natural_questions'\n",
    "    \n",
    "    if not dataset_name in item_excludes.keys():\n",
    "        print(dataset_name)  \n",
    "    \n",
    "    temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "    trimmed = temp.loc[:,~np.array([False] + list(item_excludes[dataset_name]))]\n",
    "    \n",
    "    trimmed.to_csv(os.path.join(trimmed_item_dir, file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEH at BERT-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.7818823456764221\n",
      "No gamma: 0.15949575976148359\n",
      "With gamma: 0.12340414467589644\n",
      "           mean\n",
      "0      0.175287\n",
      "1      0.207571\n",
      "2      0.060491\n",
      "3      0.036461\n",
      "4      0.092730\n",
      "...         ...\n",
      "82751  0.095442\n",
      "82752  0.183235\n",
      "82753  0.142709\n",
      "82754  0.042870\n",
      "82755  0.055453\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    list(combined_responses['userid']),\n",
    "    gamma = param_plot_stats['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert = pd.DataFrame(pd.Series(leh_scores_bert), columns = ['mean'])\n",
    "print(leh_scores_plot_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Trimmed BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache_trimmed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir_trimmed = os.path.join(repo, 'params_trimmed_model', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir_trimmed, 'responses.p'), 'rb') as f:\n",
    "    combined_responses_trimmed = pickle.load(f).reset_index()\n",
    "data_trimmed, accuracies_trimmed, example_accuracies_trimmed = get_data_accuracies(combined_responses_trimmed)\n",
    "column_names_trimmed = combined_responses_trimmed.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache_trimmed:\n",
    "    param_plot_stats_trimmed = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats_trimmed[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats_trimmed = get_plot_stats(\n",
    "        exp_dir_trimmed,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = p\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles_trimmed_model', exist_ok=True)\n",
    "    for key, value in param_plot_stats_trimmed.items():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_model', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Grad for Target Model\n",
      "Target model: bert-large-cased_best\n",
      "0.9805275201797485\n",
      "No gamma: 0.1567958442231057\n",
      "With gamma: 0.12096604941079794\n",
      "           mean\n",
      "0      0.158494\n",
      "1      0.150325\n",
      "2      0.039995\n",
      "3      0.052717\n",
      "4      0.152572\n",
      "...         ...\n",
      "82751  0.084873\n",
      "82752  0.150056\n",
      "82753  0.117921\n",
      "82754  0.098012\n",
      "82755  0.059681\n",
      "\n",
      "[82756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "target = 'bert-large-cased_best'\n",
    "\n",
    "leh_scores_bert_trimmed = icc_best_deriv(\n",
    "    param_plot_stats_trimmed['a'],\n",
    "    param_plot_stats_trimmed['b'],\n",
    "    param_plot_stats_trimmed['t'],\n",
    "    list(combined_responses_trimmed['userid']),\n",
    "    gamma = param_plot_stats_trimmed['g'],\n",
    "    target = target\n",
    ")\n",
    "\n",
    "leh_scores_plot_bert_trimmed = pd.DataFrame(pd.Series(leh_scores_bert_trimmed), columns = ['mean'])\n",
    "print(leh_scores_plot_bert_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_bert_combined = pd.concat([leh_scores_plot_bert, leh_scores_plot_bert_trimmed], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.002438095265098493\n",
      "std 0.045720058898381044\n",
      "median 0.0023253037168250966\n",
      "IQR 0.048300465122386206\n",
      "upper_whisker 0.09781669972106113\n",
      "lower_whisker -0.0953851607684837\n",
      "pcent above lower 0.03121223838754894\n",
      "pcent below lower 0.013715017642225337\n"
     ]
    }
   ],
   "source": [
    "diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])\n",
    "\n",
    "print('mean', diff.mean())\n",
    "print('std', diff.std())\n",
    "print('median', diff.median())\n",
    "\n",
    "IQR = diff.quantile(0.75) - diff.quantile(0.25)\n",
    "upper_whisker = diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (diff > upper_whisker).sum()/diff.shape[0])\n",
    "print('pcent below lower', (diff < lower_whisker).sum()/diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af78fbbb5a2455d86ab592ebfb974ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fa345a61c640c9b3a141513b109eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Difference')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH')\n",
    "ax.set_title('LEH at BERT: Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.0772699763645817\n",
      "std 0.5082816675770959\n",
      "median 0.028152315598928918\n",
      "IQR 0.5002836883702901\n",
      "upper_whisker 1.0279726531962134\n",
      "lower_whisker -0.973162100284947\n",
      "pcent above lower 0.04172507129392431\n",
      "pcent below lower 0.0\n"
     ]
    }
   ],
   "source": [
    "rel_diff = (leh_scores_plot_bert['mean'] - leh_scores_plot_bert_trimmed['mean'])/leh_scores_plot_bert_trimmed['mean']\n",
    "\n",
    "print('mean', rel_diff.mean())\n",
    "print('std', rel_diff.std())\n",
    "print('median', rel_diff.median())\n",
    "\n",
    "IQR = rel_diff.quantile(0.75) - rel_diff.quantile(0.25)\n",
    "upper_whisker = rel_diff.quantile(0.75) + 1.5*IQR\n",
    "lower_whisker = rel_diff.quantile(0.25) - 1.5*IQR\n",
    "\n",
    "print('IQR', IQR)\n",
    "print('upper_whisker', upper_whisker)\n",
    "print('lower_whisker', lower_whisker)\n",
    "\n",
    "print('pcent above lower', (rel_diff > upper_whisker).sum()/rel_diff.shape[0])\n",
    "print('pcent below lower', (rel_diff < lower_whisker).sum()/rel_diff.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a8386d159c40619c2db7f83441f2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53e497c018a4f1aa040d8c95276139e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LEH at BERT: Relative Difference')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plot.subplots()\n",
    "sns.boxplot(rel_diff, showfliers=False)\n",
    "ax.set_xlabel(r'$\\Delta$ LEH / LEH$_{BERT}$')\n",
    "ax.set_title('LEH at BERT: Relative Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_label = 12\n",
    "font_legend = 10\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 12\n",
    "font_title = 14\n",
    "marker_scale = 1.5\n",
    "\n",
    "plot.rc('axes', labelsize=font_label)\n",
    "plot.rc('axes', titlesize=font_title)\n",
    "plot.rc('legend', fontsize=font_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, order, param_type, task_metadata, xsize=12, ysize=3, width=0.6, rotation=90, ylim=None, ystep=None):\n",
    "    \n",
    "    param2label = {\n",
    "        'discriminative':r'$\\log$ Discrimination ($\\log$ $\\alpha$)',\n",
    "        'difficulty': r'Difficulty ($\\beta$)',\n",
    "        \"disc-diff\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_pos\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_minmax\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"irt-score\": \"LEH Score\",\n",
    "    }\n",
    "    \n",
    "    param2yname = {\n",
    "        'discriminative': \"log_mean\",\n",
    "        'difficulty': \"mean\",\n",
    "        \"disc-diff\": 0,\n",
    "        \"disc-diff_pos\": 0,\n",
    "        \"disc-diff_minmax\": 0,\n",
    "        \"irt-score\": \"mean\",\n",
    "    }\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    f, ax = plot.subplots(figsize=(xsize, ysize))\n",
    "    \n",
    "    my_pal = {\"MC-par\": \"r\",\n",
    "              \"MC-sent\": \"b\",\n",
    "              \"classification\":\"g\",\n",
    "              \"span selection\": \"grey\"}    \n",
    "    \n",
    "    ax = sns.boxplot(x=\"task_name\", y=param2yname[param_type], data=df, order=order, width=width)\n",
    "    \n",
    "    for i, task in enumerate(order):\n",
    "        # Select which box you want to change    \n",
    "        mybox = ax.artists[i]\n",
    "        \n",
    "        # Change the appearance of that box\n",
    "        skill = task_metadata.loc[task]['format']\n",
    "        mybox.set_facecolor(my_pal[skill])\n",
    "    \n",
    "    # Add transparency to colors\n",
    "    for patch in ax.artists:\n",
    "         r, g, b, a = patch.get_facecolor()\n",
    "         patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "    sns.despine()\n",
    "    plot.xticks(range(len(order)), order, rotation=rotation, fontsize=font_xtick)\n",
    "    \n",
    "    if not ylim is None and not ystep is None:\n",
    "        plot.ylim(ylim)\n",
    "        plot.yticks(numpy.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    \n",
    "    plot.xlabel(None)\n",
    "    plot.ylabel(param2label[param_type], fontsize=font_label)\n",
    "    \n",
    "    return f\n",
    "#     plot.savefig('../plots/' + param_type + \"_box.png\",\n",
    "#                 format='png', dpi=300,\n",
    "#                 bbox_inches = 'tight',\n",
    "#                 pad_inches = .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.845654</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean      mean\n",
       "mean  1.000000  0.845654\n",
       "mean  0.845654  1.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_bert_combined.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot_bert = pd.concat([leh_scores_plot_bert, task_name_format], axis=1)\n",
    "leh_scores_plot_bert_trimmed = pd.concat([leh_scores_plot_bert_trimmed, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>task_name</th>\n",
       "      <th>format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.175287</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207571</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060491</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036461</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092730</td>\n",
       "      <td>AbductNLI</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82751</th>\n",
       "      <td>0.095442</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82752</th>\n",
       "      <td>0.183235</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82753</th>\n",
       "      <td>0.142709</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82754</th>\n",
       "      <td>0.042870</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82755</th>\n",
       "      <td>0.055453</td>\n",
       "      <td>WSC</td>\n",
       "      <td>MC-sent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82756 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  task_name   format\n",
       "0      0.175287  AbductNLI  MC-sent\n",
       "1      0.207571  AbductNLI  MC-sent\n",
       "2      0.060491  AbductNLI  MC-sent\n",
       "3      0.036461  AbductNLI  MC-sent\n",
       "4      0.092730  AbductNLI  MC-sent\n",
       "...         ...        ...      ...\n",
       "82751  0.095442        WSC  MC-sent\n",
       "82752  0.183235        WSC  MC-sent\n",
       "82753  0.142709        WSC  MC-sent\n",
       "82754  0.042870        WSC  MC-sent\n",
       "82755  0.055453        WSC  MC-sent\n",
       "\n",
       "[82756 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_scores_plot_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbb031b94344607ba20787e371db383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plot_box(\n",
    "    leh_scores_plot_bert,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "f.suptitle('All Models')\n",
    "f.savefig(os.path.join('..', 'plots_LEH_BERT', 'all_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf8de22b3da48d19a9b6eda10dd71d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftrimmed = plot_box(\n",
    "    leh_scores_plot_bert_trimmed,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")\n",
    "\n",
    "ftrimmed.suptitle('MiniBERTas + BERT')\n",
    "ftrimmed.savefig(os.path.join('..', 'plots_LEH_BERT', 'trimmed_models.png'),\n",
    "         format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "leh_tasks = pd.concat([\n",
    "    leh_scores_plot_bert.rename(columns={'mean':'Full'}),\n",
    "    pd.DataFrame(leh_scores_plot_bert_trimmed['mean']).rename(columns={'mean':'BERT'})\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median diff (magnitude) 0.006858755512025777\n",
      "standard deviation diff (magnitude) 0.010802470947845947\n",
      "median rel diff (magnitude) 0.05756958408841538\n"
     ]
    }
   ],
   "source": [
    "leh_tasks_qtile = leh_tasks.groupby(by='task_name').quantile(q=0.75)\n",
    "leh_tasks_qtile['diff'] = leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT']\n",
    "leh_tasks_qtile['rel_diff'] = (leh_tasks_qtile['Full'] - leh_tasks_qtile['BERT'])/leh_tasks_qtile['BERT']\n",
    "\n",
    "print('median diff (magnitude)', leh_tasks_qtile['diff'].abs().median())\n",
    "print('standard deviation diff (magnitude)', leh_tasks_qtile['diff'].abs().std())\n",
    "\n",
    "print('median rel diff (magnitude)', leh_tasks_qtile['rel_diff'].abs().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>Up to BERT</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Relative Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.165283</td>\n",
       "      <td>0.183855</td>\n",
       "      <td>-0.018571</td>\n",
       "      <td>-0.101011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.119056</td>\n",
       "      <td>0.136824</td>\n",
       "      <td>-0.017768</td>\n",
       "      <td>-0.129858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.098743</td>\n",
       "      <td>0.105602</td>\n",
       "      <td>-0.006859</td>\n",
       "      <td>-0.064949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.156538</td>\n",
       "      <td>0.162685</td>\n",
       "      <td>-0.006147</td>\n",
       "      <td>-0.037782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.081164</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>-0.004958</td>\n",
       "      <td>-0.057570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.156992</td>\n",
       "      <td>0.161736</td>\n",
       "      <td>-0.004744</td>\n",
       "      <td>-0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.143918</td>\n",
       "      <td>0.146788</td>\n",
       "      <td>-0.002870</td>\n",
       "      <td>-0.019554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.139869</td>\n",
       "      <td>0.141083</td>\n",
       "      <td>-0.001214</td>\n",
       "      <td>-0.008603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.176913</td>\n",
       "      <td>0.177229</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>-0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.138228</td>\n",
       "      <td>0.137522</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.005130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.159777</td>\n",
       "      <td>0.157061</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.017292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.139947</td>\n",
       "      <td>0.137026</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.021317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.198417</td>\n",
       "      <td>0.195312</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.015897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.157412</td>\n",
       "      <td>0.153708</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.024095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>0.192761</td>\n",
       "      <td>0.187115</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.030177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.123542</td>\n",
       "      <td>0.117422</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.052121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.136245</td>\n",
       "      <td>0.129773</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.049873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.206858</td>\n",
       "      <td>0.196631</td>\n",
       "      <td>0.010227</td>\n",
       "      <td>0.052012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.183016</td>\n",
       "      <td>0.171389</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.067835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.191539</td>\n",
       "      <td>0.178365</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.073864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.171956</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>0.086641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.184805</td>\n",
       "      <td>0.168119</td>\n",
       "      <td>0.016686</td>\n",
       "      <td>0.099249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.148616</td>\n",
       "      <td>0.129645</td>\n",
       "      <td>0.018971</td>\n",
       "      <td>0.146328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>0.250347</td>\n",
       "      <td>0.230511</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.086054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>0.183131</td>\n",
       "      <td>0.162492</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.127017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.222730</td>\n",
       "      <td>0.201757</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.103950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.168858</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.140267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>0.275141</td>\n",
       "      <td>0.235964</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.166029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.214448</td>\n",
       "      <td>0.171353</td>\n",
       "      <td>0.043095</td>\n",
       "      <td>0.251496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full  Up to BERT  Difference  Relative Difference\n",
       "task_name                                                        \n",
       "ARC-C       0.165283    0.183855   -0.018571            -0.101011\n",
       "WiC         0.119056    0.136824   -0.017768            -0.129858\n",
       "CB          0.098743    0.105602   -0.006859            -0.064949\n",
       "ANLI        0.156538    0.162685   -0.006147            -0.037782\n",
       "SNLI        0.081164    0.086122   -0.004958            -0.057570\n",
       "Winogrande  0.156992    0.161736   -0.004744            -0.029333\n",
       "PiQA        0.143918    0.146788   -0.002870            -0.019554\n",
       "COPA        0.139869    0.141083   -0.001214            -0.008603\n",
       "MC-TACO     0.176913    0.177229   -0.000315            -0.001778\n",
       "WSC         0.138228    0.137522    0.000706             0.005130\n",
       "ARCT        0.159777    0.157061    0.002716             0.017292\n",
       "MNLI        0.139947    0.137026    0.002921             0.021317\n",
       "ARC-E       0.198417    0.195312    0.003105             0.015897\n",
       "RTE         0.157412    0.153708    0.003704             0.024095\n",
       "MRQA-NQ     0.192761    0.187115    0.005647             0.030177\n",
       "BoolQ       0.123542    0.117422    0.006120             0.052121\n",
       "MCScript    0.136245    0.129773    0.006472             0.049873\n",
       "QAMR        0.206858    0.196631    0.010227             0.052012\n",
       "QuAIL       0.183016    0.171389    0.011626             0.067835\n",
       "MuTual+     0.191539    0.178365    0.013175             0.073864\n",
       "CosmosQA    0.186854    0.171956    0.014898             0.086641\n",
       "SocialIQA   0.184805    0.168119    0.016686             0.099249\n",
       "AbductNLI   0.148616    0.129645    0.018971             0.146328\n",
       "NewsQA      0.250347    0.230511    0.019836             0.086054\n",
       "SQuAD2.0    0.183131    0.162492    0.020639             0.127017\n",
       "CSQA        0.222730    0.201757    0.020973             0.103950\n",
       "MuTual      0.192543    0.168858    0.023685             0.140267\n",
       "Quoref      0.275141    0.235964    0.039177             0.166029\n",
       "HellaSwag   0.214448    0.171353    0.043095             0.251496"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.rename(columns={'BERT':'Up to BERT', 'diff':'Difference', 'rel_diff':'Relative Difference'}).sort_values(by='Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Full</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT</th>\n",
       "      <td>0.954725</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full      BERT\n",
       "Full  1.000000  0.954725\n",
       "BERT  0.954725  1.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leh_tasks_qtile.loc[:,['Full', 'BERT']].corr(method='pearson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
