{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+torch.exp(-x))\n",
    "\n",
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean'):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "    print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col].values), torch.tensor(beta[col].values)\n",
    "    \n",
    "    #logits = (a*(best_value-b))\n",
    "    logits = (torch.matmul(a,best_value.T) + b).T\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = sigmoids*(1.-sigmoids)*a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g)*scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_guide(alpha_dist, theta_dist, alpha_transform, theta_transform):\n",
    "    model = lambda obs: irt_model(obs, alpha_dist, theta_dist, alpha_transform = alpha_transform, theta_transform = theta_transform)\n",
    "    guide = lambda obs: vi_posterior(obs, alpha_dist, theta_dist)\n",
    "    \n",
    "    return model, guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_accuracies(data, verbose = False, get_cols = False):\n",
    "    '''\n",
    "    Method to reformat `data` and calculate item and responder accuracies.\n",
    "    \n",
    "    Args:\n",
    "        data:                DataFrame of item responses.\n",
    "        verbose:             Boolean value of whether to print statements.\n",
    "        get_cols:            Boolean value of whether to return original column\n",
    "                             values of `data`.\n",
    "        \n",
    "    Returns:\n",
    "        new_data:            Reformatted `data`, dropping first column.\n",
    "        accuracies:          Accuracy for each responder across examples.\n",
    "        example_accuracies:  Accuracy for each example across responders.\n",
    "        data.columns.values: Returns only if `get_cols` is True. Original column\n",
    "                             values of `data`.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    new_data = new_data[:,1:]\n",
    "    \n",
    "    model_names = dict(data['userid'])\n",
    "    accuracies = new_data.mean(-1)\n",
    "    example_accuracies = new_data.mean(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'.join([f'{name}: {acc}' for name, acc in zip(model_names.values(),accuracies)]))\n",
    "    \n",
    "    if get_cols:\n",
    "        return new_data, accuracies, example_accuracies, data.columns.values\n",
    "    else:\n",
    "        return new_data, accuracies, example_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_CI(params, p=0.95, dist='normal'):\n",
    "    '''\n",
    "    Method to calculate lower and upper quantiles defined by `p`, mean, and variance of `param`\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of distribution parameters for each item keyed according to the \n",
    "                parametric distribution defined by `dist`.\n",
    "        p:      Percent of distribution covered by the lower and upper interval values for each\n",
    "                parameter.\n",
    "        dist:   Name of parametric distribution\n",
    "    \n",
    "    Returns:\n",
    "        return: {\n",
    "            'lower': Lower interval values of each parameter,\n",
    "            'upper': Upper interval values of each parameter,\n",
    "            'mean' : Mean of each parameter,\n",
    "            'var'  : Variance of each parameter\n",
    "        }\n",
    "    '''\n",
    "    stats = {}\n",
    "    if dist == 'normal':\n",
    "        L,U = scipy.stats.norm.interval(p,loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "        M,V = scipy.stats.norm.stats(loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "    elif dist == 'log-normal':\n",
    "        L,U = scipy.stats.lognorm.interval(p, s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "        M,V = scipy.stats.lognorm.stats(s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "    elif dist == 'beta':\n",
    "        L,U = scipy.stats.beta.interval(p,a=params['alpha'], b=params['beta'])\n",
    "        M,V = scipy.stats.beta.stats(a=params['alpha'], b=params['beta'])\n",
    "    else:\n",
    "        raise TypeError(f'Distribution type {dist} not supported.')\n",
    "    \n",
    "    return {\n",
    "        'lower':[L],\n",
    "        'upper':[U],\n",
    "        'mean':[M],\n",
    "        'var':[V],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_stats(exp_dir, alpha_dist, theta_dist, transforms, p = 0.95):\n",
    "    '''\n",
    "    Method to return plotting statistics for 3 parameter IRT model parameters.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir:          Path to 3 parameter IRT parameters and responses.\n",
    "        alpha_dist:       Name of the item discrimination [a] distribution.\n",
    "        theta_dist:       Name of the responder ability [t] distribution.\n",
    "        transforms:       Dictionary of transformations to apply to each parameter type\n",
    "                          where keys are parameter names and values are functions.\n",
    "        p:                Percent of distribution covered by the lower and upper interval \n",
    "                          values for each parameter.\n",
    "    \n",
    "    Returns:\n",
    "        param_plot_stats: Dictionary of parameter plot statistics where keys are parameter\n",
    "                          names and values are plot statistics dictionaries as defined by\n",
    "                          get_stats_CI().\n",
    "    '''\n",
    "    param_dists = {\n",
    "        'a':alpha_dist,\n",
    "        'b':'normal',\n",
    "        'g':'normal',\n",
    "        't':theta_dist,\n",
    "    }\n",
    "\n",
    "    dist_params = {\n",
    "        'normal':['mu', 'logstd'],\n",
    "        'log-normal':['mu', 'logstd'],\n",
    "        'beta':['alpha', 'beta'],\n",
    "    }\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(os.path.join(exp_dir, 'params.p'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    # get stats for plotting\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for param, param_dist in param_dists.items():\n",
    "        temp_params = dist_params[param_dist]\n",
    "\n",
    "        for idx, (p1_orig, p2_orig) in enumerate(zip(pyro_param_dict[f'{param} {temp_params[0]}'], pyro_param_dict[f'{param} {temp_params[1]}'])):\n",
    "            p1, p2 = p1_orig.detach(), p2_orig.detach()\n",
    "            \n",
    "            temp_stats_df = pd.DataFrame.from_dict(\n",
    "                get_stats_CI(\n",
    "                    params = {\n",
    "                        temp_params[0]:p1,\n",
    "                        temp_params[1]:p2,\n",
    "                    },\n",
    "                    p=p,\n",
    "                    dist = param_dist,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            temp_stats_df = temp_stats_df.applymap(transforms[param])\n",
    "        \n",
    "            if idx == 0:\n",
    "                param_plot_stats[param] = temp_stats_df\n",
    "            else:\n",
    "                param_plot_stats[param] = param_plot_stats[param].append(temp_stats_df, ignore_index = True)\n",
    "    \n",
    "    return param_plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_mult(df1, df2):\n",
    "    newdf = copy.deepcopy(df2)\n",
    "    \n",
    "    for idx, row in df1.iterrows():\n",
    "        if numpy.sign(row['mean']) < 0:\n",
    "            newdf.loc[idx,'mean'] = -1*newdf.loc[idx,'mean']\n",
    "            newdf.loc[idx,'lower'] = -1*newdf.loc[idx,'upper']\n",
    "            newdf.loc[idx,'upper'] = -1*newdf.loc[idx,'lower']\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_by_set(diffs, item_ids):\n",
    "    diff_by_set = {}\n",
    "    id_split = '_'\n",
    "\n",
    "    max_diff = -1e6\n",
    "    min_diff = 1e6\n",
    "    \n",
    "    for idx, diff in enumerate(diffs):\n",
    "        set_name = item_ids[idx].split(id_split)[0]\n",
    "\n",
    "        if set_name in diff_by_set.keys():\n",
    "            diff_by_set[set_name].append(diff)\n",
    "        else:\n",
    "            diff_by_set[set_name] = [diff]\n",
    "            \n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            \n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "    \n",
    "    return diff_by_set, min_diff, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_virt_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad-v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "#datasets=\"snli\"\n",
    "datasets=\"sync_dim3_alpha-lognormal-2.00_theta-normal-2.00,sync_dim3_alpha-lognormal-7.00_theta-normal-10.00\"\n",
    "\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params_mvirt_sync', f'lr-0.0001-steps-$4000-alpha-lognormal-identity-dim3_theta-normal-identity_nosubsample_1.00_0.40_particles8')\n",
    "p = 0.95\n",
    "\n",
    "#combined_responses = pd.read_pickle(os.path.join(exp_dir, 'responses.p')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_responses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a7152669059e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc_by_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mroberta_rp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_responses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_responses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mextractmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mroberta_rp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mroberta_rp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta_rp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtie_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_responses' is not defined"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/phumon/Documents/Research/nlu-test-sets/params_mvirt_sync/lr-0.0001-steps-$4000-alpha-lognormal-identity-dim3_theta-normal-identity_nosubsample_1.00_0.40_particles8'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/phumon/Documents/Research/nlu-test-sets/params_mvirt_sync/lr-0.0001-steps-$4000-alpha-lognormal-identity-dim3_theta-normal-identity_nosubsample_1.00_0.40_particles8/responses.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-40fb75f60fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcombined_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'responses.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_responses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_responses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/latent_features/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     ) as handles:\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/latent_features/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/phumon/Documents/Research/nlu-test-sets/params_mvirt_sync/lr-0.0001-steps-$4000-alpha-lognormal-identity-dim3_theta-normal-identity_nosubsample_1.00_0.40_particles8/responses.p'"
     ]
    }
   ],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "#exp_dir = os.path.join(repo, 'params_snli', f'alpha-lognormal-identity-dim3_theta-normal-identity_nosubsample_1.00_0.50')\n",
    "p = 0.95\n",
    "\n",
    "#combined_responses = pd.read_pickle(os.path.join(exp_dir, 'responses.p')).reset_index()\n",
    "#data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "#column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join(exp_dir, 'plot_stats_pickles', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs(os.path.join(exp_dir, 'plot_stats_pickles'), exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join(exp_dir, 'plot_stats_pickles', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>snli_0</th>\n",
       "      <th>snli_1</th>\n",
       "      <th>snli_2</th>\n",
       "      <th>snli_3</th>\n",
       "      <th>snli_4</th>\n",
       "      <th>snli_5</th>\n",
       "      <th>snli_6</th>\n",
       "      <th>snli_7</th>\n",
       "      <th>snli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>snli_9814</th>\n",
       "      <th>snli_9815</th>\n",
       "      <th>snli_9816</th>\n",
       "      <th>snli_9817</th>\n",
       "      <th>snli_9818</th>\n",
       "      <th>snli_9819</th>\n",
       "      <th>snli_9820</th>\n",
       "      <th>snli_9821</th>\n",
       "      <th>snli_9822</th>\n",
       "      <th>snli_9823</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 9825 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  snli_0  snli_1  snli_2  snli_3  snli_4  snli_5  \\\n",
       "0     roberta-base-10M-1_25       1       1       1       1       0       0   \n",
       "1      roberta-base-10M-1_1       1       0       0       0       0       0   \n",
       "2     roberta-base-10M-1_50       1       1       1       1       0       0   \n",
       "3     roberta-base-10M-1_10       0       1       1       1       0       0   \n",
       "4   roberta-base-10M-1_best       1       1       1       1       0       0   \n",
       "..                      ...     ...     ...     ...     ...     ...     ...   \n",
       "85     xlm-roberta-large_25       1       1       1       1       1       1   \n",
       "86      xlm-roberta-large_1       0       1       0       0       1       0   \n",
       "87     xlm-roberta-large_50       1       1       1       1       1       0   \n",
       "88     xlm-roberta-large_10       0       1       1       1       0       0   \n",
       "89   xlm-roberta-large_best       1       1       1       1       1       1   \n",
       "\n",
       "    snli_6  snli_7  snli_8  ...  snli_9814  snli_9815  snli_9816  snli_9817  \\\n",
       "0        1       1       1  ...          1          1          1          0   \n",
       "1        1       1       0  ...          0          1          0          0   \n",
       "2        1       1       1  ...          1          1          1          0   \n",
       "3        1       1       0  ...          1          1          1          1   \n",
       "4        1       1       1  ...          1          1          1          0   \n",
       "..     ...     ...     ...  ...        ...        ...        ...        ...   \n",
       "85       1       1       1  ...          1          1          1          0   \n",
       "86       1       0       0  ...          1          1          0          0   \n",
       "87       1       1       1  ...          1          1          1          0   \n",
       "88       1       1       0  ...          1          1          1          0   \n",
       "89       1       1       1  ...          1          1          1          0   \n",
       "\n",
       "    snli_9818  snli_9819  snli_9820  snli_9821  snli_9822  snli_9823  \n",
       "0           1          1          1          1          1          1  \n",
       "1           0          0          1          1          1          0  \n",
       "2           1          1          1          1          1          1  \n",
       "3           1          1          1          1          1          1  \n",
       "4           1          1          1          1          1          1  \n",
       "..        ...        ...        ...        ...        ...        ...  \n",
       "85          1          1          1          1          1          1  \n",
       "86          0          0          1          0          1          0  \n",
       "87          1          1          1          1          1          1  \n",
       "88          1          1          1          1          1          1  \n",
       "89          1          1          1          1          1          1  \n",
       "\n",
       "[90 rows x 9825 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats.items():\n",
    "    param_stat['log_mean'] = param_stat['mean'].apply(lambda x: numpy.log(x))\n",
    "    \n",
    "    if param_key in ['a', 'theta', 'b']:\n",
    "        dimensions =  param_stat['log_mean'][0].shape[0]\n",
    "        for dim in range(dimensions):\n",
    "            param_stat['log_mean_'+str(dim)]= param_stat['log_mean'].apply(lambda x: x[dim])\n",
    "            param_stat['mean_'+str(dim)]= param_stat['mean'].apply(lambda x: x[dim])\n",
    "        \n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "param_b = pd.concat([param_plot_stats['b'], task_name_format], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_plot_stats['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean'):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "    print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col]), torch.tensor(beta[col])\n",
    "    \n",
    "    logits = (a*(best_value-b))\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = (sigmoids*(1.-sigmoids)).unsqueeze(1) * a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g).unsqueeze(1) *scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats['g'],\n",
    ")\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#leh_scores_plot = pd.concat([leh_scores_plot, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "- Distribution: log_normal\n",
    "- Constraint: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_label = 12\n",
    "font_legend = 10\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 12\n",
    "font_title = 14\n",
    "marker_scale = 1.5\n",
    "\n",
    "plot.rc('axes', labelsize=font_label)\n",
    "plot.rc('axes', titlesize=font_title)\n",
    "plot.rc('legend', fontsize=font_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, order, param_type, task_metadata, dim = 0, xsize=12, ysize=3.5, width=0.6, rotation=65, ylim=None, ystep=None):\n",
    "    \n",
    "    param2label = {\n",
    "        'discriminative':r'$\\log$ Discrimination ($\\log$ $\\alpha$)-Dim'+str(dim),\n",
    "        'difficulty': r'Difficulty ($\\beta$)-Dim'+str(dim),\n",
    "        \"disc-diff\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_pos\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"disc-diff_minmax\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "        \"irt-score\": \"LEH Score\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    if dim is None:\n",
    "        param2yname = {\n",
    "            'discriminative': \"log_mean\",\n",
    "            'difficulty': \"mean\",\n",
    "            \"disc-diff\": 0,\n",
    "            \"disc-diff_pos\": 0,\n",
    "            \"disc-diff_minmax\": 0,\n",
    "            \"irt-score\": \"mean\",\n",
    "        }\n",
    "    else:\n",
    "        param2yname = {\n",
    "            'discriminative': \"log_mean_\"+str(dim),\n",
    "            'difficulty': \"mean_\"+str(dim),\n",
    "            \"disc-diff\": 0,\n",
    "            \"disc-diff_pos\": 0,\n",
    "            \"disc-diff_minmax\": 0,\n",
    "            \"irt-score\": \"mean\",\n",
    "        }\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    f, ax = plot.subplots(figsize=(xsize, ysize))\n",
    "    \n",
    "    my_pal = {\"MC-par\": \"r\",\n",
    "              \"MC-sent\": \"b\",\n",
    "              \"classification\":\"g\",\n",
    "              \"span selection\": \"grey\"}    \n",
    "    \n",
    "    ax = sns.boxplot(x=\"task_name\", y=param2yname[param_type], data=df, order=order, width=width)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, task in enumerate(order):\n",
    "        # Select which box you want to change    \n",
    "        mybox = ax.artists[i]\n",
    "        \n",
    "        # Change the appearance of that box\n",
    "        skill = task_metadata.loc[task]['format']\n",
    "        mybox.set_facecolor(my_pal[skill])\n",
    "    \n",
    "    \n",
    "    # Add transparency to colors\n",
    "    for patch in ax.artists:\n",
    "         r, g, b, a = patch.get_facecolor()\n",
    "         patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "    sns.despine()\n",
    "    plot.xticks(range(len(order)), order, rotation=rotation, fontsize=font_xtick)\n",
    "    \n",
    "    if not ylim is None and not ystep is None:\n",
    "        plot.ylim(ylim)\n",
    "        plot.yticks(numpy.arange(ylim[0], ylim[1]+ystep, ystep))\n",
    "    \n",
    "    plot.xlabel(None)\n",
    "    plot.ylabel(param2label[param_type], fontsize=font_label)\n",
    "    \n",
    "    plot.savefig('../plots/' + param_type + \"_box.png\",\n",
    "                format='png', dpi=300,\n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_a,\n",
    "    task_order,\n",
    "    \"discriminative\",\n",
    "    task_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_a,\n",
    "    task_order,\n",
    "    \"discriminative\",\n",
    "    task_metadata,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_a,\n",
    "    task_order,\n",
    "    \"discriminative\",\n",
    "    task_metadata,\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_b,\n",
    "    task_order,\n",
    "    \"difficulty\",\n",
    "    task_metadata,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_b,\n",
    "    task_order,\n",
    "    \"difficulty\",\n",
    "    task_metadata,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    param_b,\n",
    "    task_order,\n",
    "    \"difficulty\",\n",
    "    task_metadata,\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_box(\n",
    "    leh_scores_plot,\n",
    "    task_order,\n",
    "    \"irt-score\",\n",
    "    task_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=0\n",
    "xsize = 12\n",
    "ysize = 7\n",
    "width = 0.6\n",
    "rotation = 65\n",
    "order = task_order\n",
    "\n",
    "\n",
    "param2label = {\n",
    "    'discriminative':r'$\\log$ Discrimination ($\\log$ $\\alpha$)-Dim'+str(dim),\n",
    "    'difficulty': r'Difficulty ($\\beta$)-Dim'+str(dim),\n",
    "    \"disc-diff\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "    \"disc-diff_pos\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "    \"disc-diff_minmax\": \"IRT Score\", # \"discrimination - difficulty product\\n\", # + r\"($ n(\\alpha) x n(\\beta$) )\"\n",
    "}\n",
    "\n",
    "param2yname = {\n",
    "    'discriminative': \"log_mean_\"+str(dim),\n",
    "    'difficulty': \"mean_\"+str(dim),\n",
    "    \"disc-diff\": 0,\n",
    "    \"disc-diff_pos\": 0,\n",
    "    \"disc-diff_minmax\": 0,\n",
    "}\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "f, (ax1, ax2) = plot.subplots(nrows=2, ncols=1, squeeze=True, sharex=True, figsize=(xsize, ysize))\n",
    "\n",
    "my_pal = {\"MC-par\": \"r\",\n",
    "          \"MC-sent\": \"b\",\n",
    "          \"classification\":\"g\",\n",
    "          \"span selection\": \"grey\"}    \n",
    "\n",
    "param_type = \"discriminative\"\n",
    "ax = sns.boxplot(x=\"task_name\", y=param2yname[\"discriminative\"], data=param_a, order=order, width=width, ax=ax1)\n",
    "\n",
    "\n",
    "for i, task in enumerate(order):\n",
    "    # Select which box you want to change    \n",
    "    mybox = ax.artists[i]\n",
    "\n",
    "    # Change the appearance of that box\n",
    "    skill = task_metadata.loc[task]['format']\n",
    "    mybox.set_facecolor(my_pal[skill])\n",
    "\n",
    "\n",
    "# Add transparency to colors\n",
    "for patch in ax.artists:\n",
    "     r, g, b, a = patch.get_facecolor()\n",
    "     patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "ax1.set_ylabel(param2label[param_type], fontsize=font_label)\n",
    "ax1.set_xlabel(\"\")\n",
    "\n",
    "param_type = \"difficulty\"\n",
    "ax = sns.boxplot(x=\"task_name\", y=param2yname[\"difficulty\"], data=param_b, order=order, width=width, ax=ax2)\n",
    "\n",
    "\n",
    "for i, task in enumerate(order):\n",
    "    # Select which box you want to change    \n",
    "    mybox = ax.artists[i]\n",
    "\n",
    "    # Change the appearance of that box\n",
    "    skill = task_metadata.loc[task]['format']\n",
    "    mybox.set_facecolor(my_pal[skill])\n",
    "\n",
    "\n",
    "# Add transparency to colors\n",
    "for patch in ax.artists:\n",
    "     r, g, b, a = patch.get_facecolor()\n",
    "     patch.set_facecolor((r, g, b, .6))\n",
    "\n",
    "sns.despine()\n",
    "plot.xticks(range(len(order)), order, rotation=rotation, fontsize=font_xtick)\n",
    "plot.xlabel(None)\n",
    "ax2.set_ylabel(param2label[param_type], fontsize=font_label)\n",
    "\n",
    "plot.subplots_adjust(hspace=0.1)\n",
    "\n",
    "plot.savefig('../plots/disc_diff_combined_box.png',\n",
    "            format='png', dpi=300,\n",
    "            bbox_inches = 'tight',\n",
    "            pad_inches = .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per dataset analysis - single scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_scatter_plot(param1, param2, label1, label2, ymin, ymax, step, taskname, order, dim=0):\n",
    "    \n",
    "    param2label = {\n",
    "        'alpha':r'$\\log$ Discrimination ($\\log$ $\\alpha$)-Dim',\n",
    "        'beta': r'Difficulty ($\\beta$)-Dim',\n",
    "        'gamma': r'Guessing ($\\gamma$)'\n",
    "    }\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.despine(offset=5, trim=True)\n",
    "\n",
    "    keys = [\n",
    "        'lower1', \n",
    "        'upper1', \n",
    "        'mean1', \n",
    "        'var1', \n",
    "        'log_mean1',\n",
    "        param2label[label1]+'0',\n",
    "        'mean_0_1',\n",
    "        param2label[label1]+'1',\n",
    "        'mean_1_1',\n",
    "        param2label[label1]+'2',\n",
    "        'mean_2_1',\n",
    "        'lower2',\n",
    "        'upper2',\n",
    "        'mean2',\n",
    "        'var2',\n",
    "        'log_mean2',\n",
    "        'log_mean_0_2',\n",
    "        param2label[label2]+'0',\n",
    "        'log_mean_1_2',\n",
    "        param2label[label2]+'1',\n",
    "        'log_mean_2_2',\n",
    "        param2label[label2]+'2',\n",
    "        'task',\n",
    "        'format'\n",
    "    ]\n",
    "    combined_data = pd.concat([param1, param2, taskname], axis=1)\n",
    "    combined_data = combined_data.set_axis(keys, axis=1)\n",
    "\n",
    "    # Create an array with the colors you want to use\n",
    "    colors = ['b', 'r', 'g', 'grey']\n",
    "    # Set your custom color palette\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "    grid = sns.FacetGrid(combined_data, col=\"task\", hue=\"format\",\n",
    "                         col_order=order,\n",
    "                         palette=customPalette,\n",
    "                         col_wrap=7, height=2)\n",
    "\n",
    "    grid.map(plot.scatter, param2label[label1]+str(dim), param2label[label2]+str(dim), marker=\".\", s=1, alpha=0.75)\n",
    "    grid.set_titles(size=font_title)\n",
    "\n",
    "    # Adjust the tick positions and labels\n",
    "    grid.set(xticks=np.arange(-1, 1.5, 0.5), yticks=np.arange(ymin, ymax, step),\n",
    "             xlim=(-1, 1), ylim=(ymin, ymax), )\n",
    "    \n",
    "    grid.set_axis_labels('', '')\n",
    "    \n",
    "    grid.fig.text(\n",
    "        x=-0.01, y=0.5,\n",
    "        verticalalignment='center',\n",
    "        s=param2label[label2]+str(dim),\n",
    "        size=font_label,\n",
    "        rotation=90,\n",
    "    )\n",
    "    \n",
    "    grid.fig.text(\n",
    "        x=0.5, y=-0.01,\n",
    "        horizontalalignment='center',\n",
    "        s=param2label[label1]+str(dim),\n",
    "        size=font_label,\n",
    "    )\n",
    "    \n",
    "    # Adjust sub-plot title\n",
    "    axes = grid.axes.flatten()\n",
    "    for ax in axes:\n",
    "        new_title = ax.get_title().replace('task = ', '')\n",
    "        ax.set_title(new_title)\n",
    "        \n",
    "    # Adjust the arrangement of the plots\n",
    "    grid.fig.tight_layout()\n",
    "    plot.subplots_adjust(hspace=0.2)\n",
    "    \n",
    "    plot.savefig('../plots/single_' + label1 + '_' + label2 + \".png\",\n",
    "                format='png',dpi=300,bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax, step = -2, 4, 1\n",
    "single_scatter_plot(param_plot_stats['a'], param_plot_stats['b'], 'alpha', 'beta', ymin, ymax, step, task_name_format, task_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax, step = -2, 4, 1\n",
    "single_scatter_plot(param_plot_stats['a'], param_plot_stats['b'], 'alpha', 'beta', ymin, ymax, step, task_name_format, task_order, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax, step = -2, 4, 1\n",
    "single_scatter_plot(param_plot_stats['a'], param_plot_stats['b'], 'alpha', 'beta', ymin, ymax, step, task_name_format, task_order, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ymin, ymax, step = 0, 1.0, 0.2\n",
    "single_scatter_plot(param_plot_stats['a'], param_plot_stats['g'], 'alpha', 'gamma', ymin, ymax, step, task_name_format, task_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Model'\n",
    "checkpoint_name = 'Checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2plot = {\n",
    "    'roberta-med-small-1M': r'RoBERTa-Med-Small-1M',\n",
    "    'roberta-base-10M': r'RoBERTa-Base-10M',\n",
    "    'roberta-base-100M': r'RoBERTa-Base-100M',\n",
    "    'roberta-base-1B': r'RoBERTa-Base-1B',\n",
    "    'bert-base-cased': r'BERT-Base',\n",
    "    'bert-large-cased': r'BERT-Large',\n",
    "    'roberta-base': r'RoBERTa-Base',\n",
    "    'roberta-large': r'RoBERTa-Large',\n",
    "    'xlm-roberta-large': r'XLM-R-Large',\n",
    "    'albert-xxlarge-v2': r'ALBERT-XXL-v2',\n",
    "}\n",
    "model_names = [model2plot[name] for name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.DataFrame(accuracies, columns=['acc.'])\n",
    "df_model = pd.DataFrame(model_names, columns=[model_name])\n",
    "df_mlevel = pd.DataFrame(model_levels, columns=[checkpoint_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "font_label = 14\n",
    "font_legend = 14\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 14\n",
    "font_title = 14\n",
    "marker_scale = 1.5\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "keys = ['acc.', 'lower', 'upper', 'theta', 'var', 'log_mean', model_name, checkpoint_name]\n",
    "combined_data = pd.concat([df_acc, param_plot_stats['t'], df_model, df_mlevel], axis=1)\n",
    "combined_data = combined_data.set_axis(keys, axis=1)\n",
    "hue_order = ['roberta-med-small-1M', 'roberta-base-10M', 'roberta-base-100M', 'roberta-base-1B', 'bert-base-cased', 'bert-large-cased',\n",
    "            'roberta-base', 'roberta-large', 'xlm-roberta-large', 'albert-xxlarge-v2']\n",
    "hue_order = [model2plot[name] for name in hue_order]\n",
    "style_order = [r'1%', r'10%', r'25%', r'50%', 'best']\n",
    "\n",
    "level2marker = {\n",
    "    r'1%':'o',\n",
    "    r'10%':'s',\n",
    "    r'25%':'P',\n",
    "    r'50%':'X',\n",
    "    'best':'^',\n",
    "}\n",
    "\n",
    "sizes = [5, 50, 100, 200, 400]\n",
    "size_order = [r'1%', r'10%', r'25%', r'50%', 'best']\n",
    "\n",
    "f, ax = plot.subplots(figsize=(14, 4))\n",
    "sns.despine()\n",
    "\n",
    "x_lbl, y_lbl = 'theta', 'acc.'\n",
    "prefix = ''\n",
    "\n",
    "# Create an array with the colors you want to use\n",
    "colors = ['r', 'b', 'g', 'm', 'grey', 'orange', 'olive', 'teal', 'skyblue', 'navy']\n",
    "# Set your custom color palette\n",
    "customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "ax = sns.scatterplot(data=combined_data, x=x_lbl, y=y_lbl,\n",
    "                alpha=0.7,\n",
    "                palette=customPalette,\n",
    "                linewidth=0,\n",
    "                markers=level2marker,\n",
    "                style=checkpoint_name,\n",
    "                style_order=style_order,\n",
    "                s=200,\n",
    "                hue_order=hue_order,\n",
    "                hue=model_name)\n",
    "\n",
    "\n",
    "plot.xlabel(prefix + r'Ability ($\\theta$)', fontsize=font_label)\n",
    "plot.ylabel(r'Average Model Accuracy', fontsize=font_label)\n",
    "plot.legend(\n",
    "    borderaxespad=0,\n",
    "    loc=\"right center\",\n",
    "    ncol=2,\n",
    "    bbox_to_anchor=(1,1),\n",
    "    fontsize=font_legend,\n",
    "    title_fontsize=font_legendtitle,\n",
    "    markerscale=marker_scale,\n",
    ")\n",
    "f.tight_layout()\n",
    "\n",
    "plot.savefig(\"../plots/acc_\" + prefix + \"theta.png\",\n",
    "                format='png',dpi=300,bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_perf = pd.read_csv('model_performance.csv')\n",
    "df_model_perf = df_model_perf.melt(id_vars=[\"Task\"])\n",
    "df_model_perf = df_model_perf.set_axis([\"task\", \"model\", \"accuracy\"], axis=1)\n",
    "df = df_model_perf[df_model_perf.model.isin(['roberta-large', 'roberta-med-small-1M', 'albert-xxlarge-v2'])]\n",
    "df = df.replace({\"roberta-large\": \"RoBERTa-Large\", \"roberta-med-small-1M\": \"RoBERTa-Med-Small-1M-2\", \"albert-xxlarge-v2\":\"ALBERT-XXL-v2\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_label = 24\n",
    "font_legend = 24\n",
    "font_legendtitle = font_legend + 4\n",
    "font_xtick = 24\n",
    "font_title = 24\n",
    "marker_scale = 1.5\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create an array with the colors you want to use\n",
    "colors = ['navy', 'b', 'skyblue', 'olive', 'teal', 'g', 'navy']\n",
    "# Set your custom color palette\n",
    "customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "\n",
    "f, ax = plot.subplots(figsize=(30, 7))\n",
    "order = task_order\n",
    "sns.barplot(x=\"task\", y=\"accuracy\", hue=\"model\", data=df, order=order)\n",
    "plot.xticks(range(len(order)), order, rotation=45, fontsize=font_xtick)\n",
    "sns.despine()\n",
    "\n",
    "plot.xlabel('Tasks', fontsize=font_label)\n",
    "plot.xlabel(None)\n",
    "plot.ylabel('Model Performance', fontsize=font_label)\n",
    "\n",
    "# Shrink current axis's height by 10% on the bottom\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                 box.width, box.height * 0.9])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),\n",
    "          fancybox=True, shadow=True, ncol=5, prop=dict(size=24))\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "plot.savefig(\"../plots/results.png\",\n",
    "                format='png',dpi=300,bbox_inches = 'tight',\n",
    "                pad_inches = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
