{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle5 as pickle\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import torch\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.infer.mcmc\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1.+torch.exp(-x))\n",
    "\n",
    "def icc_best_deriv(alpha, beta, theta, model_names, gamma=None, col='mean'):\n",
    "    '''\n",
    "    Method to calculate the locally estimated headroom (LEH) score, defined as\n",
    "    the derivative of the item characteristic curve w.r.t. the best performing model.\n",
    "    \n",
    "    Args:\n",
    "        alpha:       DataFrame of discrimination parameter statistics for each item.\n",
    "        beta:        DataFrame of difficulty parameter statistics for each item.\n",
    "        theta:       DataFrame of ability parameter statistics for each responder.\n",
    "        model_names: List of responder names.\n",
    "        gamma:       DataFrame of guessing parameter statistics for each item.\n",
    "        col:         DataFrame column name to use for calculating LEH scores.\n",
    "    \n",
    "    Returns:\n",
    "        scores:      LEH scores for each item.    \n",
    "    '''\n",
    "    best_idx, best_value = theta[col].argmax(), theta[col].max()\n",
    "    print(f'Best model: {model_names[best_idx]}\\n{best_value}')\n",
    "    \n",
    "    a, b = torch.tensor(alpha[col].values), torch.tensor(beta[col].values)\n",
    "    \n",
    "    logits = (a*(best_value-b))\n",
    "    sigmoids = sigmoid(logits)\n",
    "    scores = sigmoids*(1.-sigmoids)*a\n",
    "    \n",
    "    print(f'No gamma: {scores.mean()}')\n",
    "    if not gamma is None:\n",
    "        g = torch.tensor(gamma[col].apply(lambda x: x.item()).values)\n",
    "        scores = (1.-g)*scores\n",
    "        print(f'With gamma: {scores.mean()}')\n",
    "    \n",
    "    return scores      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model_guide(alpha_dist, theta_dist, alpha_transform, theta_transform):\n",
    "    model = lambda obs: irt_model(obs, alpha_dist, theta_dist, alpha_transform = alpha_transform, theta_transform = theta_transform)\n",
    "    guide = lambda obs: vi_posterior(obs, alpha_dist, theta_dist)\n",
    "    \n",
    "    return model, guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_data_accuracies(data, verbose = False, get_cols = False):\n",
    "    '''\n",
    "    Method to reformat `data` and calculate item and responder accuracies.\n",
    "    \n",
    "    Args:\n",
    "        data:                DataFrame of item responses.\n",
    "        verbose:             Boolean value of whether to print statements.\n",
    "        get_cols:            Boolean value of whether to return original column\n",
    "                             values of `data`.\n",
    "        \n",
    "    Returns:\n",
    "        new_data:            Reformatted `data`, dropping first column.\n",
    "        accuracies:          Accuracy for each responder across examples.\n",
    "        example_accuracies:  Accuracy for each example across responders.\n",
    "        data.columns.values: Returns only if `get_cols` is True. Original column\n",
    "                             values of `data`.\n",
    "    '''\n",
    "    new_data = numpy.array(data)\n",
    "    new_data = new_data[:,1:]\n",
    "    \n",
    "    model_names = dict(data['userid'])\n",
    "    accuracies = new_data.mean(-1)\n",
    "    example_accuracies = new_data.mean(0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\n'.join([f'{name}: {acc}' for name, acc in zip(model_names.values(),accuracies)]))\n",
    "    \n",
    "    if get_cols:\n",
    "        return new_data, accuracies, example_accuracies, data.columns.values\n",
    "    else:\n",
    "        return new_data, accuracies, example_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_stats_CI(params, p=0.95, dist='normal'):\n",
    "    '''\n",
    "    Method to calculate lower and upper quantiles defined by `p`, mean, and variance of `param`\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of distribution parameters for each item keyed according to the \n",
    "                parametric distribution defined by `dist`.\n",
    "        p:      Percent of distribution covered by the lower and upper interval values for each\n",
    "                parameter.\n",
    "        dist:   Name of parametric distribution\n",
    "    \n",
    "    Returns:\n",
    "        return: {\n",
    "            'lower': Lower interval values of each parameter,\n",
    "            'upper': Upper interval values of each parameter,\n",
    "            'mean' : Mean of each parameter,\n",
    "            'var'  : Variance of each parameter\n",
    "        }\n",
    "    '''\n",
    "    stats = {}\n",
    "    if dist == 'normal':\n",
    "        L,U = scipy.stats.norm.interval(p,loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "        M,V = scipy.stats.norm.stats(loc=params['mu'], scale=torch.exp(params['logstd']))\n",
    "    elif dist == 'log-normal':\n",
    "        L,U = scipy.stats.lognorm.interval(p, s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "        M,V = scipy.stats.lognorm.stats(s=torch.exp(params['logstd']), scale=torch.exp(params['mu']))\n",
    "    elif dist == 'beta':\n",
    "        L,U = scipy.stats.beta.interval(p,a=params['alpha'], b=params['beta'])\n",
    "        M,V = scipy.stats.beta.stats(a=params['alpha'], b=params['beta'])\n",
    "    else:\n",
    "        raise TypeError(f'Distribution type {dist} not supported.')\n",
    "    \n",
    "    return {\n",
    "        'lower':[L],\n",
    "        'upper':[U],\n",
    "        'mean':[M],\n",
    "        'var':[V],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_plot_stats(exp_dir, alpha_dist, theta_dist, transforms, p = 0.95):\n",
    "    '''\n",
    "    Method to return plotting statistics for 3 parameter IRT model parameters.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir:          Path to 3 parameter IRT parameters and responses.\n",
    "        alpha_dist:       Name of the item discrimination [a] distribution.\n",
    "        theta_dist:       Name of the responder ability [t] distribution.\n",
    "        transforms:       Dictionary of transformations to apply to each parameter type\n",
    "                          where keys are parameter names and values are functions.\n",
    "        p:                Percent of distribution covered by the lower and upper interval \n",
    "                          values for each parameter.\n",
    "    \n",
    "    Returns:\n",
    "        param_plot_stats: Dictionary of parameter plot statistics where keys are parameter\n",
    "                          names and values are plot statistics dictionaries as defined by\n",
    "                          get_stats_CI().\n",
    "    '''\n",
    "    param_dists = {\n",
    "        'a':alpha_dist,\n",
    "        'b':'normal',\n",
    "        'g':'normal',\n",
    "        't':theta_dist,\n",
    "    }\n",
    "\n",
    "    dist_params = {\n",
    "        'normal':['mu', 'logstd'],\n",
    "        'log-normal':['mu', 'logstd'],\n",
    "        'beta':['alpha', 'beta'],\n",
    "    }\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    pyro.get_param_store().load(os.path.join(exp_dir, 'params.p'))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pyro_param_dict = dict(pyro.get_param_store().named_parameters())\n",
    "    \n",
    "    # get stats for plotting\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for param, param_dist in param_dists.items():\n",
    "        temp_params = dist_params[param_dist]\n",
    "\n",
    "        for idx, (p1_orig, p2_orig) in enumerate(zip(pyro_param_dict[f'{param} {temp_params[0]}'], pyro_param_dict[f'{param} {temp_params[1]}'])):\n",
    "            p1, p2 = p1_orig.detach(), p2_orig.detach()\n",
    "            \n",
    "            temp_stats_df = pd.DataFrame.from_dict(\n",
    "                get_stats_CI(\n",
    "                    params = {\n",
    "                        temp_params[0]:p1,\n",
    "                        temp_params[1]:p2,\n",
    "                    },\n",
    "                    p=p,\n",
    "                    dist = param_dist,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            temp_stats_df = temp_stats_df.applymap(transforms[param])\n",
    "        \n",
    "            if idx == 0:\n",
    "                param_plot_stats[param] = temp_stats_df\n",
    "            else:\n",
    "                param_plot_stats[param] = param_plot_stats[param].append(temp_stats_df, ignore_index = True)\n",
    "    \n",
    "    return param_plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sign_mult(df1, df2):\n",
    "    newdf = copy.deepcopy(df2)\n",
    "    \n",
    "    for idx, row in df1.iterrows():\n",
    "        if numpy.sign(row['mean']) < 0:\n",
    "            newdf.loc[idx,'mean'] = -1*newdf.loc[idx,'mean']\n",
    "            newdf.loc[idx,'lower'] = -1*newdf.loc[idx,'upper']\n",
    "            newdf.loc[idx,'upper'] = -1*newdf.loc[idx,'lower']\n",
    "    \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_diff_by_set(diffs, item_ids):\n",
    "    diff_by_set = {}\n",
    "    id_split = '_'\n",
    "\n",
    "    max_diff = -1e6\n",
    "    min_diff = 1e6\n",
    "    \n",
    "    for idx, diff in enumerate(diffs):\n",
    "        set_name = item_ids[idx].split(id_split)[0]\n",
    "\n",
    "        if set_name in diff_by_set.keys():\n",
    "            diff_by_set[set_name].append(diff)\n",
    "        else:\n",
    "            diff_by_set[set_name] = [diff]\n",
    "            \n",
    "        if diff < min_diff:\n",
    "            min_diff = diff\n",
    "            \n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "    \n",
    "    return diff_by_set, min_diff, max_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from variational_irt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,adversarial-nli,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad-v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data_trimmed_item'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format_trimmed = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params_trimmed_item', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large_best\n",
      "==========================================================================================\n",
      "Overall acc: 0.7692\n",
      "abductive_nli acc: 0.8564\n",
      "adversarial_nli acc: 0.4995\n",
      "arc_challenge acc: 0.3319\n",
      "arc_easy acc: 0.6299\n",
      "arct acc: 0.8604\n",
      "boolq acc: 0.8217\n",
      "cb acc: 0.8571\n",
      "commonsenseqa acc: 0.6759\n",
      "copa acc: 0.8400\n",
      "cosmosqa acc: 0.8000\n",
      "hellaswag acc: 0.8420\n",
      "mcscript acc: 0.9183\n",
      "mctaco acc: 0.6010\n",
      "mnli acc: 0.8995\n",
      "mrqa_natural_questions acc: 0.7489\n",
      "mutual_plus acc: 0.7314\n",
      "mutual acc: 0.8668\n",
      "newsqa acc: 0.6608\n",
      "piqa acc: 0.7617\n",
      "qamr acc: 0.7944\n",
      "quail acc: 0.6691\n",
      "quoref acc: 0.8241\n",
      "rte acc: 0.8345\n",
      "snli acc: 0.9192\n",
      "socialiqa acc: 0.7738\n",
      "squad_v2 acc: 0.4395\n",
      "wic acc: 0.7085\n",
      "winogrande acc: 0.7697\n",
      "wsc acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir = os.path.join(repo, 'params_trimmed_item', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()\n",
    "data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats_trimmed = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_item', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats_trimmed[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles_trimmed_item', exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join('plot_stats_pickles_trimmed_item', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <th>abductive_nli_5</th>\n",
       "      <th>abductive_nli_6</th>\n",
       "      <th>abductive_nli_7</th>\n",
       "      <th>abductive_nli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>wsc_42</th>\n",
       "      <th>wsc_43</th>\n",
       "      <th>wsc_44</th>\n",
       "      <th>wsc_45</th>\n",
       "      <th>wsc_46</th>\n",
       "      <th>wsc_47</th>\n",
       "      <th>wsc_48</th>\n",
       "      <th>wsc_49</th>\n",
       "      <th>wsc_50</th>\n",
       "      <th>wsc_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 78722 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  abductive_nli_0  abductive_nli_1  \\\n",
       "0   roberta-base-10M-1_best                1                0   \n",
       "1      roberta-base-10M-1_1                0                0   \n",
       "2     roberta-base-10M-1_25                1                1   \n",
       "3     roberta-base-10M-1_50                1                0   \n",
       "4     roberta-base-10M-1_10                1                0   \n",
       "..                      ...              ...              ...   \n",
       "85   xlm-roberta-large_best                1                1   \n",
       "86      xlm-roberta-large_1                1                1   \n",
       "87     xlm-roberta-large_25                1                1   \n",
       "88     xlm-roberta-large_50                1                1   \n",
       "89     xlm-roberta-large_10                0                1   \n",
       "\n",
       "    abductive_nli_2  abductive_nli_3  abductive_nli_4  abductive_nli_5  \\\n",
       "0                 1                1                1                1   \n",
       "1                 0                1                1                0   \n",
       "2                 1                1                1                1   \n",
       "3                 1                1                1                1   \n",
       "4                 1                1                1                1   \n",
       "..              ...              ...              ...              ...   \n",
       "85                0                1                1                1   \n",
       "86                0                1                1                0   \n",
       "87                0                1                1                1   \n",
       "88                1                1                1                1   \n",
       "89                0                1                1                0   \n",
       "\n",
       "    abductive_nli_6  abductive_nli_7  abductive_nli_8  ...  wsc_42  wsc_43  \\\n",
       "0                 1                0                1  ...       1       0   \n",
       "1                 1                0                1  ...       1       0   \n",
       "2                 1                1                1  ...       0       0   \n",
       "3                 1                0                1  ...       1       0   \n",
       "4                 1                0                1  ...       1       0   \n",
       "..              ...              ...              ...  ...     ...     ...   \n",
       "85                1                1                1  ...       1       1   \n",
       "86                1                0                1  ...       0       0   \n",
       "87                0                1                1  ...       1       1   \n",
       "88                1                1                1  ...       1       1   \n",
       "89                0                1                1  ...       0       0   \n",
       "\n",
       "    wsc_44  wsc_45  wsc_46  wsc_47  wsc_48  wsc_49  wsc_50  wsc_51  \n",
       "0        1       1       0       1       0       1       0       1  \n",
       "1        1       0       0       1       0       0       0       1  \n",
       "2        0       1       0       1       1       1       1       1  \n",
       "3        0       1       0       1       1       1       0       1  \n",
       "4        0       1       0       1       1       1       0       1  \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "85       0       1       0       1       1       1       0       0  \n",
       "86       1       0       1       0       0       0       1       1  \n",
       "87       0       1       0       1       1       1       0       0  \n",
       "88       0       1       0       1       1       1       0       0  \n",
       "89       1       0       1       0       0       0       1       1  \n",
       "\n",
       "[90 rows x 78722 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 35469\n",
      "g 0\n",
      "t 46\n"
     ]
    }
   ],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats_trimmed.items():\n",
    "    param_stat['log_mean'] = numpy.log(param_stat['mean'])\n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats_trimmed['a'], task_name_format_trimmed], axis=1)\n",
    "param_b = pd.concat([param_plot_stats_trimmed['b'], task_name_format_trimmed], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: albert-xxlarge-v2\n",
      "1.7979713678359985\n",
      "No gamma: 0.14499040325361917\n",
      "With gamma: 0.11655480116768933\n",
      "           mean\n",
      "0      0.166683\n",
      "1      0.221677\n",
      "2      0.087377\n",
      "3      0.014670\n",
      "4      0.098858\n",
      "...         ...\n",
      "78716  0.048649\n",
      "78717  0.106998\n",
      "78718  0.084177\n",
      "78719  0.188978\n",
      "78720  0.081421\n",
      "\n",
      "[78721 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats_trimmed['a'],\n",
    "    param_plot_stats_trimmed['b'],\n",
    "    param_plot_stats_trimmed['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats_trimmed['g'],\n",
    ")\n",
    "\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot_trimmed = pd.concat([leh_scores_plot, task_name_format_trimmed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from variational_irt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasets=\"boolq,cb,commonsenseqa,copa,cosmosqa,hellaswag,adversarial-nli,rte,snli,wic,qamr,arct,mcscript,mctaco,mutual,mutual-plus,quoref,socialiqa,squad-v2,wsc,mnli,mrqa-nq,newsqa,abductive-nli,arc-easy,arc-challenge,piqa,quail,winogrande,anli\"\n",
    "data_names, responses, n_items = get_files(\n",
    "    os.path.join(repo, 'data'),\n",
    "    \"csv\",\n",
    "    set(datasets.split(','))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_metadata = pd.read_csv('task_metadata.csv')\n",
    "task_metadata.set_index(\"jiant_name\", inplace=True)\n",
    "task_list = [x for x in task_metadata.index if x in data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "task_name = []\n",
    "task_format = []\n",
    "\n",
    "for tname, size in zip(data_names, n_items):\n",
    "    name = task_metadata.loc[tname]['taskname']\n",
    "    total += size\n",
    "    task_name += [name for _ in range(size)]\n",
    "    task_format += [task_metadata.loc[tname]['format'] for _ in range(size)]\n",
    "    \n",
    "task_name = pd.DataFrame(task_name, columns=['task_name'])\n",
    "task_format = pd.DataFrame(task_format, columns=['format'])\n",
    "task_name_format = pd.concat([task_name, task_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Get Params and Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(repo, 'params_trimmed_item', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-large_best\n",
      "==========================================================================================\n",
      "Overall acc: 0.7692\n",
      "abductive_nli acc: 0.8564\n",
      "adversarial_nli acc: 0.4995\n",
      "arc_challenge acc: 0.3319\n",
      "arc_easy acc: 0.6299\n",
      "arct acc: 0.8604\n",
      "boolq acc: 0.8217\n",
      "cb acc: 0.8571\n",
      "commonsenseqa acc: 0.6759\n",
      "copa acc: 0.8400\n",
      "cosmosqa acc: 0.8000\n",
      "hellaswag acc: 0.8420\n",
      "mcscript acc: 0.9183\n",
      "mctaco acc: 0.6010\n",
      "mnli acc: 0.8995\n",
      "mrqa_natural_questions acc: 0.7489\n",
      "mutual_plus acc: 0.7314\n",
      "mutual acc: 0.8668\n",
      "newsqa acc: 0.6608\n",
      "piqa acc: 0.7617\n",
      "qamr acc: 0.7944\n",
      "quail acc: 0.6691\n",
      "quoref acc: 0.8241\n",
      "rte acc: 0.8345\n",
      "snli acc: 0.9192\n",
      "socialiqa acc: 0.7738\n",
      "squad_v2 acc: 0.4395\n",
      "wic acc: 0.7085\n",
      "winogrande acc: 0.7697\n",
      "wsc acc: 0.6154\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of roberta-large models\n",
    "\n",
    "extractmodel = 'roberta-large_best'\n",
    "tie_break = 0\n",
    "\n",
    "acc_by_dataset = {}\n",
    "\n",
    "roberta_rp = combined_responses.loc[combined_responses['userid']==extractmodel, :]\n",
    "if roberta_rp.shape[0] > 1:\n",
    "    roberta_rp = roberta_rp.iloc[tie_break, :]\n",
    "\n",
    "cols = combined_responses.columns.values\n",
    "\n",
    "for item in cols[1:]:\n",
    "    data_name = '_'.join(item.split('_')[:-1])\n",
    "    resp = roberta_rp[item].item()\n",
    "    \n",
    "    if data_name in acc_by_dataset:\n",
    "        acc_by_dataset[data_name]['correct'] += resp\n",
    "        acc_by_dataset[data_name]['total'] += 1\n",
    "    else:\n",
    "        acc_by_dataset[data_name] = {'correct': resp, 'total': 1}\n",
    "\n",
    "print(extractmodel)\n",
    "print('='*90)\n",
    "print(f'Overall acc: {roberta_rp.iloc[0, 1:].sum()/(roberta_rp.shape[1]-1):.4f}')        \n",
    "\n",
    "for data_name, acc_dict in acc_by_dataset.items():\n",
    "    print(f'{data_name} acc: {acc_dict[\"correct\"]/acc_dict[\"total\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# set to False if run for the first time\n",
    "# note that this will take sometimes to run if the datasets are big\n",
    "load_from_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# distribution and transformation\n",
    "alpha_dist = 'log-normal'\n",
    "alpha_transf = 'standard'\n",
    "theta_dist = 'normal'\n",
    "theta_transf = 'standard'\n",
    "\n",
    "exp_dir = os.path.join(repo, 'params', f'alpha-lognormal-identity_theta-normal-identity_nosubsample_1.00_0.30')\n",
    "p = 0.95\n",
    "\n",
    "with open(os.path.join(exp_dir, 'responses.p'), 'rb') as f:\n",
    "    combined_responses = pickle.load(f).reset_index()\n",
    "data, accuracies, example_accuracies = get_data_accuracies(combined_responses)\n",
    "column_names = combined_responses.columns[1:]\n",
    "select_ts = {\n",
    "    'standard':lambda x:x,\n",
    "    'positive':lambda x:torch.log(1+torch.exp(torch.tensor(x))),\n",
    "    'sigmoid':lambda x:sigmoid(torch.tensor(x)),\n",
    "}\n",
    "\n",
    "transforms = {\n",
    "    'a':select_ts[alpha_transf],\n",
    "    'b':select_ts['standard'],\n",
    "    'g':select_ts['sigmoid'],\n",
    "    't':select_ts[theta_transf],\n",
    "}\n",
    "\n",
    "if load_from_cache:\n",
    "    param_plot_stats = {}\n",
    "\n",
    "    for key in transforms.keys():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'rb') as f:\n",
    "            param_plot_stats[key] = pickle.load(f)\n",
    "else:\n",
    "    param_plot_stats = get_plot_stats(\n",
    "        exp_dir,\n",
    "        alpha_dist,\n",
    "        theta_dist,\n",
    "        transforms,\n",
    "        p = 0.95\n",
    "    )\n",
    "    \n",
    "    os.makedirs('plot_stats_pickles', exist_ok=True)\n",
    "    for key, value in param_plot_stats.items():\n",
    "        with open(os.path.join('plot_stats_pickles', f'{key}.p'), 'wb') as f:\n",
    "            pickle.dump(value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>abductive_nli_0</th>\n",
       "      <th>abductive_nli_1</th>\n",
       "      <th>abductive_nli_2</th>\n",
       "      <th>abductive_nli_3</th>\n",
       "      <th>abductive_nli_4</th>\n",
       "      <th>abductive_nli_5</th>\n",
       "      <th>abductive_nli_6</th>\n",
       "      <th>abductive_nli_7</th>\n",
       "      <th>abductive_nli_8</th>\n",
       "      <th>...</th>\n",
       "      <th>wsc_42</th>\n",
       "      <th>wsc_43</th>\n",
       "      <th>wsc_44</th>\n",
       "      <th>wsc_45</th>\n",
       "      <th>wsc_46</th>\n",
       "      <th>wsc_47</th>\n",
       "      <th>wsc_48</th>\n",
       "      <th>wsc_49</th>\n",
       "      <th>wsc_50</th>\n",
       "      <th>wsc_51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta-base-10M-1_best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base-10M-1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base-10M-1_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-10M-1_50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta-base-10M-1_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>xlm-roberta-large_best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xlm-roberta-large_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>xlm-roberta-large_25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>xlm-roberta-large_50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xlm-roberta-large_10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 82234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userid  abductive_nli_0  abductive_nli_1  \\\n",
       "0   roberta-base-10M-1_best                1                0   \n",
       "1      roberta-base-10M-1_1                0                0   \n",
       "2     roberta-base-10M-1_25                1                1   \n",
       "3     roberta-base-10M-1_50                1                0   \n",
       "4     roberta-base-10M-1_10                1                0   \n",
       "..                      ...              ...              ...   \n",
       "85   xlm-roberta-large_best                1                1   \n",
       "86      xlm-roberta-large_1                1                1   \n",
       "87     xlm-roberta-large_25                1                1   \n",
       "88     xlm-roberta-large_50                1                1   \n",
       "89     xlm-roberta-large_10                0                1   \n",
       "\n",
       "    abductive_nli_2  abductive_nli_3  abductive_nli_4  abductive_nli_5  \\\n",
       "0                 1                1                1                1   \n",
       "1                 0                1                1                0   \n",
       "2                 1                1                1                1   \n",
       "3                 1                1                1                1   \n",
       "4                 1                1                1                1   \n",
       "..              ...              ...              ...              ...   \n",
       "85                0                1                1                1   \n",
       "86                0                1                1                0   \n",
       "87                0                1                1                1   \n",
       "88                1                1                1                1   \n",
       "89                0                1                1                0   \n",
       "\n",
       "    abductive_nli_6  abductive_nli_7  abductive_nli_8  ...  wsc_42  wsc_43  \\\n",
       "0                 1                0                1  ...       1       0   \n",
       "1                 1                0                1  ...       1       0   \n",
       "2                 1                1                1  ...       0       0   \n",
       "3                 1                0                1  ...       1       0   \n",
       "4                 1                0                1  ...       1       0   \n",
       "..              ...              ...              ...  ...     ...     ...   \n",
       "85                1                1                1  ...       1       1   \n",
       "86                1                0                1  ...       0       0   \n",
       "87                0                1                1  ...       1       1   \n",
       "88                1                1                1  ...       1       1   \n",
       "89                0                1                1  ...       0       0   \n",
       "\n",
       "    wsc_44  wsc_45  wsc_46  wsc_47  wsc_48  wsc_49  wsc_50  wsc_51  \n",
       "0        1       1       0       1       0       1       0       1  \n",
       "1        1       0       0       1       0       0       0       1  \n",
       "2        0       1       0       1       1       1       1       1  \n",
       "3        0       1       0       1       1       1       0       1  \n",
       "4        0       1       0       1       1       1       0       1  \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
       "85       0       1       0       1       1       1       0       0  \n",
       "86       1       0       1       0       0       0       1       1  \n",
       "87       0       1       0       1       1       1       0       0  \n",
       "88       0       1       0       1       1       1       0       0  \n",
       "89       1       0       1       0       0       0       1       1  \n",
       "\n",
       "[90 rows x 82234 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_names = []\n",
    "model_levels = []\n",
    "for m in combined_responses['userid']:\n",
    "    mname = m.split('_')[0]\n",
    "    mlevel = m.split('_')[-1]\n",
    "    if mname.endswith('-1') or mname.endswith('-2') or mname.endswith('-3'):\n",
    "        mname = mname[:-2]\n",
    "    model_names.append(mname)\n",
    "    \n",
    "    mlevel_append = '' if mlevel == 'best' else r'%'\n",
    "    model_levels.append(mlevel+mlevel_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0\n",
      "b 36860\n",
      "g 0\n",
      "t 49\n"
     ]
    }
   ],
   "source": [
    "#  we will only use log mean for discriminative parameter\n",
    "for param_key, param_stat in param_plot_stats.items():\n",
    "    param_stat['log_mean'] = numpy.log(param_stat['mean'])\n",
    "    print(param_key, param_stat['log_mean'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_a = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "param_b = pd.concat([param_plot_stats['b'], task_name_format], axis=1)\n",
    "\n",
    "task_order = [task_metadata.loc[x]['taskname'] for x in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: albert-xxlarge-v2\n",
      "1.582378625869751\n",
      "No gamma: 0.14226206233809996\n",
      "With gamma: 0.11365353401378117\n",
      "           mean\n",
      "0      0.193985\n",
      "1      0.178925\n",
      "2      0.057262\n",
      "3      0.014374\n",
      "4      0.105861\n",
      "...         ...\n",
      "82228  0.059020\n",
      "82229  0.123432\n",
      "82230  0.083337\n",
      "82231  0.107942\n",
      "82232  0.082005\n",
      "\n",
      "[82233 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "leh_scores = icc_best_deriv(\n",
    "    param_plot_stats['a'],\n",
    "    param_plot_stats['b'],\n",
    "    param_plot_stats['t'],\n",
    "    model_names,\n",
    "    gamma = param_plot_stats['g'],\n",
    ")\n",
    "\n",
    "leh_scores_plot = pd.DataFrame(pd.Series(leh_scores), columns = ['mean'])\n",
    "print(leh_scores_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leh_scores_plot = pd.concat([leh_scores_plot, task_name_format], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "task_metadata.set_index(\"taskname\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trimmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.217520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.236766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.225070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.146903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.183463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.139165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.091976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.183826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.238214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.208724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.259122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.277994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.130272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.111075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>0.203354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.213861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.217133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>0.258357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.166474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.190363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.248013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>0.257055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.171824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.043375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>0.209841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.200074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.154375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.162638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trimmed\n",
       "task_name           \n",
       "ANLI        0.217520\n",
       "ARC-C       0.236766\n",
       "ARC-E       0.225070\n",
       "ARCT        0.146903\n",
       "AbductNLI   0.183463\n",
       "BoolQ       0.139165\n",
       "CB          0.091976\n",
       "COPA        0.183826\n",
       "CSQA        0.238214\n",
       "CosmosQA    0.208724\n",
       "HellaSwag   0.259122\n",
       "MC-TACO     0.277994\n",
       "MCScript    0.130272\n",
       "MNLI        0.111075\n",
       "MRQA-NQ     0.203354\n",
       "MuTual      0.213861\n",
       "MuTual+     0.217133\n",
       "NewsQA      0.258357\n",
       "PiQA        0.166474\n",
       "QAMR        0.190363\n",
       "QuAIL       0.248013\n",
       "Quoref      0.257055\n",
       "RTE         0.171824\n",
       "SNLI        0.043375\n",
       "SQuAD2.0    0.209841\n",
       "SocialIQA   0.200074\n",
       "WSC         0.154375\n",
       "WiC         0.151300\n",
       "Winogrande  0.162638"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed = leh_scores_plot_trimmed.groupby(by='task_name').quantile(q=0.75).rename(columns={'mean':'Trimmed'})\n",
    "trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.198573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.215639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.214382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.145347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.174404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.122382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.108013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.170370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.231926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.199577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.248942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.243599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.133659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.119982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>0.182976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.204902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.210020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>0.233822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.156766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>0.172753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.227193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>0.248374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.167902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.047319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>0.178504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.192852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.141798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.143788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.160781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Full\n",
       "task_name           \n",
       "ANLI        0.198573\n",
       "ARC-C       0.215639\n",
       "ARC-E       0.214382\n",
       "ARCT        0.145347\n",
       "AbductNLI   0.174404\n",
       "BoolQ       0.122382\n",
       "CB          0.108013\n",
       "COPA        0.170370\n",
       "CSQA        0.231926\n",
       "CosmosQA    0.199577\n",
       "HellaSwag   0.248942\n",
       "MC-TACO     0.243599\n",
       "MCScript    0.133659\n",
       "MNLI        0.119982\n",
       "MRQA-NQ     0.182976\n",
       "MuTual      0.204902\n",
       "MuTual+     0.210020\n",
       "NewsQA      0.233822\n",
       "PiQA        0.156766\n",
       "QAMR        0.172753\n",
       "QuAIL       0.227193\n",
       "Quoref      0.248374\n",
       "RTE         0.167902\n",
       "SNLI        0.047319\n",
       "SQuAD2.0    0.178504\n",
       "SocialIQA   0.192852\n",
       "WSC         0.141798\n",
       "WiC         0.143788\n",
       "Winogrande  0.160781"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = leh_scores_plot.groupby(by='task_name').quantile(q=0.75).rename(columns={'mean':'Full'})\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.009146576121313699\n",
      "rel_diff 0.04985242828403232\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([trimmed, full], axis=1)\n",
    "combined['diff'] = combined['Trimmed'] - combined['Full']\n",
    "combined['rel_diff'] = (combined['Trimmed'] - combined['Full'])/combined['Full']\n",
    "\n",
    "print('diff', combined['diff'].median())\n",
    "print('rel_diff', combined['rel_diff'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trimmed</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trimmed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full</th>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Trimmed      Full\n",
       "Trimmed  1.000000  0.985714\n",
       "Full     0.985714  1.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[:,['Trimmed','Full']].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78721, 5)\n"
     ]
    }
   ],
   "source": [
    "print(param_plot_stats_trimmed['a'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78721, 2)\n"
     ]
    }
   ],
   "source": [
    "print(task_name_format_trimmed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Trimmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.910985</td>\n",
       "      <td>2.254991</td>\n",
       "      <td>1.458205</td>\n",
       "      <td>0.128729</td>\n",
       "      <td>0.377206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.829711</td>\n",
       "      <td>2.111609</td>\n",
       "      <td>1.348144</td>\n",
       "      <td>0.116188</td>\n",
       "      <td>0.298729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.832761</td>\n",
       "      <td>2.090126</td>\n",
       "      <td>1.337743</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>0.290984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.797911</td>\n",
       "      <td>2.125889</td>\n",
       "      <td>1.332243</td>\n",
       "      <td>0.123776</td>\n",
       "      <td>0.286864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.831509</td>\n",
       "      <td>2.223219</td>\n",
       "      <td>1.385403</td>\n",
       "      <td>0.136846</td>\n",
       "      <td>0.325991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.833742</td>\n",
       "      <td>2.146840</td>\n",
       "      <td>1.338929</td>\n",
       "      <td>0.125501</td>\n",
       "      <td>0.291870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.891985</td>\n",
       "      <td>2.186326</td>\n",
       "      <td>1.360933</td>\n",
       "      <td>0.116663</td>\n",
       "      <td>0.308167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.691181</td>\n",
       "      <td>2.033327</td>\n",
       "      <td>1.211465</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>0.191828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.851922</td>\n",
       "      <td>2.168921</td>\n",
       "      <td>1.400281</td>\n",
       "      <td>0.123441</td>\n",
       "      <td>0.336673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.873289</td>\n",
       "      <td>2.182176</td>\n",
       "      <td>1.411812</td>\n",
       "      <td>0.119116</td>\n",
       "      <td>0.344874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.880934</td>\n",
       "      <td>2.210066</td>\n",
       "      <td>1.416586</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.348250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.981206</td>\n",
       "      <td>2.251367</td>\n",
       "      <td>1.503941</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>0.408089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.831270</td>\n",
       "      <td>2.165778</td>\n",
       "      <td>1.370498</td>\n",
       "      <td>0.127731</td>\n",
       "      <td>0.315174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.956632</td>\n",
       "      <td>2.352935</td>\n",
       "      <td>1.521096</td>\n",
       "      <td>0.139670</td>\n",
       "      <td>0.419431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>1.090785</td>\n",
       "      <td>2.502778</td>\n",
       "      <td>1.676305</td>\n",
       "      <td>0.140862</td>\n",
       "      <td>0.516592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.860660</td>\n",
       "      <td>2.121033</td>\n",
       "      <td>1.377236</td>\n",
       "      <td>0.110566</td>\n",
       "      <td>0.320079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.874284</td>\n",
       "      <td>2.183818</td>\n",
       "      <td>1.417175</td>\n",
       "      <td>0.118083</td>\n",
       "      <td>0.348665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>1.119673</td>\n",
       "      <td>2.491661</td>\n",
       "      <td>1.688428</td>\n",
       "      <td>0.131403</td>\n",
       "      <td>0.523798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.712514</td>\n",
       "      <td>1.961070</td>\n",
       "      <td>1.209794</td>\n",
       "      <td>0.112366</td>\n",
       "      <td>0.190450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>1.225940</td>\n",
       "      <td>2.742682</td>\n",
       "      <td>1.865919</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>0.623754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.898356</td>\n",
       "      <td>2.239507</td>\n",
       "      <td>1.456621</td>\n",
       "      <td>0.121961</td>\n",
       "      <td>0.376119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>1.088433</td>\n",
       "      <td>2.402217</td>\n",
       "      <td>1.642322</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.496111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.689643</td>\n",
       "      <td>1.902678</td>\n",
       "      <td>1.183311</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.168317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.962026</td>\n",
       "      <td>2.371258</td>\n",
       "      <td>1.527674</td>\n",
       "      <td>0.144219</td>\n",
       "      <td>0.423746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>1.118240</td>\n",
       "      <td>2.586590</td>\n",
       "      <td>1.716114</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.540063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.836666</td>\n",
       "      <td>2.152473</td>\n",
       "      <td>1.370060</td>\n",
       "      <td>0.124705</td>\n",
       "      <td>0.314855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.732991</td>\n",
       "      <td>2.004430</td>\n",
       "      <td>1.219095</td>\n",
       "      <td>0.105845</td>\n",
       "      <td>0.198106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.789197</td>\n",
       "      <td>2.094490</td>\n",
       "      <td>1.301873</td>\n",
       "      <td>0.122496</td>\n",
       "      <td>0.263762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.680666</td>\n",
       "      <td>1.917013</td>\n",
       "      <td>1.152410</td>\n",
       "      <td>0.107103</td>\n",
       "      <td>0.141856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lower     upper      mean       var   Trimmed\n",
       "task_name                                                   \n",
       "ANLI        0.910985  2.254991  1.458205  0.128729  0.377206\n",
       "ARC-C       0.829711  2.111609  1.348144  0.116188  0.298729\n",
       "ARC-E       0.832761  2.090126  1.337743  0.112663  0.290984\n",
       "ARCT        0.797911  2.125889  1.332243  0.123776  0.286864\n",
       "AbductNLI   0.831509  2.223219  1.385403  0.136846  0.325991\n",
       "BoolQ       0.833742  2.146840  1.338929  0.125501  0.291870\n",
       "CB          0.891985  2.186326  1.360933  0.116663  0.308167\n",
       "COPA        0.691181  2.033327  1.211465  0.131899  0.191828\n",
       "CSQA        0.851922  2.168921  1.400281  0.123441  0.336673\n",
       "CosmosQA    0.873289  2.182176  1.411812  0.119116  0.344874\n",
       "HellaSwag   0.880934  2.210066  1.416586  0.124959  0.348250\n",
       "MC-TACO     0.981206  2.251367  1.503941  0.118791  0.408089\n",
       "MCScript    0.831270  2.165778  1.370498  0.127731  0.315174\n",
       "MNLI        0.956632  2.352935  1.521096  0.139670  0.419431\n",
       "MRQA-NQ     1.090785  2.502778  1.676305  0.140862  0.516592\n",
       "MuTual      0.860660  2.121033  1.377236  0.110566  0.320079\n",
       "MuTual+     0.874284  2.183818  1.417175  0.118083  0.348665\n",
       "NewsQA      1.119673  2.491661  1.688428  0.131403  0.523798\n",
       "PiQA        0.712514  1.961070  1.209794  0.112366  0.190450\n",
       "QAMR        1.225940  2.742682  1.865919  0.160983  0.623754\n",
       "QuAIL       0.898356  2.239507  1.456621  0.121961  0.376119\n",
       "Quoref      1.088433  2.402217  1.642322  0.124891  0.496111\n",
       "RTE         0.689643  1.902678  1.183311  0.100705  0.168317\n",
       "SNLI        0.962026  2.371258  1.527674  0.144219  0.423746\n",
       "SQuAD2.0    1.118240  2.586590  1.716114  0.153966  0.540063\n",
       "SocialIQA   0.836666  2.152473  1.370060  0.124705  0.314855\n",
       "WSC         0.732991  2.004430  1.219095  0.105845  0.198106\n",
       "WiC         0.789197  2.094490  1.301873  0.122496  0.263762\n",
       "Winogrande  0.680666  1.917013  1.152410  0.107103  0.141856"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed = pd.concat([param_plot_stats_trimmed['a'], task_name_format_trimmed], axis=1) \n",
    "trimmed = trimmed.groupby(by='task_name').quantile(q=0.75).rename(columns={'log_mean':'Trimmed'})\n",
    "trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.896719</td>\n",
       "      <td>2.221928</td>\n",
       "      <td>1.439807</td>\n",
       "      <td>0.126375</td>\n",
       "      <td>0.364509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.817265</td>\n",
       "      <td>2.082838</td>\n",
       "      <td>1.323434</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.280230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.824985</td>\n",
       "      <td>2.064168</td>\n",
       "      <td>1.317038</td>\n",
       "      <td>0.109276</td>\n",
       "      <td>0.275386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.786051</td>\n",
       "      <td>2.102383</td>\n",
       "      <td>1.291031</td>\n",
       "      <td>0.122855</td>\n",
       "      <td>0.255441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.823848</td>\n",
       "      <td>2.216965</td>\n",
       "      <td>1.391689</td>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.330518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.801109</td>\n",
       "      <td>2.106907</td>\n",
       "      <td>1.306342</td>\n",
       "      <td>0.123751</td>\n",
       "      <td>0.267231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.954628</td>\n",
       "      <td>2.059321</td>\n",
       "      <td>1.427322</td>\n",
       "      <td>0.101397</td>\n",
       "      <td>0.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.704257</td>\n",
       "      <td>1.885803</td>\n",
       "      <td>1.176215</td>\n",
       "      <td>0.104034</td>\n",
       "      <td>0.162301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.848660</td>\n",
       "      <td>2.093390</td>\n",
       "      <td>1.343194</td>\n",
       "      <td>0.111521</td>\n",
       "      <td>0.295050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.858380</td>\n",
       "      <td>2.143313</td>\n",
       "      <td>1.384106</td>\n",
       "      <td>0.121368</td>\n",
       "      <td>0.325055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.852452</td>\n",
       "      <td>2.116092</td>\n",
       "      <td>1.364264</td>\n",
       "      <td>0.113344</td>\n",
       "      <td>0.310615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.988573</td>\n",
       "      <td>2.284655</td>\n",
       "      <td>1.525085</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.422050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.829041</td>\n",
       "      <td>2.171677</td>\n",
       "      <td>1.359672</td>\n",
       "      <td>0.127456</td>\n",
       "      <td>0.307243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.966862</td>\n",
       "      <td>2.380740</td>\n",
       "      <td>1.541056</td>\n",
       "      <td>0.142127</td>\n",
       "      <td>0.432468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>1.090868</td>\n",
       "      <td>2.515599</td>\n",
       "      <td>1.683974</td>\n",
       "      <td>0.142633</td>\n",
       "      <td>0.521156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.860727</td>\n",
       "      <td>2.112886</td>\n",
       "      <td>1.361689</td>\n",
       "      <td>0.111885</td>\n",
       "      <td>0.308726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.887211</td>\n",
       "      <td>2.112536</td>\n",
       "      <td>1.403084</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.338673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>1.080887</td>\n",
       "      <td>2.454519</td>\n",
       "      <td>1.648149</td>\n",
       "      <td>0.131109</td>\n",
       "      <td>0.499653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.701058</td>\n",
       "      <td>1.943909</td>\n",
       "      <td>1.182522</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.167650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>1.236998</td>\n",
       "      <td>2.776558</td>\n",
       "      <td>1.889610</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.636371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.873645</td>\n",
       "      <td>2.166432</td>\n",
       "      <td>1.395381</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.333167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>1.046551</td>\n",
       "      <td>2.346994</td>\n",
       "      <td>1.590631</td>\n",
       "      <td>0.119931</td>\n",
       "      <td>0.464131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.673158</td>\n",
       "      <td>1.876460</td>\n",
       "      <td>1.142545</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.133258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.964162</td>\n",
       "      <td>2.398013</td>\n",
       "      <td>1.537802</td>\n",
       "      <td>0.148316</td>\n",
       "      <td>0.430354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>1.105925</td>\n",
       "      <td>2.551777</td>\n",
       "      <td>1.695642</td>\n",
       "      <td>0.147610</td>\n",
       "      <td>0.528062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.828220</td>\n",
       "      <td>2.116541</td>\n",
       "      <td>1.346476</td>\n",
       "      <td>0.117987</td>\n",
       "      <td>0.297491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.714291</td>\n",
       "      <td>1.910543</td>\n",
       "      <td>1.217325</td>\n",
       "      <td>0.085549</td>\n",
       "      <td>0.196616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.788677</td>\n",
       "      <td>2.095331</td>\n",
       "      <td>1.293893</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.257655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.661247</td>\n",
       "      <td>1.920919</td>\n",
       "      <td>1.137290</td>\n",
       "      <td>0.113739</td>\n",
       "      <td>0.128649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lower     upper      mean       var      Full\n",
       "task_name                                                   \n",
       "ANLI        0.896719  2.221928  1.439807  0.126375  0.364509\n",
       "ARC-C       0.817265  2.082838  1.323434  0.112265  0.280230\n",
       "ARC-E       0.824985  2.064168  1.317038  0.109276  0.275386\n",
       "ARCT        0.786051  2.102383  1.291031  0.122855  0.255441\n",
       "AbductNLI   0.823848  2.216965  1.391689  0.135476  0.330518\n",
       "BoolQ       0.801109  2.106907  1.306342  0.123751  0.267231\n",
       "CB          0.954628  2.059321  1.427322  0.101397  0.355759\n",
       "COPA        0.704257  1.885803  1.176215  0.104034  0.162301\n",
       "CSQA        0.848660  2.093390  1.343194  0.111521  0.295050\n",
       "CosmosQA    0.858380  2.143313  1.384106  0.121368  0.325055\n",
       "HellaSwag   0.852452  2.116092  1.364264  0.113344  0.310615\n",
       "MC-TACO     0.988573  2.284655  1.525085  0.119350  0.422050\n",
       "MCScript    0.829041  2.171677  1.359672  0.127456  0.307243\n",
       "MNLI        0.966862  2.380740  1.541056  0.142127  0.432468\n",
       "MRQA-NQ     1.090868  2.515599  1.683974  0.142633  0.521156\n",
       "MuTual      0.860727  2.112886  1.361689  0.111885  0.308726\n",
       "MuTual+     0.887211  2.112536  1.403084  0.113705  0.338673\n",
       "NewsQA      1.080887  2.454519  1.648149  0.131109  0.499653\n",
       "PiQA        0.701058  1.943909  1.182522  0.110569  0.167650\n",
       "QAMR        1.236998  2.776558  1.889610  0.162382  0.636371\n",
       "QuAIL       0.873645  2.166432  1.395381  0.118153  0.333167\n",
       "Quoref      1.046551  2.346994  1.590631  0.119931  0.464131\n",
       "RTE         0.673158  1.876460  1.142545  0.107360  0.133258\n",
       "SNLI        0.964162  2.398013  1.537802  0.148316  0.430354\n",
       "SQuAD2.0    1.105925  2.551777  1.695642  0.147610  0.528062\n",
       "SocialIQA   0.828220  2.116541  1.346476  0.117987  0.297491\n",
       "WSC         0.714291  1.910543  1.217325  0.085549  0.196616\n",
       "WiC         0.788677  2.095331  1.293893  0.123934  0.257655\n",
       "Winogrande  0.661247  1.920919  1.137290  0.113739  0.128649"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.concat([param_plot_stats['a'], task_name_format], axis=1)\n",
    "full = full.groupby(by='task_name').quantile(q=0.75).rename(columns={'log_mean':'Full'})\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.01320694910671591\n",
      "rel_diff 0.04832417383542685\n"
     ]
    }
   ],
   "source": [
    "combined_a = pd.concat([trimmed, full], axis=1)\n",
    "combined_a['diff'] = combined_a['Trimmed'] - combined_a['Full']\n",
    "combined_a['rel_diff'] = (combined_a['Trimmed'] - combined_a['Full'])/combined_a['Full']\n",
    "\n",
    "print('diff', combined_a['diff'].median())\n",
    "print('rel_diff', combined_a['rel_diff'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Trimmed</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Full</th>\n",
       "      <th>diff</th>\n",
       "      <th>rel_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANLI</th>\n",
       "      <td>0.910985</td>\n",
       "      <td>2.254991</td>\n",
       "      <td>1.458205</td>\n",
       "      <td>0.128729</td>\n",
       "      <td>0.377206</td>\n",
       "      <td>0.896719</td>\n",
       "      <td>2.221928</td>\n",
       "      <td>1.439807</td>\n",
       "      <td>0.126375</td>\n",
       "      <td>0.364509</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.034835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-C</th>\n",
       "      <td>0.829711</td>\n",
       "      <td>2.111609</td>\n",
       "      <td>1.348144</td>\n",
       "      <td>0.116188</td>\n",
       "      <td>0.298729</td>\n",
       "      <td>0.817265</td>\n",
       "      <td>2.082838</td>\n",
       "      <td>1.323434</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.280230</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.066014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARC-E</th>\n",
       "      <td>0.832761</td>\n",
       "      <td>2.090126</td>\n",
       "      <td>1.337743</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.824985</td>\n",
       "      <td>2.064168</td>\n",
       "      <td>1.317038</td>\n",
       "      <td>0.109276</td>\n",
       "      <td>0.275386</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.056642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCT</th>\n",
       "      <td>0.797911</td>\n",
       "      <td>2.125889</td>\n",
       "      <td>1.332243</td>\n",
       "      <td>0.123776</td>\n",
       "      <td>0.286864</td>\n",
       "      <td>0.786051</td>\n",
       "      <td>2.102383</td>\n",
       "      <td>1.291031</td>\n",
       "      <td>0.122855</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>0.123015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbductNLI</th>\n",
       "      <td>0.831509</td>\n",
       "      <td>2.223219</td>\n",
       "      <td>1.385403</td>\n",
       "      <td>0.136846</td>\n",
       "      <td>0.325991</td>\n",
       "      <td>0.823848</td>\n",
       "      <td>2.216965</td>\n",
       "      <td>1.391689</td>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.330518</td>\n",
       "      <td>-0.004527</td>\n",
       "      <td>-0.013696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoolQ</th>\n",
       "      <td>0.833742</td>\n",
       "      <td>2.146840</td>\n",
       "      <td>1.338929</td>\n",
       "      <td>0.125501</td>\n",
       "      <td>0.291870</td>\n",
       "      <td>0.801109</td>\n",
       "      <td>2.106907</td>\n",
       "      <td>1.306342</td>\n",
       "      <td>0.123751</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>0.024639</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.891985</td>\n",
       "      <td>2.186326</td>\n",
       "      <td>1.360933</td>\n",
       "      <td>0.116663</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.954628</td>\n",
       "      <td>2.059321</td>\n",
       "      <td>1.427322</td>\n",
       "      <td>0.101397</td>\n",
       "      <td>0.355759</td>\n",
       "      <td>-0.047592</td>\n",
       "      <td>-0.133777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COPA</th>\n",
       "      <td>0.691181</td>\n",
       "      <td>2.033327</td>\n",
       "      <td>1.211465</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>0.191828</td>\n",
       "      <td>0.704257</td>\n",
       "      <td>1.885803</td>\n",
       "      <td>1.176215</td>\n",
       "      <td>0.104034</td>\n",
       "      <td>0.162301</td>\n",
       "      <td>0.029526</td>\n",
       "      <td>0.181922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSQA</th>\n",
       "      <td>0.851922</td>\n",
       "      <td>2.168921</td>\n",
       "      <td>1.400281</td>\n",
       "      <td>0.123441</td>\n",
       "      <td>0.336673</td>\n",
       "      <td>0.848660</td>\n",
       "      <td>2.093390</td>\n",
       "      <td>1.343194</td>\n",
       "      <td>0.111521</td>\n",
       "      <td>0.295050</td>\n",
       "      <td>0.041622</td>\n",
       "      <td>0.141069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosmosQA</th>\n",
       "      <td>0.873289</td>\n",
       "      <td>2.182176</td>\n",
       "      <td>1.411812</td>\n",
       "      <td>0.119116</td>\n",
       "      <td>0.344874</td>\n",
       "      <td>0.858380</td>\n",
       "      <td>2.143313</td>\n",
       "      <td>1.384106</td>\n",
       "      <td>0.121368</td>\n",
       "      <td>0.325055</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.060972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HellaSwag</th>\n",
       "      <td>0.880934</td>\n",
       "      <td>2.210066</td>\n",
       "      <td>1.416586</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.348250</td>\n",
       "      <td>0.852452</td>\n",
       "      <td>2.116092</td>\n",
       "      <td>1.364264</td>\n",
       "      <td>0.113344</td>\n",
       "      <td>0.310615</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.121162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC-TACO</th>\n",
       "      <td>0.981206</td>\n",
       "      <td>2.251367</td>\n",
       "      <td>1.503941</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>0.408089</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>2.284655</td>\n",
       "      <td>1.525085</td>\n",
       "      <td>0.119350</td>\n",
       "      <td>0.422050</td>\n",
       "      <td>-0.013961</td>\n",
       "      <td>-0.033078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCScript</th>\n",
       "      <td>0.831270</td>\n",
       "      <td>2.165778</td>\n",
       "      <td>1.370498</td>\n",
       "      <td>0.127731</td>\n",
       "      <td>0.315174</td>\n",
       "      <td>0.829041</td>\n",
       "      <td>2.171677</td>\n",
       "      <td>1.359672</td>\n",
       "      <td>0.127456</td>\n",
       "      <td>0.307243</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.025813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNLI</th>\n",
       "      <td>0.956632</td>\n",
       "      <td>2.352935</td>\n",
       "      <td>1.521096</td>\n",
       "      <td>0.139670</td>\n",
       "      <td>0.419431</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>2.380740</td>\n",
       "      <td>1.541056</td>\n",
       "      <td>0.142127</td>\n",
       "      <td>0.432468</td>\n",
       "      <td>-0.013036</td>\n",
       "      <td>-0.030144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRQA-NQ</th>\n",
       "      <td>1.090785</td>\n",
       "      <td>2.502778</td>\n",
       "      <td>1.676305</td>\n",
       "      <td>0.140862</td>\n",
       "      <td>0.516592</td>\n",
       "      <td>1.090868</td>\n",
       "      <td>2.515599</td>\n",
       "      <td>1.683974</td>\n",
       "      <td>0.142633</td>\n",
       "      <td>0.521156</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>-0.008758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual</th>\n",
       "      <td>0.860660</td>\n",
       "      <td>2.121033</td>\n",
       "      <td>1.377236</td>\n",
       "      <td>0.110566</td>\n",
       "      <td>0.320079</td>\n",
       "      <td>0.860727</td>\n",
       "      <td>2.112886</td>\n",
       "      <td>1.361689</td>\n",
       "      <td>0.111885</td>\n",
       "      <td>0.308726</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>0.036774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuTual+</th>\n",
       "      <td>0.874284</td>\n",
       "      <td>2.183818</td>\n",
       "      <td>1.417175</td>\n",
       "      <td>0.118083</td>\n",
       "      <td>0.348665</td>\n",
       "      <td>0.887211</td>\n",
       "      <td>2.112536</td>\n",
       "      <td>1.403084</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.338673</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.029505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsQA</th>\n",
       "      <td>1.119673</td>\n",
       "      <td>2.491661</td>\n",
       "      <td>1.688428</td>\n",
       "      <td>0.131403</td>\n",
       "      <td>0.523798</td>\n",
       "      <td>1.080887</td>\n",
       "      <td>2.454519</td>\n",
       "      <td>1.648149</td>\n",
       "      <td>0.131109</td>\n",
       "      <td>0.499653</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.048324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PiQA</th>\n",
       "      <td>0.712514</td>\n",
       "      <td>1.961070</td>\n",
       "      <td>1.209794</td>\n",
       "      <td>0.112366</td>\n",
       "      <td>0.190450</td>\n",
       "      <td>0.701058</td>\n",
       "      <td>1.943909</td>\n",
       "      <td>1.182522</td>\n",
       "      <td>0.110569</td>\n",
       "      <td>0.167650</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.135999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAMR</th>\n",
       "      <td>1.225940</td>\n",
       "      <td>2.742682</td>\n",
       "      <td>1.865919</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>0.623754</td>\n",
       "      <td>1.236998</td>\n",
       "      <td>2.776558</td>\n",
       "      <td>1.889610</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.636371</td>\n",
       "      <td>-0.012617</td>\n",
       "      <td>-0.019826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuAIL</th>\n",
       "      <td>0.898356</td>\n",
       "      <td>2.239507</td>\n",
       "      <td>1.456621</td>\n",
       "      <td>0.121961</td>\n",
       "      <td>0.376119</td>\n",
       "      <td>0.873645</td>\n",
       "      <td>2.166432</td>\n",
       "      <td>1.395381</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>0.042952</td>\n",
       "      <td>0.128921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quoref</th>\n",
       "      <td>1.088433</td>\n",
       "      <td>2.402217</td>\n",
       "      <td>1.642322</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.496111</td>\n",
       "      <td>1.046551</td>\n",
       "      <td>2.346994</td>\n",
       "      <td>1.590631</td>\n",
       "      <td>0.119931</td>\n",
       "      <td>0.464131</td>\n",
       "      <td>0.031980</td>\n",
       "      <td>0.068904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTE</th>\n",
       "      <td>0.689643</td>\n",
       "      <td>1.902678</td>\n",
       "      <td>1.183311</td>\n",
       "      <td>0.100705</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.673158</td>\n",
       "      <td>1.876460</td>\n",
       "      <td>1.142545</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.133258</td>\n",
       "      <td>0.035058</td>\n",
       "      <td>0.263086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNLI</th>\n",
       "      <td>0.962026</td>\n",
       "      <td>2.371258</td>\n",
       "      <td>1.527674</td>\n",
       "      <td>0.144219</td>\n",
       "      <td>0.423746</td>\n",
       "      <td>0.964162</td>\n",
       "      <td>2.398013</td>\n",
       "      <td>1.537802</td>\n",
       "      <td>0.148316</td>\n",
       "      <td>0.430354</td>\n",
       "      <td>-0.006608</td>\n",
       "      <td>-0.015354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQuAD2.0</th>\n",
       "      <td>1.118240</td>\n",
       "      <td>2.586590</td>\n",
       "      <td>1.716114</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.540063</td>\n",
       "      <td>1.105925</td>\n",
       "      <td>2.551777</td>\n",
       "      <td>1.695642</td>\n",
       "      <td>0.147610</td>\n",
       "      <td>0.528062</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.022727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialIQA</th>\n",
       "      <td>0.836666</td>\n",
       "      <td>2.152473</td>\n",
       "      <td>1.370060</td>\n",
       "      <td>0.124705</td>\n",
       "      <td>0.314855</td>\n",
       "      <td>0.828220</td>\n",
       "      <td>2.116541</td>\n",
       "      <td>1.346476</td>\n",
       "      <td>0.117987</td>\n",
       "      <td>0.297491</td>\n",
       "      <td>0.017364</td>\n",
       "      <td>0.058367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSC</th>\n",
       "      <td>0.732991</td>\n",
       "      <td>2.004430</td>\n",
       "      <td>1.219095</td>\n",
       "      <td>0.105845</td>\n",
       "      <td>0.198106</td>\n",
       "      <td>0.714291</td>\n",
       "      <td>1.910543</td>\n",
       "      <td>1.217325</td>\n",
       "      <td>0.085549</td>\n",
       "      <td>0.196616</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.007575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WiC</th>\n",
       "      <td>0.789197</td>\n",
       "      <td>2.094490</td>\n",
       "      <td>1.301873</td>\n",
       "      <td>0.122496</td>\n",
       "      <td>0.263762</td>\n",
       "      <td>0.788677</td>\n",
       "      <td>2.095331</td>\n",
       "      <td>1.293893</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.257655</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winogrande</th>\n",
       "      <td>0.680666</td>\n",
       "      <td>1.917013</td>\n",
       "      <td>1.152410</td>\n",
       "      <td>0.107103</td>\n",
       "      <td>0.141856</td>\n",
       "      <td>0.661247</td>\n",
       "      <td>1.920919</td>\n",
       "      <td>1.137290</td>\n",
       "      <td>0.113739</td>\n",
       "      <td>0.128649</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>0.102659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lower     upper      mean       var   Trimmed     lower  \\\n",
       "task_name                                                                \n",
       "ANLI        0.910985  2.254991  1.458205  0.128729  0.377206  0.896719   \n",
       "ARC-C       0.829711  2.111609  1.348144  0.116188  0.298729  0.817265   \n",
       "ARC-E       0.832761  2.090126  1.337743  0.112663  0.290984  0.824985   \n",
       "ARCT        0.797911  2.125889  1.332243  0.123776  0.286864  0.786051   \n",
       "AbductNLI   0.831509  2.223219  1.385403  0.136846  0.325991  0.823848   \n",
       "BoolQ       0.833742  2.146840  1.338929  0.125501  0.291870  0.801109   \n",
       "CB          0.891985  2.186326  1.360933  0.116663  0.308167  0.954628   \n",
       "COPA        0.691181  2.033327  1.211465  0.131899  0.191828  0.704257   \n",
       "CSQA        0.851922  2.168921  1.400281  0.123441  0.336673  0.848660   \n",
       "CosmosQA    0.873289  2.182176  1.411812  0.119116  0.344874  0.858380   \n",
       "HellaSwag   0.880934  2.210066  1.416586  0.124959  0.348250  0.852452   \n",
       "MC-TACO     0.981206  2.251367  1.503941  0.118791  0.408089  0.988573   \n",
       "MCScript    0.831270  2.165778  1.370498  0.127731  0.315174  0.829041   \n",
       "MNLI        0.956632  2.352935  1.521096  0.139670  0.419431  0.966862   \n",
       "MRQA-NQ     1.090785  2.502778  1.676305  0.140862  0.516592  1.090868   \n",
       "MuTual      0.860660  2.121033  1.377236  0.110566  0.320079  0.860727   \n",
       "MuTual+     0.874284  2.183818  1.417175  0.118083  0.348665  0.887211   \n",
       "NewsQA      1.119673  2.491661  1.688428  0.131403  0.523798  1.080887   \n",
       "PiQA        0.712514  1.961070  1.209794  0.112366  0.190450  0.701058   \n",
       "QAMR        1.225940  2.742682  1.865919  0.160983  0.623754  1.236998   \n",
       "QuAIL       0.898356  2.239507  1.456621  0.121961  0.376119  0.873645   \n",
       "Quoref      1.088433  2.402217  1.642322  0.124891  0.496111  1.046551   \n",
       "RTE         0.689643  1.902678  1.183311  0.100705  0.168317  0.673158   \n",
       "SNLI        0.962026  2.371258  1.527674  0.144219  0.423746  0.964162   \n",
       "SQuAD2.0    1.118240  2.586590  1.716114  0.153966  0.540063  1.105925   \n",
       "SocialIQA   0.836666  2.152473  1.370060  0.124705  0.314855  0.828220   \n",
       "WSC         0.732991  2.004430  1.219095  0.105845  0.198106  0.714291   \n",
       "WiC         0.789197  2.094490  1.301873  0.122496  0.263762  0.788677   \n",
       "Winogrande  0.680666  1.917013  1.152410  0.107103  0.141856  0.661247   \n",
       "\n",
       "               upper      mean       var      Full      diff  rel_diff  \n",
       "task_name                                                               \n",
       "ANLI        2.221928  1.439807  0.126375  0.364509  0.012698  0.034835  \n",
       "ARC-C       2.082838  1.323434  0.112265  0.280230  0.018499  0.066014  \n",
       "ARC-E       2.064168  1.317038  0.109276  0.275386  0.015598  0.056642  \n",
       "ARCT        2.102383  1.291031  0.122855  0.255441  0.031423  0.123015  \n",
       "AbductNLI   2.216965  1.391689  0.135476  0.330518 -0.004527 -0.013696  \n",
       "BoolQ       2.106907  1.306342  0.123751  0.267231  0.024639  0.092200  \n",
       "CB          2.059321  1.427322  0.101397  0.355759 -0.047592 -0.133777  \n",
       "COPA        1.885803  1.176215  0.104034  0.162301  0.029526  0.181922  \n",
       "CSQA        2.093390  1.343194  0.111521  0.295050  0.041622  0.141069  \n",
       "CosmosQA    2.143313  1.384106  0.121368  0.325055  0.019819  0.060972  \n",
       "HellaSwag   2.116092  1.364264  0.113344  0.310615  0.037635  0.121162  \n",
       "MC-TACO     2.284655  1.525085  0.119350  0.422050 -0.013961 -0.033078  \n",
       "MCScript    2.171677  1.359672  0.127456  0.307243  0.007931  0.025813  \n",
       "MNLI        2.380740  1.541056  0.142127  0.432468 -0.013036 -0.030144  \n",
       "MRQA-NQ     2.515599  1.683974  0.142633  0.521156 -0.004564 -0.008758  \n",
       "MuTual      2.112886  1.361689  0.111885  0.308726  0.011353  0.036774  \n",
       "MuTual+     2.112536  1.403084  0.113705  0.338673  0.009992  0.029505  \n",
       "NewsQA      2.454519  1.648149  0.131109  0.499653  0.024145  0.048324  \n",
       "PiQA        1.943909  1.182522  0.110569  0.167650  0.022800  0.135999  \n",
       "QAMR        2.776558  1.889610  0.162382  0.636371 -0.012617 -0.019826  \n",
       "QuAIL       2.166432  1.395381  0.118153  0.333167  0.042952  0.128921  \n",
       "Quoref      2.346994  1.590631  0.119931  0.464131  0.031980  0.068904  \n",
       "RTE         1.876460  1.142545  0.107360  0.133258  0.035058  0.263086  \n",
       "SNLI        2.398013  1.537802  0.148316  0.430354 -0.006608 -0.015354  \n",
       "SQuAD2.0    2.551777  1.695642  0.147610  0.528062  0.012001  0.022727  \n",
       "SocialIQA   2.116541  1.346476  0.117987  0.297491  0.017364  0.058367  \n",
       "WSC         1.910543  1.217325  0.085549  0.196616  0.001489  0.007575  \n",
       "WiC         2.095331  1.293893  0.123934  0.257655  0.006106  0.023700  \n",
       "Winogrande  1.920919  1.137290  0.113739  0.128649  0.013207  0.102659  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Trimmed</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>Full</th>\n",
       "      <th>diff</th>\n",
       "      <th>rel_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lower</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950246</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.594581</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.982266</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.591626</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>-0.283251</td>\n",
       "      <td>-0.518719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>0.950246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.753695</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.936946</td>\n",
       "      <td>0.929064</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.731527</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>-0.302463</td>\n",
       "      <td>-0.537438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>0.932020</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.687192</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>-0.255665</td>\n",
       "      <td>-0.490148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.594581</td>\n",
       "      <td>0.753695</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.762562</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>-0.204433</td>\n",
       "      <td>-0.345320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trimmed</th>\n",
       "      <td>0.963547</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>0.932020</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.687192</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>-0.255665</td>\n",
       "      <td>-0.490148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower</th>\n",
       "      <td>0.982266</td>\n",
       "      <td>0.936946</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863054</td>\n",
       "      <td>0.979803</td>\n",
       "      <td>0.578818</td>\n",
       "      <td>0.979803</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>-0.589655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper</th>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.929064</td>\n",
       "      <td>0.932020</td>\n",
       "      <td>0.762562</td>\n",
       "      <td>0.932020</td>\n",
       "      <td>0.863054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906404</td>\n",
       "      <td>0.867980</td>\n",
       "      <td>0.906404</td>\n",
       "      <td>-0.333005</td>\n",
       "      <td>-0.538916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.979803</td>\n",
       "      <td>0.906404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.411330</td>\n",
       "      <td>-0.629064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.591626</td>\n",
       "      <td>0.731527</td>\n",
       "      <td>0.687192</td>\n",
       "      <td>0.801478</td>\n",
       "      <td>0.687192</td>\n",
       "      <td>0.578818</td>\n",
       "      <td>0.867980</td>\n",
       "      <td>0.661084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661084</td>\n",
       "      <td>-0.346798</td>\n",
       "      <td>-0.474384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full</th>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.966995</td>\n",
       "      <td>0.979803</td>\n",
       "      <td>0.906404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.411330</td>\n",
       "      <td>-0.629064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>-0.283251</td>\n",
       "      <td>-0.302463</td>\n",
       "      <td>-0.255665</td>\n",
       "      <td>-0.204433</td>\n",
       "      <td>-0.255665</td>\n",
       "      <td>-0.376355</td>\n",
       "      <td>-0.333005</td>\n",
       "      <td>-0.411330</td>\n",
       "      <td>-0.346798</td>\n",
       "      <td>-0.411330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel_diff</th>\n",
       "      <td>-0.518719</td>\n",
       "      <td>-0.537438</td>\n",
       "      <td>-0.490148</td>\n",
       "      <td>-0.345320</td>\n",
       "      <td>-0.490148</td>\n",
       "      <td>-0.589655</td>\n",
       "      <td>-0.538916</td>\n",
       "      <td>-0.629064</td>\n",
       "      <td>-0.474384</td>\n",
       "      <td>-0.629064</td>\n",
       "      <td>0.940394</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lower     upper      mean       var   Trimmed     lower  \\\n",
       "lower     1.000000  0.950246  0.963547  0.594581  0.963547  0.982266   \n",
       "upper     0.950246  1.000000  0.969458  0.753695  0.969458  0.936946   \n",
       "mean      0.963547  0.969458  1.000000  0.677340  1.000000  0.956650   \n",
       "var       0.594581  0.753695  0.677340  1.000000  0.677340  0.575862   \n",
       "Trimmed   0.963547  0.969458  1.000000  0.677340  1.000000  0.956650   \n",
       "lower     0.982266  0.936946  0.956650  0.575862  0.956650  1.000000   \n",
       "upper     0.871921  0.929064  0.932020  0.762562  0.932020  0.863054   \n",
       "mean      0.966995  0.970443  0.966995  0.642857  0.966995  0.979803   \n",
       "var       0.591626  0.731527  0.687192  0.801478  0.687192  0.578818   \n",
       "Full      0.966995  0.970443  0.966995  0.642857  0.966995  0.979803   \n",
       "diff     -0.283251 -0.302463 -0.255665 -0.204433 -0.255665 -0.376355   \n",
       "rel_diff -0.518719 -0.537438 -0.490148 -0.345320 -0.490148 -0.589655   \n",
       "\n",
       "             upper      mean       var      Full      diff  rel_diff  \n",
       "lower     0.871921  0.966995  0.591626  0.966995 -0.283251 -0.518719  \n",
       "upper     0.929064  0.970443  0.731527  0.970443 -0.302463 -0.537438  \n",
       "mean      0.932020  0.966995  0.687192  0.966995 -0.255665 -0.490148  \n",
       "var       0.762562  0.642857  0.801478  0.642857 -0.204433 -0.345320  \n",
       "Trimmed   0.932020  0.966995  0.687192  0.966995 -0.255665 -0.490148  \n",
       "lower     0.863054  0.979803  0.578818  0.979803 -0.376355 -0.589655  \n",
       "upper     1.000000  0.906404  0.867980  0.906404 -0.333005 -0.538916  \n",
       "mean      0.906404  1.000000  0.661084  1.000000 -0.411330 -0.629064  \n",
       "var       0.867980  0.661084  1.000000  0.661084 -0.346798 -0.474384  \n",
       "Full      0.906404  1.000000  0.661084  1.000000 -0.411330 -0.629064  \n",
       "diff     -0.333005 -0.411330 -0.346798 -0.411330  1.000000  0.940394  \n",
       "rel_diff -0.538916 -0.629064 -0.474384 -0.629064  0.940394  1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_a.corr(method='spearman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
